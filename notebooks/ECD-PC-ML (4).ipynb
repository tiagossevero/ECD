{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70aea681-2477-45f5-9ffe-1cb8f6cb1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'.env_file' loaded!\n",
      "ENV 'PROD' configured!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "#Import libs python\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "\n",
    "#Import libs internas\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "from hooks.hdfs.hdfs_helper import HdfsHelper\n",
    "from jobs.job_base_config import BaseETLJobClass\n",
    "\n",
    "import poc_helper\n",
    "poc_helper.load_env(\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4faf8a1f-48e4-4c57-a162-c839c8e3a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-11-13T22:04:49.569112Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUsing json file settings.     \u001b[0m [\u001b[0m\u001b[1m\u001b[34mroot\u001b[0m]\u001b[0m \u001b[36mloc\u001b[0m=\u001b[35mspark_utils_session.py:301\u001b[0m\n",
      "\u001b[2m2025-11-13T22:04:49.570997Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExporting default ENV.        \u001b[0m [\u001b[0m\u001b[1m\u001b[34mroot\u001b[0m]\u001b[0m \u001b[36mloc\u001b[0m=\u001b[35mspark_utils_session.py:305\u001b[0m\n",
      "\u001b[2m2025-11-13T22:04:49.571483Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mExporting custom ENVs.        \u001b[0m [\u001b[0m\u001b[1m\u001b[34mroot\u001b[0m]\u001b[0m \u001b[36mloc\u001b[0m=\u001b[35mspark_utils_session.py:338\u001b[0m\n",
      "\u001b[2m2025-11-13T22:04:49.571894Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuilding profile 'efd_t2'.    \u001b[0m [\u001b[0m\u001b[1m\u001b[34mroot\u001b[0m]\u001b[0m \u001b[36mloc\u001b[0m=\u001b[35mspark_utils_session.py:221\u001b[0m\n",
      "\u001b[2m2025-11-13T22:04:49.572355Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mNot enough info for building the kerberos client. Ignoring it\u001b[0m [\u001b[0m\u001b[1m\u001b[34mroot\u001b[0m]\u001b[0m \u001b[36mloc\u001b[0m=\u001b[35mspark_utils_session.py:284\u001b[0m\n",
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/cloudera/parcels/SPARK3-3.5.4.3.5.7191000.0-30-1.p0.68499982/lib/spark3/jars/ivy-2.5.2.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/tsevero/.ivy2/cache\n",
      "The jars for the packages stored in: /home/tsevero/.ivy2/jars\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "com.oracle.database.security#oraclepki added as a dependency\n",
      "com.oracle.database.security#osdt_core added as a dependency\n",
      "com.oracle.database.security#osdt_cert added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-281f0f11-bd7a-4333-a048-ccd78fb0fe55;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.18.0 in central\n",
      "\tfound commons-io#commons-io;2.11.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;3.0.2 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.3.0 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.9.0 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.9.2 in central\n",
      "\tfound com.oracle.database.security#oraclepki;21.19.0.0 in central\n",
      "\tfound com.oracle.database.security#osdt_core;21.19.0.0 in central\n",
      "\tfound com.oracle.database.security#osdt_cert;21.19.0.0 in central\n",
      ":: resolution report :: resolve 175ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.databricks#spark-xml_2.12;0.18.0 from central in [default]\n",
      "\tcom.oracle.database.security#oraclepki;21.19.0.0 from central in [default]\n",
      "\tcom.oracle.database.security#osdt_cert;21.19.0.0 from central in [default]\n",
      "\tcom.oracle.database.security#osdt_core;21.19.0.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.11.0 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.9.2 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.3.0 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;3.0.2 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.9.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-281f0f11-bd7a-4333-a048-ccd78fb0fe55\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/6ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/13 19:04:53 WARN  conf.HiveConf: [Thread-9]: HiveConf of name hive.metastore.runworker.in does not exist\n",
      "25/11/13 19:04:53 WARN  conf.HiveConf: [Thread-9]: HiveConf of name hive.masking.algo does not exist\n",
      "25/11/13 19:04:54 WARN  util.Utils: [Thread-9]: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/com.databricks_spark-xml_2.12-0.18.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.9.2.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/com.oracle.database.security_oraclepki-21.19.0.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/com.oracle.database.security_osdt_core-21.19.0.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/com.oracle.database.security_osdt_cert-21.19.0.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/commons-io_commons-io-2.11.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/org.glassfish.jaxb_txw2-3.0.2.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.3.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:04:54 WARN  yarn.Client: [Thread-9]: Same path resource file:///home/tsevero/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.9.0.jar added multiple times to distributed cache.\n",
      "25/11/13 19:05:00 WARN  util.Utils: [Thread-9]: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    }
   ],
   "source": [
    "def get_session(profile: str, dynamic_allocation_enabled: bool = True) -> utils.DBASparkAppSession:\n",
    "    \"\"\"Generates DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"tsevero_ecd_pc_ml\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "session = get_session(profile='efd_t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00777b24-69dc-4a6e-ba6f-4e11cd534937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = f3baefac-bad0-4d72-a757-9d3824767e61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|namespace         |\n",
      "+------------------+\n",
      "|anac              |\n",
      "|bcadastro         |\n",
      "|bpe               |\n",
      "|c115              |\n",
      "|ccc               |\n",
      "|ccg               |\n",
      "|cte               |\n",
      "|default           |\n",
      "|destda            |\n",
      "|detran_share      |\n",
      "|dime              |\n",
      "|due               |\n",
      "|efd               |\n",
      "|fci               |\n",
      "|gecob             |\n",
      "|gescol            |\n",
      "|gessimples        |\n",
      "|gplam             |\n",
      "|information_schema|\n",
      "|malhas            |\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sparkSession.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5dd6bb-3844-436b-9810-cce86e02a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç SISTEMA DE AN√ÅLISE\n",
      "================================================================================\n",
      "Sess√£o Spark: tsevero_ecd_pc_ml\n",
      "Vers√£o Spark: 3.5.4.3.5.7191000.0-30\n",
      "Iniciado em: 2025-11-13 19:05:08\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PySpark imports com aliases para evitar conflitos\n",
    "from pyspark.sql.functions import (\n",
    "    col as spark_col, \n",
    "    sum as spark_sum, \n",
    "    avg as spark_avg,\n",
    "    count as spark_count,\n",
    "    when as spark_when,\n",
    "    desc as spark_desc,\n",
    "    asc as spark_asc,\n",
    "    round as spark_round,\n",
    "    concat as spark_concat,\n",
    "    lit as spark_lit,\n",
    "    max as spark_max,\n",
    "    min as spark_min,\n",
    "    stddev as spark_stddev,\n",
    "    countDistinct as spark_countDistinct\n",
    ")\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# ‚úÖ CORRE√á√ÉO: N√£o usar abs() que conflita com PySpark\n",
    "# pd.set_option('display.float_format', lambda x: f'{x:,.2f}' if abs(x) > 0.01 else f'{x:.6f}')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Acesso ao Spark\n",
    "spark = session.sparkSession\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç SISTEMA DE AN√ÅLISE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Sess√£o Spark: {spark.sparkContext.appName}\")\n",
    "print(f\"Vers√£o Spark: {spark.version}\")\n",
    "print(f\"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0bca34-e8a9-406c-b6cf-d7cc1486c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configura√ß√µes aplicadas para suprimir warnings\n",
      "\n",
      "    ================================================================================\n",
      "    PIPELINE COMPLETO DE CLASSIFICA√á√ÉO CONT√ÅBIL ECD\n",
      "    ================================================================================\n",
      "    \n",
      "    Para executar:\n",
      "    \n",
      "    1. No ambiente PySpark:\n",
      "       >>> resultado = main(spark)\n",
      "    \n",
      "    2. Acessar resultados:\n",
      "       >>> df_final = resultado['df_final']\n",
      "       >>> estatisticas = resultado['estatisticas']\n",
      "    \n",
      "    3. Carregar resultados intermedi√°rios:\n",
      "       >>> df = carregar_resultado_intermediario(spark, 'final')\n",
      "    \n",
      "    4. Exportar para Hive:\n",
      "       >>> exportar_para_tabela_hive(\n",
      "       ...     resultado['df_final'], \n",
      "       ...     'usr_sat_ecd.contas_classificadas',\n",
      "       ...     particionar_por='dt_referencia'\n",
      "       ... )\n",
      "    \n",
      "    ================================================================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PIPELINE COMPLETO DE CLASSIFICA√á√ÉO ECD - VERS√ÉO COMPLETA\n",
    "================================================================================\n",
    "Atualizado em: 2025-11-13\n",
    "\n",
    "Este pipeline integra todas as funcionalidades do notebook original:\n",
    "1. Ground Truth (identifica√ß√£o de empresas bem comportadas)\n",
    "2. Feature Engineering (extra√ß√£o de caracter√≠sticas estruturais)\n",
    "3. Classifica√ß√£o Estrutural (regras baseadas em padr√µes)\n",
    "4. Classifica√ß√£o por Dicion√°rios (palavras-chave)\n",
    "5. Valida√ß√£o Cont√°bil (equa√ß√£o, natureza, hierarquia)\n",
    "\n",
    "Autor: Sistema de Classifica√ß√£o ECD - SEFAZ/SC\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, lit, regexp_extract, substring, upper, lower, \n",
    "    length, regexp_replace, count, sum as spark_sum, avg,\n",
    "    desc, asc, row_number, dense_rank, countDistinct,\n",
    "    coalesce, greatest, least, round as spark_round,\n",
    "    concat, concat_ws, trim, array, array_contains,\n",
    "    levenshtein, abs as spark_abs, max as spark_max, min as spark_min,\n",
    "    stddev as spark_stddev\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, ArrayType, StructType, StructField\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# ============================================================================\n",
    "# SUPRIMIR WARNINGS DO JANINO\n",
    "# ============================================================================\n",
    "\n",
    "# Configurar logging do Spark para suprimir warnings do CodeGenerator\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Configurar propriedades do Spark para otimizar gera√ß√£o de c√≥digo\n",
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", \"false\")  # Desabilitar whole-stage codegen\n",
    "spark.conf.set(\"spark.sql.codegen.maxFields\", \"50\")     # Reduzir m√°ximo de campos\n",
    "\n",
    "print(\"‚úÖ Configura√ß√µes aplicadas para suprimir warnings\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURA√á√ïES GLOBAIS\n",
    "# ============================================================================\n",
    "\n",
    "class PipelineConfig:\n",
    "    \"\"\"Configura√ß√µes centralizadas do pipeline\"\"\"\n",
    "    \n",
    "    # === DADOS ===\n",
    "    ANO_REFERENCIA = 2024\n",
    "    SCHEMA = \"usr_sat_ecd\"\n",
    "#    TABLE_PLANO_CONTAS = f\"{SCHEMA}.ecd_ri050_plano_contas\"\n",
    "    TABLE_BP = f\"{SCHEMA}.ecd_rj100_balanco_patrimonial\"\n",
    "    TABLE_DRE = f\"{SCHEMA}.ecd_rj150_demonstracao_resultado_exercicio\"\n",
    "    TABLE_IDENTIFICACAO = f\"{SCHEMA}.ecd_r0000_identificacao\"\n",
    "    TABLE_REF_BP = \"teste.ecd_pc_bp\"\n",
    "    TABLE_REF_DRE = \"teste.ecd_pc_dre\"\n",
    "    \n",
    "    # === PROCESSAMENTO ===\n",
    "    LIMITE_REGISTROS = None  # Use None para processar todos\n",
    "    TIPO_CONTA = \"A\"  # A = Anal√≠tica, S = Sint√©tica\n",
    "    \n",
    "    # === OUTPUTS ===\n",
    "    PATH_BASE = \"SAT_BIG_DATA/data-pipeline/batch/poc/tsevero\"\n",
    "    PATH_FEATURES = f\"{PATH_BASE}/features\"\n",
    "    PATH_ESTRUTURAL = f\"{PATH_BASE}/estrutural\"\n",
    "    PATH_DICIONARIOS = f\"{PATH_BASE}/dicionarios\"\n",
    "    PATH_GROUND_TRUTH = f\"{PATH_BASE}/ground_truth\"\n",
    "    PATH_VALIDACAO = f\"{PATH_BASE}/validacao\"\n",
    "    PATH_FINAL = f\"{PATH_BASE}/final\"\n",
    "    \n",
    "    # === CONTROLE DE EXECU√á√ÉO ===\n",
    "    EXECUTAR_GROUND_TRUTH = True\n",
    "    EXECUTAR_FEATURE_ENGINEERING = True\n",
    "    EXECUTAR_CLASSIFICACAO_ESTRUTURAL = True\n",
    "    EXECUTAR_CLASSIFICACAO_DICIONARIOS = True\n",
    "    EXECUTAR_VALIDACAO = True\n",
    "    SALVAR_INTERMEDIARIOS = True\n",
    "    \n",
    "    # === THRESHOLDS GROUND TRUTH ===\n",
    "    THRESHOLD_MATCH_EXATO = 0.30\n",
    "    THRESHOLD_MATCH_FUZZY = 0.50\n",
    "    THRESHOLD_COMPLETUDE = 0.80\n",
    "    TOP_N_EMPRESAS = 1000\n",
    "    \n",
    "    # === TOLER√ÇNCIAS DE VALIDA√á√ÉO ===\n",
    "    TOLERANCIA_EQUACAO = 100.0  # R$ 100 de diferen√ßa aceita\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# M√ìDULO 1: DICION√ÅRIOS DE PALAVRAS-CHAVE\n",
    "# ============================================================================\n",
    "\n",
    "class DicionariosContabeis:\n",
    "    \"\"\"\n",
    "    Dicion√°rios tem√°ticos baseados no padr√£o da Receita Federal\n",
    "    Organizados hierarquicamente por categoria cont√°bil\n",
    "    \"\"\"\n",
    "    \n",
    "    # BALAN√áO PATRIMONIAL - ATIVO\n",
    "    DISPONIBILIDADES = {\n",
    "        'codigo_rf': '1.01.01',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'caixa', 'banco', 'bancos', 'conta corrente', 'conta movimento',\n",
    "            'deposito', 'depositos', 'numerario', 'dinheiro', 'disponivel',\n",
    "            'disponibilidade', 'aplicacao financeira', 'aplicacoes',\n",
    "            'fundo liquidez', 'liquidez imediata'\n",
    "        ],\n",
    "        'palavras_negativas': ['fornecedor', 'cliente', 'estoque', 'imobilizado']\n",
    "    }\n",
    "    \n",
    "    CLIENTES_DUPLICATAS = {\n",
    "        'codigo_rf': '1.01.02.02',\n",
    "        'nivel': 4,\n",
    "        'palavras_chave': [\n",
    "            'cliente', 'clientes', 'duplicata', 'duplicatas', 'receber',\n",
    "            'conta receber', 'contas receber', 'credito', 'creditos',\n",
    "            'faturamento receber', 'vendas receber', 'titulos receber'\n",
    "        ],\n",
    "        'palavras_negativas': ['fornecedor', 'pagar', 'estoque']\n",
    "    }\n",
    "    \n",
    "    ESTOQUES = {\n",
    "        'codigo_rf': '1.01.03',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'estoque', 'estoques', 'mercadoria', 'mercadorias',\n",
    "            'produto', 'produtos', 'materia prima', 'insumo', 'insumos',\n",
    "            'produto acabado', 'produto processo', 'almoxarifado'\n",
    "        ],\n",
    "        'palavras_negativas': ['imobilizado', 'investimento']\n",
    "    }\n",
    "    \n",
    "    TRIBUTOS_RECUPERAR = {\n",
    "        'codigo_rf': '1.01.02.03',\n",
    "        'nivel': 4,\n",
    "        'palavras_chave': [\n",
    "            'icms recuperar', 'ipi recuperar', 'pis recuperar',\n",
    "            'cofins recuperar', 'imposto recuperar', 'tributo recuperar',\n",
    "            'credito tributario', 'credito fiscal'\n",
    "        ],\n",
    "        'palavras_negativas': ['pagar', 'recolher', 'provisao']\n",
    "    }\n",
    "    \n",
    "    IMOBILIZADO = {\n",
    "        'codigo_rf': '1.02.03',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'imobilizado', 'imovel', 'imoveis', 'veiculo', 'veiculos',\n",
    "            'maquina', 'maquinas', 'equipamento', 'equipamentos',\n",
    "            'instalacao', 'instalacoes', 'mobilia', 'moveis', 'utensilio',\n",
    "            'ferramental', 'edificacao', 'edificacoes', 'terreno', 'terrenos',\n",
    "            'benfeitoria', 'benfeitorias', 'ativo fixo'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    DEPRECIACAO = {\n",
    "        'codigo_rf': '1.02.03',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'depreciacao', 'depreciacao acumulada', 'amortizacao',\n",
    "            'amortizacao acumulada', 'exaustao', 'exaustao acumulada'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    INVESTIMENTOS = {\n",
    "        'codigo_rf': '1.02.01',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'participacao', 'participacoes', 'investimento', 'investimentos',\n",
    "            'coligada', 'coligadas', 'controlada', 'controladas',\n",
    "            'acao', 'acoes', 'quota', 'quotas', 'consorcio', 'consorcios'\n",
    "        ],\n",
    "        'palavras_negativas': ['capital proprio', 'capital social']\n",
    "    }\n",
    "    \n",
    "    # BALAN√áO PATRIMONIAL - PASSIVO\n",
    "    FORNECEDORES = {\n",
    "        'codigo_rf': '2.01.03',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'fornecedor', 'fornecedores', 'duplicata pagar', 'duplicatas pagar',\n",
    "            'conta pagar', 'contas pagar', 'debito', 'debitos',\n",
    "            'compra pagar', 'compras pagar', 'obrigacao fornecedor'\n",
    "        ],\n",
    "        'palavras_negativas': ['cliente', 'receber']\n",
    "    }\n",
    "    \n",
    "    EMPRESTIMOS_FINANCIAMENTOS = {\n",
    "        'codigo_rf': '2.01.05',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'emprestimo', 'emprestimos', 'financiamento', 'financiamentos',\n",
    "            'banco pagar', 'bancos pagar', 'divida', 'dividas',\n",
    "            'debito bancario', 'credito bancario', 'linha credito'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    OBRIGACOES_TRABALHISTAS = {\n",
    "        'codigo_rf': '2.01.02',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'salario', 'salarios', 'ordenado', 'ordenados', 'folha pagamento',\n",
    "            'fgts', 'inss', 'ferias', 'decimo terceiro', '13o salario',\n",
    "            'provisao ferias', 'provisao 13o', 'encargo social',\n",
    "            'encargos sociais', 'trabalhista', 'trabalhistas'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    OBRIGACOES_FISCAIS = {\n",
    "        'codigo_rf': '2.01.04',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'icms pagar', 'ipi pagar', 'pis pagar', 'cofins pagar',\n",
    "            'iss pagar', 'irpj pagar', 'csll pagar', 'simples pagar',\n",
    "            'imposto pagar', 'tributo pagar', 'taxa pagar',\n",
    "            'obrigacao fiscal', 'obrigacao tributaria'\n",
    "        ],\n",
    "        'palavras_negativas': ['recuperar', 'credito']\n",
    "    }\n",
    "    \n",
    "    # BALAN√áO PATRIMONIAL - PATRIM√îNIO L√çQUIDO\n",
    "    CAPITAL_SOCIAL = {\n",
    "        'codigo_rf': '2.03.01',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'capital social', 'capital subscrito', 'capital integralizado',\n",
    "            'capital realizado', 'capital'\n",
    "        ],\n",
    "        'palavras_negativas': ['capital terceiros', 'capital giro']\n",
    "    }\n",
    "    \n",
    "    RESERVAS = {\n",
    "        'codigo_rf': '2.03.04',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'reserva', 'reservas', 'reserva legal', 'reserva lucro',\n",
    "            'reserva capital', 'reserva estatutaria'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    LUCROS_PREJUIZOS_ACUMULADOS = {\n",
    "        'codigo_rf': '2.03.09',\n",
    "        'nivel': 3,\n",
    "        'palavras_chave': [\n",
    "            'lucro acumulado', 'lucros acumulados', 'prejuizo acumulado',\n",
    "            'prejuizos acumulados', 'resultado acumulado', 'lucro exercicio',\n",
    "            'prejuizo exercicio'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    # DRE - RECEITAS\n",
    "    RECEITA_BRUTA = {\n",
    "        'codigo_rf': '3.01.01.01.01',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'receita bruta', 'receita venda', 'receita vendas',\n",
    "            'faturamento', 'venda mercadoria', 'venda produto',\n",
    "            'venda servico', 'receita servico', 'receita operacional'\n",
    "        ],\n",
    "        'palavras_negativas': ['deducao', 'devolucao', 'liquida']\n",
    "    }\n",
    "    \n",
    "    DEDUCOES_RECEITA = {\n",
    "        'codigo_rf': '3.01.01.01.02',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'deducao', 'deducoes', 'devolucao', 'devolucoes',\n",
    "            'icms vendas', 'pis vendas', 'cofins vendas',\n",
    "            'iss vendas', 'abatimento', 'abatimentos',\n",
    "            'desconto incondicional', 'cancelamento venda'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    # DRE - CUSTOS E DESPESAS\n",
    "    CUSTO_MERCADORIAS_VENDIDAS = {\n",
    "        'codigo_rf': '3.01.01.03.01.02',\n",
    "        'nivel': 6,\n",
    "        'palavras_chave': [\n",
    "            'cmv', 'custo mercadoria', 'custo mercadorias',\n",
    "            'custo produto', 'custo produtos', 'cpv',\n",
    "            'custo venda', 'custo vendas'\n",
    "        ],\n",
    "        'palavras_negativas': ['despesa', 'administrativa', 'comercial']\n",
    "    }\n",
    "    \n",
    "    DESPESAS_ADMINISTRATIVAS = {\n",
    "        'codigo_rf': '3.01.01.07.01',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'despesa administrativa', 'despesas administrativas',\n",
    "            'despesa geral', 'despesas gerais', 'despesa escritorio',\n",
    "            'material escritorio', 'telefone', 'internet', 'aluguel',\n",
    "            'condominio', 'agua', 'luz', 'energia eletrica'\n",
    "        ],\n",
    "        'palavras_negativas': ['venda', 'comercial']\n",
    "    }\n",
    "    \n",
    "    DESPESAS_COMERCIAIS = {\n",
    "        'codigo_rf': '3.01.01.07.01',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'despesa comercial', 'despesas comerciais', 'despesa venda',\n",
    "            'despesas vendas', 'comissao', 'comissoes', 'propaganda',\n",
    "            'publicidade', 'marketing', 'frete', 'entrega'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    DESPESAS_PESSOAL = {\n",
    "        'codigo_rf': '3.01.01.07.01.02',\n",
    "        'nivel': 6,\n",
    "        'palavras_chave': [\n",
    "            'salario', 'salarios', 'ordenado', 'pro labore',\n",
    "            'honorario', 'honorarios', 'remuneracao', 'gratificacao',\n",
    "            'despesa pessoal', 'folha pagamento'\n",
    "        ],\n",
    "        'palavras_negativas': []\n",
    "    }\n",
    "    \n",
    "    DESPESAS_TRIBUTARIAS = {\n",
    "        'codigo_rf': '3.01.01.07.01',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'taxa', 'taxas', 'multa', 'multas', 'tributo', 'tributos',\n",
    "            'iptu', 'ipva', 'alvara', 'licenca'\n",
    "        ],\n",
    "        'palavras_negativas': ['recuperar', 'credito']\n",
    "    }\n",
    "    \n",
    "    DESPESAS_FINANCEIRAS = {\n",
    "        'codigo_rf': '3.01.01.07.01',\n",
    "        'nivel': 5,\n",
    "        'palavras_chave': [\n",
    "            'juros', 'juro', 'despesa financeira', 'despesas financeiras',\n",
    "            'iof', 'tarifa bancaria', 'encargo financeiro',\n",
    "            'despesa bancaria'\n",
    "        ],\n",
    "        'palavras_negativas': ['receita']\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def obter_todos_dicionarios(cls):\n",
    "        \"\"\"Retorna todos os dicion√°rios como lista\"\"\"\n",
    "        return [\n",
    "            # Ativo\n",
    "            cls.DISPONIBILIDADES,\n",
    "            cls.CLIENTES_DUPLICATAS,\n",
    "            cls.ESTOQUES,\n",
    "            cls.TRIBUTOS_RECUPERAR,\n",
    "            cls.IMOBILIZADO,\n",
    "            cls.DEPRECIACAO,\n",
    "            cls.INVESTIMENTOS,\n",
    "            # Passivo\n",
    "            cls.FORNECEDORES,\n",
    "            cls.EMPRESTIMOS_FINANCIAMENTOS,\n",
    "            cls.OBRIGACOES_TRABALHISTAS,\n",
    "            cls.OBRIGACOES_FISCAIS,\n",
    "            # PL\n",
    "            cls.CAPITAL_SOCIAL,\n",
    "            cls.RESERVAS,\n",
    "            cls.LUCROS_PREJUIZOS_ACUMULADOS,\n",
    "            # DRE\n",
    "            cls.RECEITA_BRUTA,\n",
    "            cls.DEDUCOES_RECEITA,\n",
    "            cls.CUSTO_MERCADORIAS_VENDIDAS,\n",
    "            cls.DESPESAS_ADMINISTRATIVAS,\n",
    "            cls.DESPESAS_COMERCIAIS,\n",
    "            cls.DESPESAS_PESSOAL,\n",
    "            cls.DESPESAS_TRIBUTARIAS,\n",
    "            cls.DESPESAS_FINANCEIRAS\n",
    "        ]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 1: CARREGAMENTO DE DADOS\n",
    "# ============================================================================\n",
    "\n",
    "def carregar_dados(spark):\n",
    "    \"\"\"Carrega dados do plano de contas COM FILTROS DE QUALIDADE\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üì• ETAPA 1: CARREGAMENTO DE DADOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Carregar plano de contas (dados brutos)\n",
    "    print(\"\\nüìä Carregando dados do Balan√ßo Patrimonial e DRE...\")\n",
    "    \n",
    "    # 1. Ler Balan√ßo Patrimonial\n",
    "    df_bp = (spark.table(f\"{PipelineConfig.SCHEMA}.ecd_rj100_balanco_patrimonial\")\n",
    "        .filter(col('dt_referencia') >= PipelineConfig.ANO_REFERENCIA)\n",
    "        .select(\n",
    "            col('id_ecd'),\n",
    "            col('dt_referencia'),\n",
    "            col('cod_agl').alias('cd_conta_anl'),\n",
    "            col('cod_agl_sup').alias('cd_conta_sint'),\n",
    "            col('descr_cod_agl'),  # ‚úÖ Nome da conta\n",
    "            col('ind_dc_cta_fin').alias('cd_natureza'),\n",
    "            col('nivel_agl').alias('nivel'),\n",
    "            lit('A').alias('tp_conta'),  # A = Anal√≠tica\n",
    "            lit('BP').alias('origem')  # Marcador de origem\n",
    "        )\n",
    "    )\n",
    "    print(f\"  ‚úÖ Balan√ßo Patrimonial: {df_bp.count():,} registros\")\n",
    "    \n",
    "    # 2. Ler DRE\n",
    "    df_dre = (spark.table(f\"{PipelineConfig.SCHEMA}.ecd_rj150_demonstracao_resultado_exercicio\")\n",
    "        .filter(col('dt_referencia') >= PipelineConfig.ANO_REFERENCIA)\n",
    "        .select(\n",
    "            col('id_ecd'),\n",
    "            col('dt_referencia'),\n",
    "            col('cod_agl').alias('cd_conta_anl'),\n",
    "            col('cod_agl_sup').alias('cd_conta_sint'),\n",
    "            col('descr_cod_agl'),  # ‚úÖ Nome da conta\n",
    "            col('ind_dc_cta_fin').alias('cd_natureza'),\n",
    "            col('nivel_agl').alias('nivel'),\n",
    "            lit('A').alias('tp_conta'),  # A = Anal√≠tica\n",
    "            lit('DRE').alias('origem')  # Marcador de origem\n",
    "        )\n",
    "    )\n",
    "    print(f\"  ‚úÖ DRE: {df_dre.count():,} registros\")\n",
    "    \n",
    "    # 3. UNI√ÉO das duas tabelas\n",
    "    df_raw = df_bp.union(df_dre)\n",
    "    print(f\"  ‚úÖ Total ap√≥s uni√£o: {df_raw.count():,} registros\")\n",
    "    \n",
    "    # 4. Remover duplicatas (mesma conta pode aparecer em BP e DRE)\n",
    "    print(\"\\nüîÑ Removendo duplicatas...\")\n",
    "    df_raw = df_raw.dropDuplicates(['id_ecd', 'dt_referencia', 'cd_conta_anl'])\n",
    "    print(f\"  ‚úÖ Total ap√≥s deduplica√ß√£o: {df_raw.count():,} registros\")\n",
    "    \n",
    "    # ‚úÖ ADICIONAR AQUI: Distribui√ß√£o por origem\n",
    "    print(\"\\nüìä Distribui√ß√£o por origem:\")\n",
    "    df_raw.groupBy('origem').count().orderBy('origem').show()\n",
    "    \n",
    "    print(\"\\nüîç Aplicando filtros de qualidade...\")\n",
    "    \n",
    "    # Contar registros originais (1x .count())\n",
    "    qtd_original = df_raw.count()\n",
    "    print(f\"üìä Registros originais: {qtd_original:,}\")\n",
    "    \n",
    "    # FILTRO 1: Remover c√≥digos/nomes inv√°lidos\n",
    "    df = df_raw.filter(\n",
    "        col('cd_conta_anl').isNotNull() & \n",
    "        (col('cd_conta_anl') != '') &\n",
    "        (col('cd_conta_anl') != 'NULL') &\n",
    "        col('descr_cod_agl').isNotNull() & \n",
    "        (col('descr_cod_agl') != '') &\n",
    "        (col('descr_cod_agl') != 'NULL')\n",
    "    )\n",
    "    \n",
    "    # FILTRO 2: Remover c√≥digos muito curtos\n",
    "    df = df.filter(length(col('cd_conta_anl')) >= 3)\n",
    "    \n",
    "    # FILTRO 3: Remover duplicatas\n",
    "    if all(c in df.columns for c in ['id_ecd', 'cd_conta_anl', 'dt_referencia']):\n",
    "        qtd_antes_dedup = df.count()\n",
    "        df = df.dropDuplicates(['id_ecd', 'cd_conta_anl', 'dt_referencia'])\n",
    "        qtd_depois_dedup = df.count()\n",
    "        duplicatas_removidas = qtd_antes_dedup - qtd_depois_dedup\n",
    "        \n",
    "        if duplicatas_removidas > 0:\n",
    "            print(f\"   ‚îú‚îÄ Duplicatas removidas: {duplicatas_removidas:,}\")\n",
    "    \n",
    "    # Contar registros finais (1x .count())\n",
    "    qtd_final = df.count()\n",
    "    registros_removidos = qtd_original - qtd_final\n",
    "    \n",
    "    print(f\"üìä Registros filtrados: {qtd_final:,}\")\n",
    "    print(f\"üóëÔ∏è  Registros removidos: {registros_removidos:,}\")\n",
    "    print(f\"üìà Taxa de reten√ß√£o: {(qtd_final / qtd_original * 100):.2f}%\")\n",
    "    \n",
    "    # Aplicar limite se configurado\n",
    "    if PipelineConfig.LIMITE_REGISTROS:\n",
    "        print(f\"\\n‚ö†Ô∏è  Aplicando limite: {PipelineConfig.LIMITE_REGISTROS:,}\")\n",
    "        df = df.limit(PipelineConfig.LIMITE_REGISTROS)\n",
    "    \n",
    "    # Cache para performance\n",
    "    df = df.cache()\n",
    "    \n",
    "    # Estat√≠sticas finais\n",
    "    total = df.count()\n",
    "    empresas = df.select('id_ecd').distinct().count()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Contas carregadas: {total:,}\")\n",
    "    print(f\"‚úÖ Empresas √∫nicas: {empresas:,}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 2: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "def extrair_features(df):\n",
    "    \"\"\"Extrai features estruturais do c√≥digo e nome da conta\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚öôÔ∏è  ETAPA 2: FEATURE ENGINEERING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Primeiro d√≠gito\n",
    "    df = df.withColumn(\n",
    "        'primeiro_digito',\n",
    "        regexp_extract(col('cd_conta_anl'), r'^(\\d)', 1)\n",
    "    )\n",
    "    \n",
    "    # 2. Prefixo de 2 caracteres\n",
    "    df = df.withColumn(\n",
    "        'prefixo_2_chars',\n",
    "        upper(substring(col('cd_conta_anl'), 1, 2))\n",
    "    )\n",
    "    \n",
    "    # 3. Tem ponto?\n",
    "    df = df.withColumn(\n",
    "        'tem_ponto',\n",
    "        when(col('cd_conta_anl').contains('.'), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 4. Comprimento do c√≥digo\n",
    "    df = df.withColumn(\n",
    "        'comprimento_codigo',\n",
    "        length(col('cd_conta_anl'))\n",
    "    )\n",
    "    \n",
    "    # 5. Quantidade de pontos\n",
    "    df = df.withColumn(\n",
    "        'qtd_pontos',\n",
    "        length(col('cd_conta_anl')) - length(regexp_replace(col('cd_conta_anl'), r'\\.', ''))\n",
    "    )\n",
    "    \n",
    "    # 6. Tem letra?\n",
    "    df = df.withColumn(\n",
    "        'tem_letra',\n",
    "        when(col('cd_conta_anl').rlike('[a-zA-Z]'), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 7. Padr√£o estrutural\n",
    "    df = df.withColumn(\n",
    "        'padrao_estrutural',\n",
    "        when(col('cd_conta_anl').rlike(r'^\\d+\\.\\d+\\.\\d+'), 'PADRAO_PONTOS')\n",
    "        .when(col('cd_conta_anl').rlike('^BP'), 'PREFIXO_BP')\n",
    "        .when(col('cd_conta_anl').rlike('^DRE'), 'PREFIXO_DRE')\n",
    "        .when(col('cd_conta_anl').rlike(r'^\\d+$'), 'SOMENTE_NUMEROS')\n",
    "        .otherwise('OUTRO')\n",
    "    )\n",
    "    \n",
    "    # 8. Features de natureza\n",
    "    df = df.withColumn(\n",
    "        'natureza_devedora',\n",
    "        when(col('cd_natureza') == '01', 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        'natureza_credora',\n",
    "        when(col('cd_natureza') == '02', 1).otherwise(0)\n",
    "    ).withColumn(\n",
    "        'natureza_resultado',\n",
    "        when(col('cd_natureza') == '04', 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # 9. Normalizar nome para matching\n",
    "    df = df.withColumn(\n",
    "        'nm_conta_normalizado',\n",
    "        lower(\n",
    "            regexp_replace(\n",
    "                regexp_replace(\n",
    "                    col('descr_cod_agl'),\n",
    "                    '[√°√†√¢√£√§√©√®√™√´√≠√¨√Æ√Ø√≥√≤√¥√µ√∂√∫√π√ª√º√ß√±]',\n",
    "                    ''\n",
    "                ),\n",
    "                '[^a-z0-9 ]',\n",
    "                ''\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Features extra√≠das\")\n",
    "    \n",
    "    # Salvar se configurado\n",
    "    if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "        path = PipelineConfig.PATH_FEATURES\n",
    "        print(f\"\\nüíæ Salvando features em: {path}\")\n",
    "        df.write.mode('overwrite').parquet(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 3: GROUND TRUTH (EMPRESAS BEM COMPORTADAS)\n",
    "# ============================================================================\n",
    "\n",
    "def identificar_ground_truth(spark, df):\n",
    "    \"\"\"\n",
    "    Identifica empresas que seguem rigorosamente o padr√£o da Receita Federal\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ ETAPA 3: IDENTIFICA√á√ÉO DE GROUND TRUTH\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Carregar tabelas de refer√™ncia da RF\n",
    "    try:\n",
    "        df_ref_bp = spark.table(PipelineConfig.TABLE_REF_BP)\n",
    "        df_ref_dre = spark.table(PipelineConfig.TABLE_REF_DRE)\n",
    "        \n",
    "        print(\"‚úÖ Tabelas de refer√™ncia carregadas\")\n",
    "        \n",
    "        # Verificar colunas dispon√≠veis\n",
    "        print(f\"   Colunas BP:  {df_ref_bp.columns}\")\n",
    "        print(f\"   Colunas DRE: {df_ref_dre.columns}\")\n",
    "        \n",
    "        # Calcular matches exatos (usando nomes corretos das colunas)\n",
    "        df_matches = df.join(\n",
    "            df_ref_bp.select(\n",
    "                col('codigo').alias('cd_conta_anl'),\n",
    "                col('descricao').alias('desc_rf')\n",
    "            ),\n",
    "            on='cd_conta_anl',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Por empresa, calcular % de matches\n",
    "        df_stats = df_matches.groupBy('id_ecd', 'dt_referencia').agg(\n",
    "            count('*').alias('total_contas'),\n",
    "            spark_sum(when(col('desc_rf').isNotNull(), 1).otherwise(0)).alias('matches_exatos')\n",
    "        ).withColumn(\n",
    "            'pct_match',\n",
    "            col('matches_exatos') / col('total_contas')\n",
    "        )\n",
    "        \n",
    "        # Filtrar empresas bem comportadas\n",
    "        df_ground_truth = df_stats.filter(\n",
    "            col('pct_match') >= PipelineConfig.THRESHOLD_MATCH_EXATO\n",
    "        ).orderBy(desc('pct_match')).limit(PipelineConfig.TOP_N_EMPRESAS)\n",
    "        \n",
    "        total_gt = df_ground_truth.count()\n",
    "        print(f\"\\n‚úÖ Empresas ground truth identificadas: {total_gt:,}\")\n",
    "        \n",
    "        # Salvar\n",
    "        if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "            path = PipelineConfig.PATH_GROUND_TRUTH\n",
    "            print(f\"üíæ Salvando em: {path}\")\n",
    "            df_ground_truth.write.mode('overwrite').parquet(path)\n",
    "        \n",
    "        return df_ground_truth\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Tabelas de refer√™ncia n√£o dispon√≠veis: {str(e)}\")\n",
    "        print(\"   Pulando identifica√ß√£o de ground truth\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 4: CLASSIFICA√á√ÉO ESTRUTURAL (REGRAS)\n",
    "# ============================================================================\n",
    "\n",
    "def classificar_estrutural(df):\n",
    "    \"\"\"Aplica regras para classificar contas baseado em padr√µes estruturais\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã ETAPA 4: CLASSIFICA√á√ÉO ESTRUTURAL (REGRAS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # --- N√çVEL 1: CLASSES (ATIVO, PASSIVO, RESULTADO) ---\n",
    "    print(\"   ‚Üí N√≠vel 1: Classes (ATIVO, PASSIVO, RESULTADO)...\")\n",
    "    \n",
    "    # Classifica√ß√£o N√≠vel 1\n",
    "    df = df.withColumn(\n",
    "        'classificacao_nivel_1',\n",
    "        # Regra 1: Natureza + N√≠vel exato\n",
    "        when((col('cd_natureza') == '01') & (col('nivel').cast('int') == 1), lit(1))  # ATIVO\n",
    "        .when((col('cd_natureza') == '02') & (col('nivel').cast('int') == 1), lit(2))  # PASSIVO\n",
    "        .when(col('cd_natureza') == '04', lit(3))  # RESULTADO\n",
    "        # Regra 2: Primeiro d√≠gito\n",
    "        .when(col('primeiro_digito') == '1', lit(1))  # ATIVO\n",
    "        .when(col('prefixo_2_chars') == '01', lit(1))  # ATIVO\n",
    "        .when(col('primeiro_digito') == '2', lit(2))  # PASSIVO\n",
    "        .when(col('prefixo_2_chars') == '02', lit(2))  # PASSIVO\n",
    "        .when(col('primeiro_digito') == '3', lit(3))  # RESULTADO\n",
    "        .when(col('prefixo_2_chars') == '03', lit(3))  # RESULTADO\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Descri√ß√£o da classifica√ß√£o\n",
    "    df = df.withColumn(\n",
    "        'classificacao_nivel_1_desc',\n",
    "        when(col('classificacao_nivel_1') == 1, 'ATIVO')\n",
    "        .when(col('classificacao_nivel_1') == 2, 'PASSIVO')\n",
    "        .when(col('classificacao_nivel_1') == 3, 'RESULTADO')\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Confian√ßa da classifica√ß√£o\n",
    "    df = df.withColumn(\n",
    "        'confianca_nivel_1',\n",
    "        when((col('cd_natureza') == '01') & (col('nivel').cast('int') == 1), lit(0.95))\n",
    "        .when((col('cd_natureza') == '02') & (col('nivel').cast('int') == 1), lit(0.95))\n",
    "        .when(col('cd_natureza') == '04', lit(0.90))\n",
    "        .when(col('primeiro_digito').isin(['1', '2', '3']), lit(0.80))\n",
    "        .otherwise(0.0)\n",
    "    )\n",
    "    \n",
    "    # --- N√çVEL 2: SUBGRUPOS ---\n",
    "    print(\"   ‚Üí N√≠vel 2: Subgrupos (Circulante, N√£o Circulante, etc)...\")\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        'classificacao_nivel_2',\n",
    "        # ATIVO\n",
    "        when((col('classificacao_nivel_1') == 1) & \n",
    "             (col('cd_conta_anl').rlike(r'^1\\.?01') | col('cd_conta_anl').rlike(r'^01\\.?1\\.?01')), \n",
    "             lit(1.01))  # Ativo Circulante\n",
    "        .when((col('classificacao_nivel_1') == 1) & \n",
    "              (col('cd_conta_anl').rlike(r'^1\\.?02') | col('cd_conta_anl').rlike(r'^01\\.?1\\.?02')), \n",
    "              lit(1.02))  # Ativo N√£o Circulante\n",
    "        # PASSIVO\n",
    "        .when((col('classificacao_nivel_1') == 2) & \n",
    "              (col('cd_conta_anl').rlike(r'^2\\.?01') | col('cd_conta_anl').rlike(r'^02\\.?1\\.?01')), \n",
    "              lit(2.01))  # Passivo Circulante\n",
    "        .when((col('classificacao_nivel_1') == 2) & \n",
    "              (col('cd_conta_anl').rlike(r'^2\\.?02') | col('cd_conta_anl').rlike(r'^02\\.?1\\.?02')), \n",
    "              lit(2.02))  # Passivo N√£o Circulante\n",
    "        .when((col('classificacao_nivel_1') == 2) & \n",
    "              (col('cd_conta_anl').rlike(r'^2\\.?03') | col('cd_conta_anl').rlike(r'^02\\.?3')), \n",
    "              lit(2.03))  # Patrim√¥nio L√≠quido\n",
    "        .otherwise(col('classificacao_nivel_1'))  # Manter n√≠vel 1 se n√£o houver n√≠vel 2\n",
    "    )\n",
    "    \n",
    "    # Adicionar m√©todo de classifica√ß√£o\n",
    "    df = df.withColumn(\n",
    "        'metodo_classificacao',\n",
    "        when(col('classificacao_nivel_1').isNotNull(), 'ESTRUTURAL')\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    total = df.count()\n",
    "    n1 = df.filter(col('classificacao_nivel_1').isNotNull()).count()\n",
    "    n2 = df.filter(col('classificacao_nivel_2').isNotNull()).count()\n",
    "    \n",
    "    print(f\"\\n‚úÖ N√≠vel 1: {n1:,} / {total:,} ({n1/total*100:.1f}%)\")\n",
    "    print(f\"‚úÖ N√≠vel 2: {n2:,} / {total:,} ({n2/total*100:.1f}%)\")\n",
    "    \n",
    "    # Salvar se configurado\n",
    "    if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "        path = PipelineConfig.PATH_ESTRUTURAL\n",
    "        print(f\"\\nüíæ Salvando classifica√ß√£o estrutural em: {path}\")\n",
    "        df.write.mode('overwrite').parquet(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 5: CLASSIFICA√á√ÉO POR DICION√ÅRIOS\n",
    "# ============================================================================\n",
    "\n",
    "def normalizar_texto_classificacao(texto):\n",
    "    \"\"\"\n",
    "    Normaliza texto para matching de palavras-chave\n",
    "    \"\"\"\n",
    "    if texto is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove acentos e caracteres especiais\n",
    "    texto = texto.lower()\n",
    "    texto = texto.replace('√°', 'a').replace('√†', 'a').replace('√¢', 'a').replace('√£', 'a')\n",
    "    texto = texto.replace('√©', 'e').replace('√®', 'e').replace('√™', 'e')\n",
    "    texto = texto.replace('√≠', 'i').replace('√¨', 'i').replace('√Æ', 'i')\n",
    "    texto = texto.replace('√≥', 'o').replace('√≤', 'o').replace('√¥', 'o').replace('√µ', 'o')\n",
    "    texto = texto.replace('√∫', 'u').replace('√π', 'u').replace('√ª', 'u')\n",
    "    texto = texto.replace('√ß', 'c').replace('√±', 'n')\n",
    "    \n",
    "    # Remove caracteres especiais, mantendo apenas letras e espa√ßos\n",
    "    import re\n",
    "    texto = re.sub(r'[^a-z0-9 ]', '', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "\n",
    "def classificar_por_dicionarios(df):\n",
    "    \"\"\"\n",
    "    Classifica contas usando dicion√°rios de palavras-chave\n",
    "    Aplicado apenas √†s contas que n√£o foram classificadas por regras estruturais\n",
    "    \n",
    "    VERS√ÉO OTIMIZADA: Processa dicion√°rios em lotes para evitar erros de compila√ß√£o\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìö ETAPA 5: CLASSIFICA√á√ÉO POR DICION√ÅRIOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Identificar contas n√£o classificadas\n",
    "    df_nao_classificadas = df.filter(col('classificacao_nivel_1').isNull())\n",
    "    df_classificadas = df.filter(col('classificacao_nivel_1').isNotNull())\n",
    "    \n",
    "    total_nao_class = df_nao_classificadas.count()\n",
    "    print(f\"\\nüìä Contas n√£o classificadas: {total_nao_class:,}\")\n",
    "    \n",
    "    if total_nao_class == 0:\n",
    "        print(\"‚úÖ Todas as contas j√° foram classificadas!\")\n",
    "        return df\n",
    "    \n",
    "    # Obter todos os dicion√°rios\n",
    "    dicionarios = DicionariosContabeis.obter_todos_dicionarios()\n",
    "    print(f\"‚úÖ Dicion√°rios carregados: {len(dicionarios)}\")\n",
    "    \n",
    "    # ESTRAT√âGIA OTIMIZADA: Processar em lotes menores\n",
    "    TAMANHO_LOTE = 5  # Processar 5 dicion√°rios por vez\n",
    "    df_dict_class = df_nao_classificadas\n",
    "    \n",
    "    for lote_idx in range(0, len(dicionarios), TAMANHO_LOTE):\n",
    "        lote = dicionarios[lote_idx:lote_idx + TAMANHO_LOTE]\n",
    "        print(f\"\\n   Processando lote {lote_idx//TAMANHO_LOTE + 1}/{(len(dicionarios)-1)//TAMANHO_LOTE + 1}...\")\n",
    "        \n",
    "        for i, dicionario in enumerate(lote):\n",
    "            idx_global = lote_idx + i\n",
    "            \n",
    "            # Criar lista de palavras-chave para usar com SQL LIKE\n",
    "            palavras_positivas = [normalizar_texto_classificacao(p) for p in dicionario['palavras_chave']]\n",
    "            palavras_negativas = [normalizar_texto_classificacao(p) for p in dicionario['palavras_negativas']]\n",
    "            \n",
    "            # Construir condi√ß√£o usando array_contains (mais eficiente)\n",
    "            codigo_rf = dicionario['codigo_rf']\n",
    "            \n",
    "            # Condi√ß√£o positiva simplificada\n",
    "            condicao = lit(False)\n",
    "            for palavra in palavras_positivas[:10]:  # Limitar a 10 palavras por dicion√°rio\n",
    "                condicao = condicao | col('nm_conta_normalizado').contains(palavra)\n",
    "            \n",
    "            # Condi√ß√£o negativa\n",
    "            if palavras_negativas:\n",
    "                for palavra in palavras_negativas[:5]:  # Limitar a 5 palavras negativas\n",
    "                    condicao = condicao & ~col('nm_conta_normalizado').contains(palavra)\n",
    "            \n",
    "            df_dict_class = df_dict_class.withColumn(\n",
    "                f'match_dict_{idx_global}',\n",
    "                when(condicao, lit(codigo_rf)).otherwise(None)\n",
    "            )\n",
    "        \n",
    "        # A cada lote, consolidar para evitar ac√∫mulo excessivo de colunas\n",
    "        if (lote_idx + TAMANHO_LOTE) % 10 == 0:\n",
    "            match_cols_parcial = [f'match_dict_{j}' for j in range(lote_idx + TAMANHO_LOTE)]\n",
    "            df_dict_class = df_dict_class.withColumn(\n",
    "                f'consolidado_{lote_idx}',\n",
    "                coalesce(*[col(c) for c in match_cols_parcial if c in df_dict_class.columns])\n",
    "            )\n",
    "            # Remover colunas intermedi√°rias\n",
    "            for c in match_cols_parcial:\n",
    "                if c in df_dict_class.columns:\n",
    "                    df_dict_class = df_dict_class.drop(c)\n",
    "    \n",
    "    # Consolidar todas as classifica√ß√µes\n",
    "    cols_consolidadas = [c for c in df_dict_class.columns if c.startswith('consolidado_')]\n",
    "    match_cols_finais = [c for c in df_dict_class.columns if c.startswith('match_dict_')]\n",
    "    \n",
    "    todas_cols = cols_consolidadas + match_cols_finais\n",
    "    if todas_cols:\n",
    "        df_dict_class = df_dict_class.withColumn(\n",
    "            'classificacao_dicionario',\n",
    "            coalesce(*[col(c) for c in todas_cols])\n",
    "        )\n",
    "    else:\n",
    "        df_dict_class = df_dict_class.withColumn('classificacao_dicionario', lit(None))\n",
    "    \n",
    "    # Atualizar classifica√ß√£o final\n",
    "    df_dict_class = df_dict_class.withColumn(\n",
    "        'classificacao_nivel_1',\n",
    "        when(col('classificacao_dicionario').isNotNull(),\n",
    "             substring(col('classificacao_dicionario'), 1, 1).cast(IntegerType()))\n",
    "        .otherwise(col('classificacao_nivel_1'))\n",
    "    ).withColumn(\n",
    "        'classificacao_nivel_1_desc',\n",
    "        when(col('classificacao_dicionario').isNotNull(),\n",
    "             when(col('classificacao_dicionario').startswith('1'), 'ATIVO')\n",
    "             .when(col('classificacao_dicionario').startswith('2'), 'PASSIVO')\n",
    "             .when(col('classificacao_dicionario').startswith('3'), 'RESULTADO')\n",
    "             .otherwise(None))\n",
    "        .otherwise(col('classificacao_nivel_1_desc'))\n",
    "    ).withColumn(\n",
    "        'classificacao_nivel_2',\n",
    "        when(col('classificacao_dicionario').isNotNull(), col('classificacao_dicionario'))\n",
    "        .otherwise(col('classificacao_nivel_2'))\n",
    "    ).withColumn(\n",
    "        'metodo_classificacao',\n",
    "        when(col('classificacao_dicionario').isNotNull(), 'DICIONARIO')\n",
    "        .otherwise(col('metodo_classificacao'))\n",
    "    ).withColumn(\n",
    "        'confianca_nivel_1',\n",
    "        when(col('classificacao_dicionario').isNotNull(), lit(0.75))\n",
    "        .otherwise(col('confianca_nivel_1'))\n",
    "    )\n",
    "    \n",
    "    # Limpar todas as colunas tempor√°rias\n",
    "    colunas_para_remover = ([c for c in df_dict_class.columns if c.startswith('match_dict_')] +\n",
    "                           [c for c in df_dict_class.columns if c.startswith('consolidado_')] +\n",
    "                           ['classificacao_dicionario'])\n",
    "    \n",
    "    for col_name in colunas_para_remover:\n",
    "        if col_name in df_dict_class.columns:\n",
    "            df_dict_class = df_dict_class.drop(col_name)\n",
    "    \n",
    "    # Juntar de volta com as j√° classificadas\n",
    "    df_final = df_classificadas.unionByName(df_dict_class, allowMissingColumns=True)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    classificadas_dict = df_dict_class.filter(col('metodo_classificacao') == 'DICIONARIO').count()\n",
    "    print(f\"\\n‚úÖ Classificadas por dicion√°rio: {classificadas_dict:,}\")\n",
    "    \n",
    "    # Salvar\n",
    "    if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "        path = PipelineConfig.PATH_DICIONARIOS\n",
    "        print(f\"üíæ Salvando em: {path}\")\n",
    "        df_final.write.mode('overwrite').parquet(path)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 6: CONSOLIDA√á√ÉO E CLASSIFICA√á√ÉO FINAL\n",
    "# ============================================================================\n",
    "\n",
    "def consolidar_classificacao(df):\n",
    "    \"\"\"\n",
    "    Consolida todas as classifica√ß√µes em uma classifica√ß√£o final\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîÑ ETAPA 6: CONSOLIDA√á√ÉO DA CLASSIFICA√á√ÉO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Criar classifica√ß√£o final (prioridade: estrutural > dicion√°rio)\n",
    "    df = df.withColumn(\n",
    "        'classificacao_final',\n",
    "        coalesce(\n",
    "            col('classificacao_nivel_2'),\n",
    "            col('classificacao_nivel_1').cast(StringType())\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Confian√ßa final\n",
    "    df = df.withColumn(\n",
    "        'confianca_final',\n",
    "        coalesce(col('confianca_nivel_1'), lit(0.0))\n",
    "    )\n",
    "    \n",
    "    # Estat√≠sticas finais\n",
    "    total = df.count()\n",
    "    classificadas = df.filter(col('classificacao_final').isNotNull()).count()\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADO FINAL:\")\n",
    "    print(f\"   Total de contas:       {total:,}\")\n",
    "    print(f\"   Contas classificadas:  {classificadas:,} ({classificadas/total*100:.1f}%)\")\n",
    "    print(f\"   N√£o classificadas:     {total - classificadas:,}\")\n",
    "    \n",
    "    # Distribui√ß√£o por m√©todo\n",
    "    print(\"\\nüìä Distribui√ß√£o por m√©todo de classifica√ß√£o:\")\n",
    "    df.filter(col('classificacao_final').isNotNull()) \\\n",
    "        .groupBy('metodo_classificacao').count() \\\n",
    "        .orderBy(desc('count')).show(truncate=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 7: VALIDA√á√ÉO CONT√ÅBIL\n",
    "# ============================================================================\n",
    "\n",
    "def validar_equacao_contabil(spark, df_classificado):\n",
    "    \"\"\"\n",
    "    Valida a equa√ß√£o cont√°bil fundamental: ATIVO = PASSIVO + PL\n",
    "    VERS√ÉO CORRIGIDA com tratamento de NULLs\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ ETAPA 7: VALIDA√á√ÉO CONT√ÅBIL\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nüîç VALIDA√á√ÉO 1: EQUA√á√ÉO CONT√ÅBIL (ATIVO = PASSIVO + PL)\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # VERIFICA√á√ÉO PR√âVIA: Checar se as colunas necess√°rias existem\n",
    "    # ========================================================================\n",
    "    \n",
    "    colunas_necessarias = ['id_ecd', 'dt_referencia', 'cd_conta_anl', 'classificacao_final']\n",
    "    colunas_faltando = [c for c in colunas_necessarias if c not in df_classificado.columns]\n",
    "    \n",
    "    if colunas_faltando:\n",
    "        print(f\"‚ùå ERRO: Colunas faltando no DataFrame classificado: {colunas_faltando}\")\n",
    "        print(f\"   Colunas dispon√≠veis: {df_classificado.columns}\")\n",
    "        \n",
    "        # Tentar usar classificacao_nivel_2 como fallback\n",
    "        if 'classificacao_nivel_2' in df_classificado.columns:\n",
    "            print(\"   ‚ö†Ô∏è Usando 'classificacao_nivel_2' como fallback\")\n",
    "            df_classificado = df_classificado.withColumn(\n",
    "                'classificacao_final',\n",
    "                coalesce(\n",
    "                    col('classificacao_nivel_2'),\n",
    "                    col('classificacao_nivel_1').cast(StringType())\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\"   ‚ùå Imposs√≠vel continuar valida√ß√£o sem classifica√ß√£o\")\n",
    "            return None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CARREGAR BALAN√áO PATRIMONIAL\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä Carregando dados de {PipelineConfig.TABLE_BP}...\")\n",
    "    \n",
    "    df_bp = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            id_ecd, \n",
    "            dt_referencia, \n",
    "            cod_agl, \n",
    "            ind_grp_bal,\n",
    "            vl_cta_fin, \n",
    "            ind_dc_cta_fin\n",
    "        FROM {PipelineConfig.TABLE_BP}\n",
    "        WHERE dt_referencia >= {PipelineConfig.ANO_REFERENCIA}\n",
    "          AND ind_cod_agl = 'D'\n",
    "          AND vl_cta_fin IS NOT NULL\n",
    "    \"\"\")\n",
    "    \n",
    "    total_bp = df_bp.count()\n",
    "    print(f\"   ‚úÖ Registros do BP: {total_bp:,}\")\n",
    "    \n",
    "    if total_bp == 0:\n",
    "        print(\"   ‚ùå Nenhum registro encontrado no Balan√ßo Patrimonial!\")\n",
    "        return None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # JUNTAR COM CLASSIFICA√á√ÉO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüîÑ Juntando BP com classifica√ß√µes...\")\n",
    "    \n",
    "    df_bp_class = df_bp.join(\n",
    "        df_classificado.select(\n",
    "            'id_ecd', \n",
    "            'dt_referencia',\n",
    "            col('cd_conta_anl').alias('cod_agl'),\n",
    "            'classificacao_final'\n",
    "        ).filter(col('classificacao_final').isNotNull()),  # ‚úÖ Filtrar NULLs\n",
    "        on=['id_ecd', 'dt_referencia', 'cod_agl'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Estat√≠sticas de JOIN\n",
    "    total_com_class = df_bp_class.filter(col('classificacao_final').isNotNull()).count()\n",
    "    pct_class = (total_com_class / total_bp * 100) if total_bp > 0 else 0\n",
    "    \n",
    "    print(f\"   ‚úÖ Contas com classifica√ß√£o: {total_com_class:,} ({pct_class:.1f}%)\")\n",
    "    print(f\"   ‚ö†Ô∏è Contas sem classifica√ß√£o: {total_bp - total_com_class:,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DETERMINAR GRUPO CONT√ÅBIL\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_bp_class = df_bp_class.withColumn(\n",
    "        'grupo_contabil',\n",
    "        when(col('classificacao_final').isNull(), lit('SEM_CLASSIFICACAO'))\n",
    "        .when(col('classificacao_final').startswith('1'), lit('ATIVO'))\n",
    "        .when(col('classificacao_final').startswith('2.01'), lit('PASSIVO'))\n",
    "        .when(col('classificacao_final').startswith('2.02'), lit('PASSIVO'))\n",
    "        .when(col('classificacao_final').startswith('2.03'), lit('PL'))\n",
    "        .otherwise(lit('OUTROS'))\n",
    "    )\n",
    "    \n",
    "    # Verificar distribui√ß√£o\n",
    "    print(\"\\nüìä Distribui√ß√£o por Grupo Cont√°bil:\")\n",
    "    df_bp_class.groupBy('grupo_contabil').count().orderBy(desc('count')).show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AJUSTAR VALOR PELO INDICADOR D/C\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_bp_class = df_bp_class.withColumn(\n",
    "        'valor_ajustado',\n",
    "        when(col('ind_dc_cta_fin') == 'D', col('vl_cta_fin'))\n",
    "        .when(col('ind_dc_cta_fin') == 'C', -col('vl_cta_fin'))\n",
    "        .otherwise(lit(0))\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TOTALIZAR POR EMPRESA\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nüìä Calculando totais por empresa...\")\n",
    "    \n",
    "    df_totais = df_bp_class.groupBy('id_ecd', 'dt_referencia').agg(\n",
    "        spark_sum(\n",
    "            when(col('grupo_contabil') == 'ATIVO', col('valor_ajustado'))\n",
    "            .otherwise(0)\n",
    "        ).alias('total_ativo'),\n",
    "        spark_sum(\n",
    "            when(col('grupo_contabil') == 'PASSIVO', col('valor_ajustado'))\n",
    "            .otherwise(0)\n",
    "        ).alias('total_passivo'),\n",
    "        spark_sum(\n",
    "            when(col('grupo_contabil') == 'PL', col('valor_ajustado'))\n",
    "            .otherwise(0)\n",
    "        ).alias('total_pl'),\n",
    "        spark_sum(\n",
    "            when(col('grupo_contabil') == 'OUTROS', col('valor_ajustado'))\n",
    "            .otherwise(0)\n",
    "        ).alias('total_outros'),\n",
    "        spark_sum(\n",
    "            when(col('grupo_contabil') == 'SEM_CLASSIFICACAO', col('valor_ajustado'))\n",
    "            .otherwise(0)\n",
    "        ).alias('total_sem_class')\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CALCULAR DIFEREN√áA E VALIDAR\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_totais = df_totais.withColumn(\n",
    "        'passivo_pl_calculado',\n",
    "        coalesce(col('total_passivo'), lit(0)) + coalesce(col('total_pl'), lit(0))\n",
    "    ).withColumn(\n",
    "        'diferenca',\n",
    "        spark_abs(col('total_ativo') - col('passivo_pl_calculado'))\n",
    "    ).withColumn(\n",
    "        'diferenca_percentual',\n",
    "        when(col('total_ativo') != 0,\n",
    "             (col('diferenca') / spark_abs(col('total_ativo'))) * 100)\n",
    "        .otherwise(lit(0))\n",
    "    ).withColumn(\n",
    "        'equacao_valida',\n",
    "        (col('diferenca') <= PipelineConfig.TOLERANCIA_EQUACAO) |\n",
    "        (col('diferenca_percentual') <= 0.01)  # Toler√¢ncia de 0.01%\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ESTAT√çSTICAS FINAIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    total_empresas = df_totais.count()\n",
    "    empresas_validas = df_totais.filter(col('equacao_valida')).count()\n",
    "    pct_validas = (empresas_validas / total_empresas * 100) if total_empresas > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS DA VALIDA√á√ÉO:\")\n",
    "    print(f\"   Total de empresas:     {total_empresas:,}\")\n",
    "    print(f\"   Equa√ß√£o v√°lida:        {empresas_validas:,} ({pct_validas:.1f}%)\")\n",
    "    print(f\"   Equa√ß√£o inv√°lida:      {total_empresas - empresas_validas:,}\")\n",
    "    \n",
    "    # Top 10 maiores diferen√ßas\n",
    "    print(\"\\n‚ö†Ô∏è Top 10 maiores diferen√ßas:\")\n",
    "    df_totais.orderBy(desc('diferenca')).select(\n",
    "        'id_ecd',\n",
    "        'dt_referencia',\n",
    "        spark_round('total_ativo', 2).alias('ativo'),\n",
    "        spark_round('passivo_pl_calculado', 2).alias('passivo_pl'),\n",
    "        spark_round('diferenca', 2).alias('diferenca'),\n",
    "        spark_round('diferenca_percentual', 2).alias('diferenca_%'),\n",
    "        'equacao_valida'\n",
    "    ).show(10, truncate=False)\n",
    "    \n",
    "    # Estat√≠sticas de valores n√£o classificados\n",
    "    df_stats_outros = df_totais.select(\n",
    "        spark_sum('total_outros').alias('soma_outros'),\n",
    "        spark_sum('total_sem_class').alias('soma_sem_class'),\n",
    "        spark_sum(spark_abs('total_ativo')).alias('soma_ativos')\n",
    "    ).collect()[0]\n",
    "    \n",
    "    if df_stats_outros['soma_ativos'] > 0:\n",
    "        pct_outros = (df_stats_outros['soma_outros'] / df_stats_outros['soma_ativos']) * 100\n",
    "        pct_sem_class = (df_stats_outros['soma_sem_class'] / df_stats_outros['soma_ativos']) * 100\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è Impacto de contas n√£o classificadas:\")\n",
    "        print(f\"   Classificadas como 'OUTROS': {pct_outros:.2f}% do ativo total\")\n",
    "        print(f\"   Sem classifica√ß√£o: {pct_sem_class:.2f}% do ativo total\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SALVAR RESULTADOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "        path = f\"{PipelineConfig.PATH_VALIDACAO}/equacao_contabil\"\n",
    "        print(f\"\\nüíæ Salvando valida√ß√£o em: {path}\")\n",
    "        df_totais.write.mode('overwrite').parquet(path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return df_totais\n",
    "\n",
    "def validacao_simples(df_final):\n",
    "    \"\"\"\n",
    "    Valida√ß√£o b√°sica dos resultados de classifica√ß√£o\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã VALIDA√á√ÉO SIMPLES DA CLASSIFICA√á√ÉO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Distribui√ß√£o por classifica√ß√£o n√≠vel 1\n",
    "    print(\"\\nüìä Distribui√ß√£o N√≠vel 1:\")\n",
    "    df_final.groupBy('classificacao_nivel_1_desc').count() \\\n",
    "        .orderBy('classificacao_nivel_1_desc').show()\n",
    "    \n",
    "    # 2. Distribui√ß√£o por classifica√ß√£o n√≠vel 2\n",
    "    print(\"\\nüìä Distribui√ß√£o N√≠vel 2 (Top 10):\")\n",
    "    df_final.filter(col('classificacao_nivel_2').isNotNull()) \\\n",
    "        .groupBy('classificacao_nivel_2').count() \\\n",
    "        .orderBy(desc('count')).show(10)\n",
    "    \n",
    "    # 3. Contas n√£o classificadas\n",
    "    print(\"\\n‚ö†Ô∏è Contas N√ÉO classificadas (N√≠vel 1):\")\n",
    "    nao_classificadas = df_final.filter(col('classificacao_nivel_1').isNull())\n",
    "    count_nao_class = nao_classificadas.count()\n",
    "    \n",
    "    if count_nao_class > 0:\n",
    "        print(f\"   Total: {count_nao_class:,}\")\n",
    "        print(\"\\n   Exemplos:\")\n",
    "        nao_classificadas.select(\n",
    "            'cd_conta_anl',\n",
    "            'descr_cod_agl',\n",
    "            'cd_natureza',\n",
    "            'primeiro_digito'\n",
    "        ).show(10, truncate=False)\n",
    "    else:\n",
    "        print(\"   ‚úÖ Todas as contas foram classificadas!\")\n",
    "    \n",
    "    # 4. Distribui√ß√£o de confian√ßa\n",
    "    print(\"\\nüìä Distribui√ß√£o de Confian√ßa:\")\n",
    "    df_final.select('confianca_final').summary().show()\n",
    "    \n",
    "    # 5. Faixas de confian√ßa\n",
    "    print(\"\\nüìä Classifica√ß√µes por faixa de confian√ßa:\")\n",
    "    df_final.filter(col('classificacao_nivel_1').isNotNull()) \\\n",
    "        .select(\n",
    "            when(col('confianca_final') >= 0.90, 'ALTA (‚â•0.90)')\n",
    "            .when(col('confianca_final') >= 0.80, 'BOA (0.80-0.89)')\n",
    "            .when(col('confianca_final') >= 0.70, 'MODERADA (0.70-0.79)')\n",
    "            .otherwise('BAIXA (<0.70)')\n",
    "            .alias('faixa')\n",
    "        ).groupBy('faixa').count().orderBy('faixa').show(truncate=False)\n",
    "    \n",
    "    return {\n",
    "        'total': df_final.count(),\n",
    "        'classificadas_n1': df_final.filter(col('classificacao_nivel_1').isNotNull()).count(),\n",
    "        'classificadas_n2': df_final.filter(col('classificacao_nivel_2').isNotNull()).count(),\n",
    "        'nao_classificadas': count_nao_class\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ORQUESTRADOR DO PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def executar_pipeline_completo(spark):\n",
    "    \"\"\"Executa o pipeline completo de classifica√ß√£o\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ INICIANDO PIPELINE COMPLETO DE CLASSIFICA√á√ÉO ECD\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Ano de refer√™ncia: {PipelineConfig.ANO_REFERENCIA}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    inicio = datetime.now()\n",
    "    resultados = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Carregamento\n",
    "        df = carregar_dados(spark)\n",
    "        \n",
    "        # 2. Feature Engineering\n",
    "        if PipelineConfig.EXECUTAR_FEATURE_ENGINEERING:\n",
    "            df = extrair_features(df)\n",
    "        \n",
    "        # 3. Ground Truth\n",
    "        if PipelineConfig.EXECUTAR_GROUND_TRUTH:\n",
    "            try:\n",
    "                df_ground_truth = identificar_ground_truth(spark, df)\n",
    "                resultados['ground_truth'] = df_ground_truth\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Erro em Ground Truth: {str(e)}\")\n",
    "        \n",
    "        # 4. Classifica√ß√£o Estrutural\n",
    "        if PipelineConfig.EXECUTAR_CLASSIFICACAO_ESTRUTURAL:\n",
    "            df = classificar_estrutural(df)\n",
    "        \n",
    "        # 5. Classifica√ß√£o por Dicion√°rios\n",
    "        if PipelineConfig.EXECUTAR_CLASSIFICACAO_DICIONARIOS:\n",
    "            df = classificar_por_dicionarios(df)\n",
    "        \n",
    "        # 6. Consolida√ß√£o\n",
    "        df_final = consolidar_classificacao(df)\n",
    "        \n",
    "        # 7. Valida√ß√£o\n",
    "        if PipelineConfig.EXECUTAR_VALIDACAO:\n",
    "            print(\"\\n‚úÖ Executando valida√ß√£o...\")\n",
    "            try:\n",
    "                # Valida√ß√£o simples\n",
    "                resultado_validacao = validacao_simples(df_final)\n",
    "                resultados['validacao_simples'] = resultado_validacao\n",
    "                \n",
    "                # Valida√ß√£o da equa√ß√£o cont√°bil\n",
    "                df_equacao = validar_equacao_contabil(spark, df_final)\n",
    "                resultados['validacao_equacao'] = df_equacao\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Erro na Valida√ß√£o: {str(e)}\")\n",
    "        \n",
    "        # Relat√≥rio Final\n",
    "        fim = datetime.now()\n",
    "        duracao = fim - inicio\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ PIPELINE CONCLU√çDO COM SUCESSO\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"In√≠cio:   {inicio.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Fim:      {fim.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Dura√ß√£o:  {duracao}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\nüìä ESTAT√çSTICAS FINAIS:\")\n",
    "        total = df_final.count()\n",
    "        classificadas_n1 = df_final.filter(col('classificacao_nivel_1').isNotNull()).count()\n",
    "        classificadas_n2 = df_final.filter(col('classificacao_nivel_2').isNotNull()).count()\n",
    "        \n",
    "        print(f\"   Total de contas:       {total:,}\")\n",
    "        print(f\"   Classificadas N√≠vel 1: {classificadas_n1:,} ({classificadas_n1/total*100:.1f}%)\")\n",
    "        print(f\"   Classificadas N√≠vel 2: {classificadas_n2:,} ({classificadas_n2/total*100:.1f}%)\")\n",
    "        \n",
    "        # Salvar resultado final\n",
    "        if PipelineConfig.SALVAR_INTERMEDIARIOS:\n",
    "            print(f\"\\nüíæ Salvando resultado final em: {PipelineConfig.PATH_FINAL}\")\n",
    "            df_final.write.mode('overwrite').parquet(PipelineConfig.PATH_FINAL)\n",
    "        \n",
    "        return {\n",
    "            'df_final': df_final,\n",
    "            'resultados': resultados,\n",
    "            'estatisticas': {\n",
    "                'total': total,\n",
    "                'classificadas_n1': classificadas_n1,\n",
    "                'classificadas_n2': classificadas_n2,\n",
    "                'duracao': duracao\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO NO PIPELINE: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ïES AUXILIARES\n",
    "# ============================================================================\n",
    "\n",
    "def carregar_resultado_intermediario(spark, etapa):\n",
    "    \"\"\"Carrega resultado de uma etapa j√° processada\"\"\"\n",
    "    \n",
    "    path_map = {\n",
    "        'features': PipelineConfig.PATH_FEATURES,\n",
    "        'estrutural': PipelineConfig.PATH_ESTRUTURAL,\n",
    "        'dicionarios': PipelineConfig.PATH_DICIONARIOS,\n",
    "        'ground_truth': PipelineConfig.PATH_GROUND_TRUTH,\n",
    "        'final': PipelineConfig.PATH_FINAL\n",
    "    }\n",
    "    \n",
    "    path = path_map.get(etapa, f\"{PipelineConfig.PATH_BASE}/{etapa}\")\n",
    "    print(f\"üì• Carregando resultado intermedi√°rio de: {path}\")\n",
    "    \n",
    "    try:\n",
    "        df = spark.read.parquet(path)\n",
    "        print(f\"‚úÖ Carregado: {df.count():,} registros\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def exportar_para_tabela_hive(df, nome_tabela, particionar_por=None):\n",
    "    \"\"\"Exporta resultado para tabela Hive\"\"\"\n",
    "    \n",
    "    print(f\"\\nüíæ Exportando para tabela Hive: {nome_tabela}\")\n",
    "    \n",
    "    writer = df.write.mode('overwrite')\n",
    "    \n",
    "    if particionar_por:\n",
    "        writer = writer.partitionBy(particionar_por)\n",
    "    \n",
    "    writer.saveAsTable(nome_tabela)\n",
    "    \n",
    "    print(f\"‚úÖ Tabela criada: {nome_tabela}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main(spark):\n",
    "    \"\"\"Fun√ß√£o principal\"\"\"\n",
    "    \n",
    "    resultado = executar_pipeline_completo(spark)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECU√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\"\"\n",
    "    ================================================================================\n",
    "    PIPELINE COMPLETO DE CLASSIFICA√á√ÉO CONT√ÅBIL ECD\n",
    "    ================================================================================\n",
    "    \n",
    "    Para executar:\n",
    "    \n",
    "    1. No ambiente PySpark:\n",
    "       >>> resultado = main(spark)\n",
    "    \n",
    "    2. Acessar resultados:\n",
    "       >>> df_final = resultado['df_final']\n",
    "       >>> estatisticas = resultado['estatisticas']\n",
    "    \n",
    "    3. Carregar resultados intermedi√°rios:\n",
    "       >>> df = carregar_resultado_intermediario(spark, 'final')\n",
    "    \n",
    "    4. Exportar para Hive:\n",
    "       >>> exportar_para_tabela_hive(\n",
    "       ...     resultado['df_final'], \n",
    "       ...     'usr_sat_ecd.contas_classificadas',\n",
    "       ...     particionar_por='dt_referencia'\n",
    "       ... )\n",
    "    \n",
    "    ================================================================================\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e845cd-9c73-4724-afd2-b58f0bf3c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√µes de filtro carregadas com sucesso!\n",
      "\n",
      "üìñ Pr√≥ximos passos:\n",
      "   1. Use: df_saldos, df_empresas, df_ml = carregar_dados_ecd_filtrados()\n",
      "   2. Ou: df_filtrado = aplicar_filtros_globais(df_raw, tipo_tabela='saldos')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "C√âLULA DE FILTRO DE DADOS - ADICIONAR LOGO AP√ìS CONFIGURA√á√ÉO INICIAL\n",
    "================================================================================\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "1. Adicione esta c√©lula DEPOIS da c√©lula de configura√ß√£o inicial\n",
    "2. ANTES de qualquer processamento de dados\n",
    "3. Esta c√©lula deve ser a primeira a carregar e filtrar os dados\n",
    "\n",
    "POSI√á√ÉO RECOMENDADA:\n",
    "- Depois da c√©lula com \"class PipelineConfig\"\n",
    "- Antes de qualquer c√©lula que carregue dados das tabelas\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import col, abs as spark_abs, coalesce, lit\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO DE FILTRO GLOBAL - REMOVER ZEROS E NULOS\n",
    "# ============================================================================\n",
    "\n",
    "def filtrar_dados_validos(df, campos_saldo=['saldo_final_contabil', 'saldo_inicial_contabil', \n",
    "                                              'valor_debito_periodo', 'valor_credito_periodo']):\n",
    "    \"\"\"\n",
    "    Filtra registros com valores zerados ou nulos nos campos de saldo.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a ser filtrado\n",
    "        campos_saldo: Lista de campos de saldo para verificar\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame filtrado (sem zeros e nulos)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üìä Registros antes do filtro: {df.count():,}\")\n",
    "    \n",
    "    # Construir condi√ß√£o de filtro\n",
    "    # Remove registros onde TODOS os campos de saldo s√£o zero ou nulo\n",
    "    condicao_valida = None\n",
    "    \n",
    "    for campo in campos_saldo:\n",
    "        if campo in df.columns:\n",
    "            # Campo n√£o √© nulo E n√£o √© zero\n",
    "            condicao_campo = (\n",
    "                col(campo).isNotNull() & \n",
    "                (spark_abs(col(campo)) > 0.01)  # Toler√¢ncia para valores muito pequenos\n",
    "            )\n",
    "            \n",
    "            if condicao_valida is None:\n",
    "                condicao_valida = condicao_campo\n",
    "            else:\n",
    "                # Pelo menos UM campo deve ter valor v√°lido\n",
    "                condicao_valida = condicao_valida | condicao_campo\n",
    "    \n",
    "    # Aplicar filtro\n",
    "    if condicao_valida is not None:\n",
    "        df_filtrado = df.filter(condicao_valida)\n",
    "    else:\n",
    "        df_filtrado = df\n",
    "    \n",
    "    registros_removidos = df.count() - df_filtrado.count()\n",
    "    print(f\"üìä Registros depois do filtro: {df_filtrado.count():,}\")\n",
    "    print(f\"üóëÔ∏è  Registros removidos (zeros/nulos): {registros_removidos:,}\")\n",
    "    print(f\"‚úÖ Taxa de reten√ß√£o: {(df_filtrado.count() / df.count() * 100):.2f}%\")\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "\n",
    "def filtrar_contas_validas(df, campo_conta='cd_conta', campo_nome='nm_conta'):\n",
    "    \"\"\"\n",
    "    Remove registros com c√≥digos ou nomes de conta inv√°lidos.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a ser filtrado\n",
    "        campo_conta: Nome do campo com c√≥digo da conta\n",
    "        campo_nome: Nome do campo com nome da conta\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame filtrado\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìã Filtrando contas inv√°lidas...\")\n",
    "    print(f\"üìä Registros antes: {df.count():,}\")\n",
    "    \n",
    "    condicoes = []\n",
    "    \n",
    "    # 1. C√≥digo da conta n√£o pode ser nulo ou vazio\n",
    "    if campo_conta in df.columns:\n",
    "        condicoes.append(\n",
    "            col(campo_conta).isNotNull() & \n",
    "            (col(campo_conta) != '') &\n",
    "            (col(campo_conta) != 'NULL')\n",
    "        )\n",
    "    \n",
    "    # 2. Nome da conta n√£o pode ser nulo ou vazio\n",
    "    if campo_nome in df.columns:\n",
    "        condicoes.append(\n",
    "            col(campo_nome).isNotNull() & \n",
    "            (col(campo_nome) != '') &\n",
    "            (col(campo_nome) != 'NULL')\n",
    "        )\n",
    "    \n",
    "    # Aplicar todas as condi√ß√µes\n",
    "    if condicoes:\n",
    "        condicao_final = condicoes[0]\n",
    "        for cond in condicoes[1:]:\n",
    "            condicao_final = condicao_final & cond\n",
    "        \n",
    "        df_filtrado = df.filter(condicao_final)\n",
    "    else:\n",
    "        df_filtrado = df\n",
    "    \n",
    "    registros_removidos = df.count() - df_filtrado.count()\n",
    "    print(f\"üìä Registros depois: {df_filtrado.count():,}\")\n",
    "    print(f\"üóëÔ∏è  Registros removidos (inv√°lidos): {registros_removidos:,}\")\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "\n",
    "def aplicar_filtros_globais(df, tipo_tabela='saldos'):\n",
    "    \"\"\"\n",
    "    Aplica todos os filtros de qualidade nos dados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a ser filtrado\n",
    "        tipo_tabela: Tipo de tabela ('saldos', 'plano_contas', 'balanco', 'dre')\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame filtrado e limpo\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"üîç APLICANDO FILTROS DE QUALIDADE - {tipo_tabela.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_original = df\n",
    "    \n",
    "    # Filtro 1: Remover zeros e nulos dos saldos\n",
    "    if tipo_tabela in ['saldos', 'balanco', 'dre']:\n",
    "        if tipo_tabela == 'saldos':\n",
    "            campos = ['saldo_final_contabil', 'saldo_inicial_contabil', \n",
    "                     'valor_debito_periodo', 'valor_credito_periodo']\n",
    "        else:\n",
    "            # Para BP e DRE, verificar campos de valor\n",
    "            campos = [c for c in df.columns if 'valor' in c.lower() or 'saldo' in c.lower()]\n",
    "        \n",
    "        if campos:\n",
    "            df = filtrar_dados_validos(df, campos)\n",
    "    \n",
    "    # Filtro 2: Remover contas inv√°lidas\n",
    "    if 'cd_conta' in df.columns or 'nm_conta' in df.columns:\n",
    "        df = filtrar_contas_validas(df)\n",
    "    \n",
    "    # Filtro 3: Remover registros duplicados (se houver)\n",
    "    if 'id_ecd' in df.columns and 'cd_conta' in df.columns:\n",
    "        colunas_chave = ['id_ecd', 'cd_conta']\n",
    "        if 'dt_referencia' in df.columns or 'ano_referencia' in df.columns:\n",
    "            colunas_chave.append('dt_referencia' if 'dt_referencia' in df.columns else 'ano_referencia')\n",
    "        \n",
    "        qtd_antes = df.count()\n",
    "        df = df.dropDuplicates(colunas_chave)\n",
    "        qtd_depois = df.count()\n",
    "        \n",
    "        if qtd_antes != qtd_depois:\n",
    "            print(f\"\\nüóëÔ∏è  Duplicatas removidas: {qtd_antes - qtd_depois:,}\")\n",
    "    \n",
    "    # Resumo final\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä RESUMO DO FILTRO:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Registros originais: {df_original.count():,}\")\n",
    "    print(f\"Registros filtrados: {df.count():,}\")\n",
    "    print(f\"Registros removidos: {df_original.count() - df.count():,}\")\n",
    "    print(f\"Taxa de reten√ß√£o: {(df.count() / df_original.count() * 100):.2f}%\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXEMPLO DE USO - CARREGAR E FILTRAR DADOS\n",
    "# ============================================================================\n",
    "\n",
    "def carregar_dados_ecd_filtrados():\n",
    "    \"\"\"\n",
    "    Carrega e filtra os dados principais do ECD.\n",
    "    USAR ESTA FUN√á√ÉO NO LUGAR DO CARREGAMENTO DIRETO DAS TABELAS.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ Carregando dados do ECD com filtros aplicados...\")\n",
    "    \n",
    "    # 1. Carregar tabela de saldos\n",
    "    print(\"\\nüìÇ Carregando: teste.ecd_saldos_contas_v2\")\n",
    "    df_saldos_raw = spark.table('teste.ecd_saldos_contas_v2')\n",
    "    df_saldos = aplicar_filtros_globais(df_saldos_raw, tipo_tabela='saldos')\n",
    "    \n",
    "    # 2. Carregar tabela de empresas (n√£o precisa filtrar saldos)\n",
    "    print(\"\\nüìÇ Carregando: teste.ecd_empresas_cadastro\")\n",
    "    df_empresas = spark.table('teste.ecd_empresas_cadastro')\n",
    "    print(f\"üìä Empresas carregadas: {df_empresas.count():,}\")\n",
    "    \n",
    "    # 3. Carregar tabela ML (n√£o precisa filtrar saldos)\n",
    "    print(\"\\nüìÇ Carregando: teste.ecd_ml_empresas_resumo\")\n",
    "    df_ml = spark.table('teste.ecd_ml_empresas_resumo')\n",
    "    print(f\"üìä Registros ML carregados: {df_ml.count():,}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Todos os dados carregados e filtrados com sucesso!\")\n",
    "    \n",
    "    return df_saldos, df_empresas, df_ml\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INSTRU√á√ïES DE USO NO NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "COMO USAR:\n",
    "\n",
    "1. ADICIONE ESTA C√âLULA LOGO AP√ìS A C√âLULA DE CONFIGURA√á√ÉO INICIAL\n",
    "\n",
    "4. PARA OUTROS TIPOS DE TABELAS:\n",
    "\n",
    "   df_bp = aplicar_filtros_globais(df_bp_raw, tipo_tabela='balanco')\n",
    "   df_dre = aplicar_filtros_globais(df_dre_raw, tipo_tabela='dre')\n",
    "   df_plano = aplicar_filtros_globais(df_plano_raw, tipo_tabela='plano_contas')\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de filtro carregadas com sucesso!\")\n",
    "print(\"\\nüìñ Pr√≥ximos passos:\")\n",
    "print(\"   1. Use: df_saldos, df_empresas, df_ml = carregar_dados_ecd_filtrados()\")\n",
    "print(\"   2. Ou: df_filtrado = aplicar_filtros_globais(df_raw, tipo_tabela='saldos')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f4c0ad-dad3-4c71-b25f-2ba390cce46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ INICIANDO PIPELINE COMPLETO DE CLASSIFICA√á√ÉO ECD\n",
      "================================================================================\n",
      "Data/Hora: 2025-11-13 19:05:37\n",
      "Ano de refer√™ncia: 2024\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üì• ETAPA 1: CARREGAMENTO DE DADOS\n",
      "================================================================================\n",
      "\n",
      "üìä Carregando dados do Balan√ßo Patrimonial e DRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Balan√ßo Patrimonial: 144,602,899 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ DRE: 40,260,048 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Total ap√≥s uni√£o: 184,862,947 registros\n",
      "\n",
      "üîÑ Removendo duplicatas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Total ap√≥s deduplica√ß√£o: 102,628,360 registros\n",
      "\n",
      "üìä Distribui√ß√£o por origem:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|origem|   count|\n",
      "+------+--------+\n",
      "|    BP|80595853|\n",
      "|   DRE|22032507|\n",
      "+------+--------+\n",
      "\n",
      "\n",
      "üîç Aplicando filtros de qualidade...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros originais: 102,628,360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros filtrados: 99,773,786\n",
      "üóëÔ∏è  Registros removidos: 2,854,574\n",
      "üìà Taxa de reten√ß√£o: 97.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Contas carregadas: 99,773,786\n",
      "‚úÖ Empresas √∫nicas: 384,515\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚öôÔ∏è  ETAPA 2: FEATURE ENGINEERING\n",
      "================================================================================\n",
      "‚úÖ Features extra√≠das\n",
      "\n",
      "üíæ Salvando features em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ ETAPA 3: IDENTIFICA√á√ÉO DE GROUND TRUTH\n",
      "================================================================================\n",
      "‚úÖ Tabelas de refer√™ncia carregadas\n",
      "   Colunas BP:  ['codigo', 'descricao', 'tipo', 'conta_superior', 'nivel', 'natureza']\n",
      "   Colunas DRE: ['codigo', 'descricao', 'tipo', 'conta_superior', 'nivel', 'natureza']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Empresas ground truth identificadas: 1,000\n",
      "üíæ Salvando em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/ground_truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìã ETAPA 4: CLASSIFICA√á√ÉO ESTRUTURAL (REGRAS)\n",
      "================================================================================\n",
      "   ‚Üí N√≠vel 1: Classes (ATIVO, PASSIVO, RESULTADO)...\n",
      "   ‚Üí N√≠vel 2: Subgrupos (Circulante, N√£o Circulante, etc)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ N√≠vel 1: 45,316,501 / 99,773,786 (45.4%)\n",
      "‚úÖ N√≠vel 2: 45,316,501 / 99,773,786 (45.4%)\n",
      "\n",
      "üíæ Salvando classifica√ß√£o estrutural em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/estrutural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö ETAPA 5: CLASSIFICA√á√ÉO POR DICION√ÅRIOS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Contas n√£o classificadas: 54,457,285\n",
      "‚úÖ Dicion√°rios carregados: 22\n",
      "\n",
      "   Processando lote 1/5...\n",
      "\n",
      "   Processando lote 2/5...\n",
      "\n",
      "   Processando lote 3/5...\n",
      "\n",
      "   Processando lote 4/5...\n",
      "\n",
      "   Processando lote 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Classificadas por dicion√°rio: 488,183\n",
      "üíæ Salvando em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/dicionarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîÑ ETAPA 6: CONSOLIDA√á√ÉO DA CLASSIFICA√á√ÉO\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTADO FINAL:\n",
      "   Total de contas:       99,773,786\n",
      "   Contas classificadas:  45,804,684 (45.9%)\n",
      "   N√£o classificadas:     53,969,102\n",
      "\n",
      "üìä Distribui√ß√£o por m√©todo de classifica√ß√£o:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|metodo_classificacao|count   |\n",
      "+--------------------+--------+\n",
      "|ESTRUTURAL          |45316501|\n",
      "|DICIONARIO          |488183  |\n",
      "+--------------------+--------+\n",
      "\n",
      "\n",
      "‚úÖ Executando valida√ß√£o...\n",
      "\n",
      "================================================================================\n",
      "üìã VALIDA√á√ÉO SIMPLES DA CLASSIFICA√á√ÉO\n",
      "================================================================================\n",
      "\n",
      "üìä Distribui√ß√£o N√≠vel 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------+\n",
      "|classificacao_nivel_1_desc|   count|\n",
      "+--------------------------+--------+\n",
      "|                      NULL|53969102|\n",
      "|                     ATIVO|24308453|\n",
      "|                   PASSIVO|14421108|\n",
      "|                 RESULTADO| 7075123|\n",
      "+--------------------------+--------+\n",
      "\n",
      "\n",
      "üìä Distribui√ß√£o N√≠vel 2 (Top 10):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+\n",
      "|classificacao_nivel_2|   count|\n",
      "+---------------------+--------+\n",
      "|                  1.0|21809053|\n",
      "|                  2.0|13108673|\n",
      "|                  3.0| 7054066|\n",
      "|                 1.01| 1520498|\n",
      "|                 2.01|  876119|\n",
      "|                 1.02|  548446|\n",
      "|              1.02.01|  348150|\n",
      "|                 2.02|  235869|\n",
      "|                 2.03|  163777|\n",
      "|              1.02.03|   36318|\n",
      "+---------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "‚ö†Ô∏è Contas N√ÉO classificadas (N√≠vel 1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total: 53,969,102\n",
      "\n",
      "   Exemplos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------------------+-----------+---------------+\n",
      "|cd_conta_anl           |descr_cod_agl                   |cd_natureza|primeiro_digito|\n",
      "+-----------------------+--------------------------------+-----------+---------------+\n",
      "|BP.1.1.4.5.0014        |Encargos Financeiros a Apropriar|D          |               |\n",
      "|BP.1.2.3               |IMOBILIZADO                     |D          |               |\n",
      "|0011111                |CAIXAS E EQUIVALENTES DE CAIXA  |D          |0              |\n",
      "|00200000000000005000010|(-) CONTRIBUICAO SOCIAL         |D          |0              |\n",
      "|BAL1.2.1.1.03.006-2006 |INSS C/ TERCEIROS               |C          |               |\n",
      "|050.010.588            |Inss                            |D          |0              |\n",
      "|050.110.570            |Uniformes e Equipamentos        |D          |0              |\n",
      "|001126                 |ALUGUEIS A RECEBER              |C          |0              |\n",
      "|001.2654               |Vendas de Mercadorias a Vista   |C          |0              |\n",
      "|050.010.4334           |INSS                            |C          |0              |\n",
      "+-----------------------+--------------------------------+-----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìä Distribui√ß√£o de Confian√ßa:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|    confianca_final|\n",
      "+-------+-------------------+\n",
      "|  count|           99773786|\n",
      "|   mean| 0.3525927145827882|\n",
      "| stddev|0.39694970358710846|\n",
      "|    min|                0.0|\n",
      "|    25%|                0.0|\n",
      "|    50%|                0.0|\n",
      "|    75%|                0.8|\n",
      "|    max|                0.8|\n",
      "+-------+-------------------+\n",
      "\n",
      "\n",
      "üìä Classifica√ß√µes por faixa de confian√ßa:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|faixa               |count   |\n",
      "+--------------------+--------+\n",
      "|BAIXA (<0.70)       |1799785 |\n",
      "|BOA (0.80-0.89)     |43516716|\n",
      "|MODERADA (0.70-0.79)|488183  |\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ ETAPA 7: VALIDA√á√ÉO CONT√ÅBIL\n",
      "================================================================================\n",
      "\n",
      "üîç VALIDA√á√ÉO 1: EQUA√á√ÉO CONT√ÅBIL (ATIVO = PASSIVO + PL)\n",
      "\n",
      "üìä Carregando dados de usr_sat_ecd.ecd_rj100_balanco_patrimonial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Registros do BP: 119,548,452\n",
      "\n",
      "üîÑ Juntando BP com classifica√ß√µes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Contas com classifica√ß√£o: 61,996,033 (51.9%)\n",
      "   ‚ö†Ô∏è Contas sem classifica√ß√£o: 57,552,419\n",
      "\n",
      "üìä Distribui√ß√£o por Grupo Cont√°bil:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|   grupo_contabil|   count|\n",
      "+-----------------+--------+\n",
      "|SEM_CLASSIFICACAO|57552419|\n",
      "|            ATIVO|36058759|\n",
      "|           OUTROS|24003354|\n",
      "|          PASSIVO| 1709838|\n",
      "|               PL|  224082|\n",
      "+-----------------+--------+\n",
      "\n",
      "\n",
      "üìä Calculando totais por empresa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTADOS DA VALIDA√á√ÉO:\n",
      "   Total de empresas:     379,007\n",
      "   Equa√ß√£o v√°lida:        82,821 (21.9%)\n",
      "   Equa√ß√£o inv√°lida:      296,186\n",
      "\n",
      "‚ö†Ô∏è Top 10 maiores diferen√ßas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----------------+----------+----------------+-----------+--------------+\n",
      "|id_ecd|dt_referencia|ativo           |passivo_pl|diferenca       |diferenca_%|equacao_valida|\n",
      "+------+-------------+----------------+----------+----------------+-----------+--------------+\n",
      "|109386|202210       |9796033727588.86|0.00      |9796033727588.86|100.00     |false         |\n",
      "|109390|202207       |9631568638524.51|0.00      |9631568638524.51|100.00     |false         |\n",
      "|97416 |202101       |8415527074030.25|0.00      |8415527074030.25|100.00     |false         |\n",
      "|109394|202204       |7912653391240.36|0.00      |7912653391240.36|100.00     |false         |\n",
      "|109405|202201       |7770812443837.53|0.00      |7770812443837.53|100.00     |false         |\n",
      "|97412 |202107       |7707438895603.16|0.00      |7707438895603.16|100.00     |false         |\n",
      "|97454 |202007       |2914767011935.26|0.00      |2914767011935.26|100.00     |false         |\n",
      "|97464 |202001       |2840113087999.97|0.00      |2840113087999.97|100.00     |false         |\n",
      "|97533 |201907       |2568446965558.72|0.00      |2568446965558.72|100.00     |false         |\n",
      "|97553 |201901       |2345857960097.81|0.00      |2345857960097.81|100.00     |false         |\n",
      "+------+-------------+----------------+----------+----------------+-----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Impacto de contas n√£o classificadas:\n",
      "   Classificadas como 'OUTROS': -38.51% do ativo total\n",
      "   Sem classifica√ß√£o: -55.70% do ativo total\n",
      "\n",
      "üíæ Salvando valida√ß√£o em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/validacao/equacao_contabil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE CONCLU√çDO COM SUCESSO\n",
      "================================================================================\n",
      "In√≠cio:   2025-11-13 19:05:37\n",
      "Fim:      2025-11-13 19:32:06\n",
      "Dura√ß√£o:  0:26:28.505710\n",
      "================================================================================\n",
      "\n",
      "üìä ESTAT√çSTICAS FINAIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total de contas:       99,773,786\n",
      "   Classificadas N√≠vel 1: 45,804,684 (45.9%)\n",
      "   Classificadas N√≠vel 2: 45,804,684 (45.9%)\n",
      "\n",
      "üíæ Salvando resultado final em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Carregando resultado intermedi√°rio de: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/dicionarios\n",
      "‚úÖ Carregado: 99,773,786 registros\n",
      "\n",
      "================================================================================\n",
      "üìä AN√ÅLISE DOS RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Total de contas: 99,773,786\n",
      "‚úÖ Classificadas N√≠vel 1: 45,804,684 (45.9%)\n",
      "‚úÖ Classificadas N√≠vel 2: 45,804,684 (45.9%)\n",
      "‚úÖ Dura√ß√£o: 0:26:28.505710\n",
      "\n",
      "üìä Distribui√ß√£o de Classifica√ß√µes N√≠vel 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------+\n",
      "|classificacao_nivel_1_desc|   count|\n",
      "+--------------------------+--------+\n",
      "|                      NULL|53969102|\n",
      "|                     ATIVO|24308453|\n",
      "|                   PASSIVO|14421108|\n",
      "|                 RESULTADO| 7075123|\n",
      "+--------------------------+--------+\n",
      "\n",
      "\n",
      "üìä Top 10 Empresas (por n√∫mero de contas):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|id_ecd| count|\n",
      "+------+------+\n",
      "|432550|434099|\n",
      "|217595|336081|\n",
      "|217594|331894|\n",
      "|487536|330477|\n",
      "|487521|330474|\n",
      "|217593|326588|\n",
      "|217597|261948|\n",
      "|392704|221321|\n",
      "|259811|214478|\n",
      "|344332|179898|\n",
      "+------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìä Distribui√ß√£o por M√©todo de Classifica√ß√£o:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|metodo_classificacao|   count|\n",
      "+--------------------+--------+\n",
      "|          ESTRUTURAL|45316501|\n",
      "|          DICIONARIO|  488183|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Contas n√£o classificadas: 53,969,102 (54.1%)\n",
      "\n",
      "üìÇ Resultado salvo em: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/final\n",
      "‚úÖ Registros no arquivo: 99,773,786\n",
      "‚úÖ Colunas: 27\n",
      "\n",
      "üìä Distribui√ß√£o por origem (dados intermedi√°rios):\n",
      "+------+--------+\n",
      "|origem|   count|\n",
      "+------+--------+\n",
      "|    BP|77910062|\n",
      "|   DRE|21863724|\n",
      "+------+--------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ AN√ÅLISE CONCLU√çDA!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Executar pipeline completo\n",
    "resultado = main(spark)\n",
    "\n",
    "# Acessar resultados\n",
    "df_final = resultado['df_final']\n",
    "estatisticas = resultado['estatisticas']\n",
    "\n",
    "# Carregar etapa intermedi√°ria\n",
    "df = carregar_resultado_intermediario(spark, 'dicionarios')\n",
    "\n",
    "# ============================================================================\n",
    "# AN√ÅLISE DOS RESULTADOS (SEM REEXECUTAR O PIPELINE)\n",
    "# ============================================================================\n",
    "\n",
    "if resultado:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä AN√ÅLISE DOS RESULTADOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # J√° temos df_final e estatisticas carregados!\n",
    "    \n",
    "    # 1. Estat√≠sticas gerais\n",
    "    print(f\"\\n‚úÖ Total de contas: {estatisticas['total']:,}\")\n",
    "    print(f\"‚úÖ Classificadas N√≠vel 1: {estatisticas['classificadas_n1']:,} ({estatisticas['classificadas_n1']/estatisticas['total']*100:.1f}%)\")\n",
    "    print(f\"‚úÖ Classificadas N√≠vel 2: {estatisticas['classificadas_n2']:,} ({estatisticas['classificadas_n2']/estatisticas['total']*100:.1f}%)\")\n",
    "    print(f\"‚úÖ Dura√ß√£o: {estatisticas['duracao']}\")\n",
    "    \n",
    "    # 2. Distribui√ß√£o de classifica√ß√µes\n",
    "    print(\"\\nüìä Distribui√ß√£o de Classifica√ß√µes N√≠vel 1:\")\n",
    "    df_final.groupBy('classificacao_nivel_1_desc').count() \\\n",
    "        .orderBy('classificacao_nivel_1_desc').show()\n",
    "    \n",
    "    # 3. Top 10 empresas por n√∫mero de contas\n",
    "    print(\"\\nüìä Top 10 Empresas (por n√∫mero de contas):\")\n",
    "    df_final.groupBy('id_ecd').count() \\\n",
    "        .orderBy(desc('count')).show(10)\n",
    "    \n",
    "    # 4. M√©todos de classifica√ß√£o\n",
    "    print(\"\\nüìä Distribui√ß√£o por M√©todo de Classifica√ß√£o:\")\n",
    "    df_final.filter(col('metodo_classificacao').isNotNull()) \\\n",
    "        .groupBy('metodo_classificacao').count() \\\n",
    "        .orderBy(desc('count')).show()\n",
    "    \n",
    "    # 5. Contas n√£o classificadas\n",
    "    nao_class = df_final.filter(col('classificacao_nivel_1').isNull()).count()\n",
    "    print(f\"\\n‚ö†Ô∏è Contas n√£o classificadas: {nao_class:,} ({nao_class/estatisticas['total']*100:.1f}%)\")\n",
    "    \n",
    "    # 6. Verificar arquivo salvo\n",
    "    print(f\"\\nüìÇ Resultado salvo em: {PipelineConfig.PATH_FINAL}\")\n",
    "    df_salvo = spark.read.parquet(PipelineConfig.PATH_FINAL)\n",
    "    print(f\"‚úÖ Registros no arquivo: {df_salvo.count():,}\")\n",
    "    print(f\"‚úÖ Colunas: {len(df_salvo.columns)}\")\n",
    "    \n",
    "    # 7. Ver distribui√ß√£o por origem (do DataFrame intermedi√°rio 'df')\n",
    "    if 'origem' in df.columns:\n",
    "        print(\"\\nüìä Distribui√ß√£o por origem (dados intermedi√°rios):\")\n",
    "        df.groupBy('origem').count().orderBy('origem').show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ AN√ÅLISE CONCLU√çDA!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå Resultado n√£o dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2265cc5-6afe-47d6-9135-c19978d1fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ================================================================================\n",
      "    SCRIPT DE SALVAMENTO - RESULTADOS CLASSIFICA√á√ÉO ECD\n",
      "    ================================================================================\n",
      "    \n",
      "    Para executar:\n",
      "    \n",
      "    1. Ap√≥s executar o pipeline:\n",
      "       >>> exec(open('/mnt/user-data/outputs/salvar_resultados_hive.py').read())\n",
      "       >>> tabelas = salvar_todos_resultados(spark)\n",
      "    \n",
      "    2. Ver estat√≠sticas:\n",
      "       >>> mostrar_estatisticas_tabelas(spark)\n",
      "    \n",
      "    3. Consultar tabelas no Streamlit:\n",
      "       >>> df = spark.table('teste.ecd_ml_empresas_resumo')\n",
      "       >>> df.show()\n",
      "    \n",
      "    ================================================================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "SCRIPT DE SALVAMENTO - RESULTADOS CLASSIFICA√á√ÉO ECD\n",
    "================================================================================\n",
    "Salva resultados do pipeline em m√∫ltiplas tabelas Hive otimizadas para an√°lise\n",
    "e visualiza√ß√£o no Streamlit.\n",
    "\n",
    "Tabelas criadas:\n",
    "1. teste.ecd_ml_contas_classificadas       - Classifica√ß√£o detalhada de contas\n",
    "2. teste.ecd_ml_empresas_resumo            - Resumo por empresa\n",
    "3. teste.ecd_ml_validacao_equacao          - Valida√ß√£o da equa√ß√£o cont√°bil\n",
    "4. teste.ecd_ml_distribuicao_classes       - Distribui√ß√£o de classes cont√°beis\n",
    "5. teste.ecd_ml_contas_nao_classificadas   - An√°lise de contas n√£o classificadas\n",
    "\n",
    "Autor: Sistema de Classifica√ß√£o ECD - SEFAZ/SC\n",
    "Data: 2025-11-13\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, count, countDistinct, sum as spark_sum, avg, max as spark_max,\n",
    "    min as spark_min, round as spark_round, desc, lit, concat_ws, \n",
    "    current_timestamp, abs as spark_abs\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "SCHEMA_DESTINO = \"teste\"\n",
    "PREFIXO_TABELAS = \"ecd_ml\"\n",
    "\n",
    "# Caminhos dos resultados do pipeline\n",
    "PATH_FINAL = \"SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/final\"\n",
    "PATH_VALIDACAO = \"SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/validacao/equacao_contabil\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO 1: SALVAR CONTAS CLASSIFICADAS (DETALHE)\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_contas_classificadas(spark, df_final):\n",
    "    \"\"\"\n",
    "    Tabela principal com classifica√ß√£o detalhada de todas as contas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TABELA 1: ecd_ml_contas_classificadas\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    nome_tabela = f\"{SCHEMA_DESTINO}.{PREFIXO_TABELAS}_contas_classificadas\"\n",
    "    \n",
    "    # Preparar dados\n",
    "    df_output = df_final.select(\n",
    "        # Identifica√ß√£o\n",
    "        col('id_ecd'),\n",
    "        col('dt_referencia').alias('ano_mes_referencia'),\n",
    "        (col('dt_referencia') / 100).cast('int').alias('ano_referencia'),\n",
    "        \n",
    "        # Conta\n",
    "        col('cd_conta_anl').alias('codigo_conta'),\n",
    "        col('descr_cod_agl').alias('nome_conta'),\n",
    "        col('cd_conta_sint').alias('codigo_conta_sintetica'),\n",
    "        col('cd_natureza').alias('natureza_contabil'),\n",
    "        col('nivel').alias('nivel_hierarquico'),\n",
    "        col('tp_conta').alias('tipo_conta'),\n",
    "        \n",
    "        # Features extra√≠das\n",
    "        col('primeiro_digito'),\n",
    "        col('prefixo_2_chars'),\n",
    "        col('tem_ponto'),\n",
    "        col('comprimento_codigo'),\n",
    "        col('qtd_pontos'),\n",
    "        col('tem_letra'),\n",
    "        col('padrao_estrutural'),\n",
    "        \n",
    "        # Classifica√ß√£o\n",
    "        col('classificacao_nivel_1').alias('classe_nivel_1'),\n",
    "        col('classificacao_nivel_1_desc').alias('classe_nivel_1_descricao'),\n",
    "        col('classificacao_nivel_2').alias('classe_nivel_2'),\n",
    "        col('classificacao_final'),\n",
    "        col('metodo_classificacao'),\n",
    "        col('confianca_final').alias('confianca_classificacao'),\n",
    "        \n",
    "        # Faixa de confian√ßa\n",
    "        when(col('confianca_final') >= 0.95, 'MUITO_ALTA')\n",
    "        .when(col('confianca_final') >= 0.90, 'ALTA')\n",
    "        .when(col('confianca_final') >= 0.80, 'BOA')\n",
    "        .when(col('confianca_final') >= 0.70, 'MODERADA')\n",
    "        .otherwise('BAIXA')\n",
    "        .alias('faixa_confianca'),\n",
    "        \n",
    "        # Flag de classifica√ß√£o\n",
    "        when(col('classificacao_nivel_1').isNotNull(), 1).otherwise(0).alias('flag_classificada'),\n",
    "        \n",
    "        # Metadados\n",
    "        current_timestamp().alias('data_processamento')\n",
    "    )\n",
    "    \n",
    "    # Dropar tabela se existir\n",
    "    print(f\"\\nüóëÔ∏è  Removendo tabela antiga (se existir)...\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {nome_tabela} PURGE\")\n",
    "    \n",
    "    # Criar tabela particionada por ano\n",
    "    print(f\"üìù Criando tabela {nome_tabela}...\")\n",
    "    df_output.write \\\n",
    "        .mode('overwrite') \\\n",
    "        .partitionBy('ano_referencia') \\\n",
    "        .format('parquet') \\\n",
    "        .saveAsTable(nome_tabela)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    total = df_output.count()\n",
    "    classificadas = df_output.filter(col('flag_classificada') == 1).count()\n",
    "    \n",
    "    print(f\"‚úÖ Tabela criada com sucesso!\")\n",
    "    print(f\"   Total de registros: {total:,}\")\n",
    "    print(f\"   Classificadas: {classificadas:,} ({classificadas/total*100:.1f}%)\")\n",
    "    \n",
    "    # Mostrar sample\n",
    "    print(\"\\nüìã Sample dos dados:\")\n",
    "    spark.sql(f\"SELECT * FROM {nome_tabela} LIMIT 5\").show(truncate=False)\n",
    "    \n",
    "    return nome_tabela\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO 2: SALVAR RESUMO POR EMPRESA\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_empresas_resumo(spark, df_final):\n",
    "    \"\"\"\n",
    "    Resumo agregado por empresa com estat√≠sticas de classifica√ß√£o\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TABELA 2: ecd_ml_empresas_resumo\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    nome_tabela = f\"{SCHEMA_DESTINO}.{PREFIXO_TABELAS}_empresas_resumo\"\n",
    "    \n",
    "    # Agregar por empresa\n",
    "    df_resumo = df_final.groupBy('id_ecd', 'dt_referencia').agg(\n",
    "        # Contadores\n",
    "        count('*').alias('total_contas'),\n",
    "        countDistinct('cd_conta_anl').alias('contas_distintas'),\n",
    "        spark_sum(when(col('classificacao_nivel_1').isNotNull(), 1).otherwise(0)).alias('contas_classificadas'),\n",
    "        spark_sum(when(col('classificacao_nivel_1').isNull(), 1).otherwise(0)).alias('contas_nao_classificadas'),\n",
    "        \n",
    "        # Por classe\n",
    "        spark_sum(when(col('classificacao_nivel_1_desc') == 'ATIVO', 1).otherwise(0)).alias('total_ativo'),\n",
    "        spark_sum(when(col('classificacao_nivel_1_desc') == 'PASSIVO', 1).otherwise(0)).alias('total_passivo'),\n",
    "        spark_sum(when(col('classificacao_nivel_1_desc') == 'RESULTADO', 1).otherwise(0)).alias('total_resultado'),\n",
    "        \n",
    "        # Por m√©todo\n",
    "        spark_sum(when(col('metodo_classificacao') == 'ESTRUTURAL', 1).otherwise(0)).alias('class_estrutural'),\n",
    "        spark_sum(when(col('metodo_classificacao') == 'DICIONARIO', 1).otherwise(0)).alias('class_dicionario'),\n",
    "        \n",
    "        # Confian√ßa\n",
    "        avg('confianca_final').alias('confianca_media'),\n",
    "        spark_min('confianca_final').alias('confianca_minima'),\n",
    "        spark_max('confianca_final').alias('confianca_maxima'),\n",
    "        \n",
    "        # Por faixa de confian√ßa\n",
    "        spark_sum(when(col('confianca_final') >= 0.90, 1).otherwise(0)).alias('confianca_alta'),\n",
    "        spark_sum(when((col('confianca_final') >= 0.80) & (col('confianca_final') < 0.90), 1).otherwise(0)).alias('confianca_boa'),\n",
    "        spark_sum(when((col('confianca_final') >= 0.70) & (col('confianca_final') < 0.80), 1).otherwise(0)).alias('confianca_moderada'),\n",
    "        spark_sum(when(col('confianca_final') < 0.70, 1).otherwise(0)).alias('confianca_baixa'),\n",
    "        \n",
    "        # Padr√µes estruturais\n",
    "        countDistinct('padrao_estrutural').alias('qtd_padroes_distintos'),\n",
    "        countDistinct('primeiro_digito').alias('qtd_digitos_distintos'),\n",
    "        \n",
    "        # N√≠veis hier√°rquicos\n",
    "        spark_min('nivel').alias('nivel_minimo'),\n",
    "        spark_max('nivel').alias('nivel_maximo'),\n",
    "        avg('nivel').alias('nivel_medio')\n",
    "    )\n",
    "    \n",
    "    # Adicionar campos calculados\n",
    "    df_resumo = df_resumo.withColumn(\n",
    "        'taxa_classificacao',\n",
    "        spark_round((col('contas_classificadas') / col('total_contas')) * 100, 2)\n",
    "    ).withColumn(\n",
    "        'taxa_ativo',\n",
    "        spark_round((col('total_ativo') / col('contas_classificadas')) * 100, 2)\n",
    "    ).withColumn(\n",
    "        'taxa_passivo',\n",
    "        spark_round((col('total_passivo') / col('contas_classificadas')) * 100, 2)\n",
    "    ).withColumn(\n",
    "        'taxa_resultado',\n",
    "        spark_round((col('total_resultado') / col('contas_classificadas')) * 100, 2)\n",
    "    ).withColumn(\n",
    "        'ano_referencia',\n",
    "        (col('dt_referencia') / 100).cast('int')\n",
    "    ).withColumn(\n",
    "        'confianca_media',\n",
    "        spark_round('confianca_media', 4)\n",
    "    ).withColumn(\n",
    "        'confianca_minima',\n",
    "        spark_round('confianca_minima', 4)\n",
    "    ).withColumn(\n",
    "        'confianca_maxima',\n",
    "        spark_round('confianca_maxima', 4)\n",
    "    ).withColumn(\n",
    "        'nivel_medio',\n",
    "        spark_round('nivel_medio', 2)\n",
    "    ).withColumn(\n",
    "        # Qualidade geral da classifica√ß√£o\n",
    "        'qualidade_classificacao',\n",
    "        when(col('taxa_classificacao') >= 95, 'EXCELENTE')\n",
    "        .when(col('taxa_classificacao') >= 90, 'OTIMA')\n",
    "        .when(col('taxa_classificacao') >= 80, 'BOA')\n",
    "        .when(col('taxa_classificacao') >= 70, 'REGULAR')\n",
    "        .otherwise('RUIM')\n",
    "    ).withColumn(\n",
    "        'data_processamento',\n",
    "        current_timestamp()\n",
    "    )\n",
    "    \n",
    "    # Dropar e criar\n",
    "    print(f\"\\nüóëÔ∏è  Removendo tabela antiga (se existir)...\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {nome_tabela} PURGE\")\n",
    "    \n",
    "    print(f\"üìù Criando tabela {nome_tabela}...\")\n",
    "    df_resumo.write \\\n",
    "        .mode('overwrite') \\\n",
    "        .partitionBy('ano_referencia') \\\n",
    "        .format('parquet') \\\n",
    "        .saveAsTable(nome_tabela)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    total_empresas = df_resumo.count()\n",
    "    media_taxa = df_resumo.select(avg('taxa_classificacao')).collect()[0][0]\n",
    "    \n",
    "    print(f\"‚úÖ Tabela criada com sucesso!\")\n",
    "    print(f\"   Total de empresas: {total_empresas:,}\")\n",
    "    print(f\"   Taxa m√©dia de classifica√ß√£o: {media_taxa:.1f}%\")\n",
    "    \n",
    "    # Distribui√ß√£o de qualidade\n",
    "    print(\"\\nüìä Distribui√ß√£o de qualidade:\")\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            qualidade_classificacao,\n",
    "            COUNT(*) as empresas,\n",
    "            ROUND(AVG(taxa_classificacao), 2) as taxa_media\n",
    "        FROM {nome_tabela}\n",
    "        GROUP BY qualidade_classificacao\n",
    "        ORDER BY \n",
    "            CASE qualidade_classificacao\n",
    "                WHEN 'EXCELENTE' THEN 1\n",
    "                WHEN 'OTIMA' THEN 2\n",
    "                WHEN 'BOA' THEN 3\n",
    "                WHEN 'REGULAR' THEN 4\n",
    "                ELSE 5\n",
    "            END\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    return nome_tabela\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO 3: SALVAR VALIDA√á√ÉO DA EQUA√á√ÉO CONT√ÅBIL\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_validacao_equacao(spark):\n",
    "    \"\"\"\n",
    "    Resultados da valida√ß√£o da equa√ß√£o cont√°bil\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TABELA 3: ecd_ml_validacao_equacao\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    nome_tabela = f\"{SCHEMA_DESTINO}.{PREFIXO_TABELAS}_validacao_equacao\"\n",
    "    \n",
    "    # Carregar valida√ß√£o\n",
    "    try:\n",
    "        df_validacao = spark.read.parquet(PATH_VALIDACAO)\n",
    "        \n",
    "        # Adicionar campos calculados\n",
    "        df_output = df_validacao.withColumn(\n",
    "            'ano_referencia',\n",
    "            (col('dt_referencia') / 100).cast('int')\n",
    "        ).withColumn(\n",
    "            'percentual_diferenca',\n",
    "            spark_round(\n",
    "                (col('diferenca') / (spark_abs(col('total_ativo')) + 0.01)) * 100, \n",
    "                4\n",
    "            )\n",
    "        ).withColumn(\n",
    "            'status_equacao',\n",
    "            when(col('equacao_valida'), 'VALIDA').otherwise('INVALIDA')\n",
    "        ).withColumn(\n",
    "            'gravidade',\n",
    "            when(col('diferenca') <= 100, 'BAIXA')\n",
    "            .when(col('diferenca') <= 1000, 'MEDIA')\n",
    "            .when(col('diferenca') <= 10000, 'ALTA')\n",
    "            .otherwise('CRITICA')\n",
    "        ).withColumn(\n",
    "            'data_processamento',\n",
    "            current_timestamp()\n",
    "        )\n",
    "        \n",
    "        # Selecionar colunas\n",
    "        df_output = df_output.select(\n",
    "            'id_ecd',\n",
    "            'dt_referencia',\n",
    "            'ano_referencia',\n",
    "            'total_ativo',\n",
    "            'total_passivo',\n",
    "            'total_pl',\n",
    "            'passivo_pl_calculado',\n",
    "            'diferenca',\n",
    "            'percentual_diferenca',\n",
    "            'equacao_valida',\n",
    "            'status_equacao',\n",
    "            'gravidade',\n",
    "            'data_processamento'\n",
    "        )\n",
    "        \n",
    "        # Dropar e criar\n",
    "        print(f\"\\nüóëÔ∏è  Removendo tabela antiga (se existir)...\")\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {nome_tabela} PURGE\")\n",
    "        \n",
    "        print(f\"üìù Criando tabela {nome_tabela}...\")\n",
    "        df_output.write \\\n",
    "            .mode('overwrite') \\\n",
    "            .partitionBy('ano_referencia') \\\n",
    "            .format('parquet') \\\n",
    "            .saveAsTable(nome_tabela)\n",
    "        \n",
    "        # Estat√≠sticas\n",
    "        total = df_output.count()\n",
    "        validas = df_output.filter(col('equacao_valida')).count()\n",
    "        \n",
    "        print(f\"‚úÖ Tabela criada com sucesso!\")\n",
    "        print(f\"   Total de empresas: {total:,}\")\n",
    "        print(f\"   Equa√ß√£o v√°lida: {validas:,} ({validas/total*100:.1f}%)\")\n",
    "        \n",
    "        # Distribui√ß√£o por gravidade\n",
    "        print(\"\\nüìä Distribui√ß√£o por gravidade (inv√°lidas):\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                gravidade,\n",
    "                COUNT(*) as empresas,\n",
    "                ROUND(AVG(diferenca), 2) as diferenca_media,\n",
    "                ROUND(AVG(percentual_diferenca), 2) as percentual_medio\n",
    "            FROM {nome_tabela}\n",
    "            WHERE NOT equacao_valida\n",
    "            GROUP BY gravidade\n",
    "            ORDER BY \n",
    "                CASE gravidade\n",
    "                    WHEN 'CRITICA' THEN 1\n",
    "                    WHEN 'ALTA' THEN 2\n",
    "                    WHEN 'MEDIA' THEN 3\n",
    "                    ELSE 4\n",
    "                END\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        return nome_tabela\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao processar valida√ß√£o: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO 4: SALVAR DISTRIBUI√á√ÉO DE CLASSES\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_distribuicao_classes(spark, df_final):\n",
    "    \"\"\"\n",
    "    Distribui√ß√£o de classes cont√°beis para an√°lise visual\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TABELA 4: ecd_ml_distribuicao_classes\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    nome_tabela = f\"{SCHEMA_DESTINO}.{PREFIXO_TABELAS}_distribuicao_classes\"\n",
    "    \n",
    "    # Agregar por empresa e classe\n",
    "    df_dist = df_final.filter(col('classificacao_nivel_1').isNotNull()) \\\n",
    "        .groupBy(\n",
    "            'id_ecd',\n",
    "            'dt_referencia',\n",
    "            'classificacao_nivel_1_desc',\n",
    "            'classificacao_nivel_2'\n",
    "        ).agg(\n",
    "            count('*').alias('quantidade_contas'),\n",
    "            avg('confianca_final').alias('confianca_media'),\n",
    "            countDistinct('padrao_estrutural').alias('qtd_padroes'),\n",
    "            countDistinct('primeiro_digito').alias('qtd_digitos')\n",
    "        )\n",
    "    \n",
    "    # Adicionar ano e percentuais\n",
    "    df_dist = df_dist.withColumn(\n",
    "        'ano_referencia',\n",
    "        (col('dt_referencia') / 100).cast('int')\n",
    "    ).withColumn(\n",
    "        'confianca_media',\n",
    "        spark_round('confianca_media', 4)\n",
    "    ).withColumn(\n",
    "        'data_processamento',\n",
    "        current_timestamp()\n",
    "    )\n",
    "    \n",
    "    # Dropar e criar\n",
    "    print(f\"\\nüóëÔ∏è  Removendo tabela antiga (se existir)...\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {nome_tabela} PURGE\")\n",
    "    \n",
    "    print(f\"üìù Criando tabela {nome_tabela}...\")\n",
    "    df_dist.write \\\n",
    "        .mode('overwrite') \\\n",
    "        .partitionBy('ano_referencia', 'classificacao_nivel_1_desc') \\\n",
    "        .format('parquet') \\\n",
    "        .saveAsTable(nome_tabela)\n",
    "    \n",
    "    print(f\"‚úÖ Tabela criada com sucesso!\")\n",
    "    print(f\"   Total de registros: {df_dist.count():,}\")\n",
    "    \n",
    "    # Top 10 classifica√ß√µes\n",
    "    print(\"\\nüìä Top 10 combina√ß√µes mais frequentes:\")\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            classificacao_nivel_1_desc,\n",
    "            classificacao_nivel_2,\n",
    "            SUM(quantidade_contas) as total_contas,\n",
    "            ROUND(AVG(confianca_media), 3) as confianca\n",
    "        FROM {nome_tabela}\n",
    "        GROUP BY classificacao_nivel_1_desc, classificacao_nivel_2\n",
    "        ORDER BY total_contas DESC\n",
    "        LIMIT 10\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    return nome_tabela\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO 5: SALVAR CONTAS N√ÉO CLASSIFICADAS\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_contas_nao_classificadas(spark, df_final):\n",
    "    \"\"\"\n",
    "    An√°lise detalhada das contas que n√£o foram classificadas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TABELA 5: ecd_ml_contas_nao_classificadas\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    nome_tabela = f\"{SCHEMA_DESTINO}.{PREFIXO_TABELAS}_contas_nao_classificadas\"\n",
    "    \n",
    "    # Filtrar n√£o classificadas\n",
    "    df_nao_class = df_final.filter(col('classificacao_nivel_1').isNull())\n",
    "    \n",
    "    # Agregar por padr√£o\n",
    "    df_analise = df_nao_class.groupBy(\n",
    "        'dt_referencia',\n",
    "        'primeiro_digito',\n",
    "        'padrao_estrutural',\n",
    "        'cd_natureza',\n",
    "        'tem_ponto',\n",
    "        'tem_letra'\n",
    "    ).agg(\n",
    "        count('*').alias('quantidade'),\n",
    "        countDistinct('id_ecd').alias('empresas_afetadas'),\n",
    "        avg('comprimento_codigo').alias('comprimento_medio'),\n",
    "        avg('qtd_pontos').alias('pontos_medio')\n",
    "    )\n",
    "    \n",
    "    # Adicionar campos\n",
    "    df_analise = df_analise.withColumn(\n",
    "        'ano_referencia',\n",
    "        (col('dt_referencia') / 100).cast('int')\n",
    "    ).withColumn(\n",
    "        'comprimento_medio',\n",
    "        spark_round('comprimento_medio', 2)\n",
    "    ).withColumn(\n",
    "        'pontos_medio',\n",
    "        spark_round('pontos_medio', 2)\n",
    "    ).withColumn(\n",
    "        'tipo_problema',\n",
    "        when(col('primeiro_digito').isin(['0', '4', '5', '6', '7', '8', '9']), 'CODIGO_NAO_PADRONIZADO')\n",
    "        .when(col('tem_letra') == 1, 'CODIGO_COM_LETRA')\n",
    "        .otherwise('OUTRO')\n",
    "    ).withColumn(\n",
    "        'data_processamento',\n",
    "        current_timestamp()\n",
    "    )\n",
    "    \n",
    "    # Dropar e criar\n",
    "    print(f\"\\nüóëÔ∏è  Removendo tabela antiga (se existir)...\")\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {nome_tabela} PURGE\")\n",
    "    \n",
    "    print(f\"üìù Criando tabela {nome_tabela}...\")\n",
    "    df_analise.write \\\n",
    "        .mode('overwrite') \\\n",
    "        .partitionBy('ano_referencia') \\\n",
    "        .format('parquet') \\\n",
    "        .saveAsTable(nome_tabela)\n",
    "    \n",
    "    total_nao_class = df_nao_class.count()\n",
    "    print(f\"‚úÖ Tabela criada com sucesso!\")\n",
    "    print(f\"   Total de contas n√£o classificadas: {total_nao_class:,}\")\n",
    "    \n",
    "    # Distribui√ß√£o por tipo\n",
    "    print(\"\\nüìä Distribui√ß√£o por tipo de problema:\")\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            tipo_problema,\n",
    "            SUM(quantidade) as total_contas,\n",
    "            SUM(empresas_afetadas) as total_empresas\n",
    "        FROM {nome_tabela}\n",
    "        GROUP BY tipo_problema\n",
    "        ORDER BY total_contas DESC\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    # Top padr√µes problem√°ticos\n",
    "    print(\"\\nüìä Top 10 padr√µes n√£o classificados:\")\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            primeiro_digito,\n",
    "            padrao_estrutural,\n",
    "            cd_natureza,\n",
    "            SUM(quantidade) as total\n",
    "        FROM {nome_tabela}\n",
    "        GROUP BY primeiro_digito, padrao_estrutural, cd_natureza\n",
    "        ORDER BY total DESC\n",
    "        LIMIT 10\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    return nome_tabela\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO PRINCIPAL: SALVAR TODOS OS RESULTADOS\n",
    "# ============================================================================\n",
    "\n",
    "def salvar_todos_resultados(spark):\n",
    "    \"\"\"\n",
    "    Salva todos os resultados em tabelas Hive\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üíæ SALVAMENTO DE RESULTADOS EM TABELAS HIVE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Schema: {SCHEMA_DESTINO}\")\n",
    "    print(f\"Prefixo: {PREFIXO_TABELAS}_*\")\n",
    "    print(f\"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    inicio = datetime.now()\n",
    "    tabelas_criadas = []\n",
    "    \n",
    "    try:\n",
    "        # Carregar resultado final\n",
    "        print(f\"\\nüì• Carregando resultados do pipeline...\")\n",
    "        print(f\"   Path: {PATH_FINAL}\")\n",
    "        df_final = spark.read.parquet(PATH_FINAL)\n",
    "        print(f\"‚úÖ Carregado: {df_final.count():,} registros\")\n",
    "        \n",
    "        # 1. Contas classificadas (detalhe)\n",
    "        tabela = salvar_contas_classificadas(spark, df_final)\n",
    "        tabelas_criadas.append(tabela)\n",
    "        \n",
    "        # 2. Resumo por empresa\n",
    "        tabela = salvar_empresas_resumo(spark, df_final)\n",
    "        tabelas_criadas.append(tabela)\n",
    "        \n",
    "        # 3. Valida√ß√£o equa√ß√£o\n",
    "        tabela = salvar_validacao_equacao(spark)\n",
    "        if tabela:\n",
    "            tabelas_criadas.append(tabela)\n",
    "        \n",
    "        # 4. Distribui√ß√£o de classes\n",
    "        tabela = salvar_distribuicao_classes(spark, df_final)\n",
    "        tabelas_criadas.append(tabela)\n",
    "        \n",
    "        # 5. Contas n√£o classificadas\n",
    "        tabela = salvar_contas_nao_classificadas(spark, df_final)\n",
    "        tabelas_criadas.append(tabela)\n",
    "        \n",
    "        # Relat√≥rio final\n",
    "        fim = datetime.now()\n",
    "        duracao = fim - inicio\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ SALVAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Tempo total: {duracao}\")\n",
    "        print(f\"\\nüìä TABELAS CRIADAS ({len(tabelas_criadas)}):\")\n",
    "        for i, tabela in enumerate(tabelas_criadas, 1):\n",
    "            print(f\"   {i}. {tabela}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üéØ PR√ìXIMOS PASSOS:\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\"\"\n",
    "        1. Remover LIMITE_REGISTROS para processar popula√ß√£o completa:\n",
    "           PipelineConfig.LIMITE_REGISTROS = None\n",
    "        \n",
    "        2. Executar pipeline completo (945M registros, 73.335 empresas)\n",
    "        \n",
    "        3. Visualizar no Streamlit usando as tabelas:\n",
    "           - teste.ecd_ml_contas_classificadas\n",
    "           - teste.ecd_ml_empresas_resumo\n",
    "           - teste.ecd_ml_validacao_equacao\n",
    "           - teste.ecd_ml_distribuicao_classes\n",
    "           - teste.ecd_ml_contas_nao_classificadas\n",
    "        \n",
    "        4. Queries √∫teis para Streamlit:\n",
    "        \n",
    "           # Empresas com melhor classifica√ß√£o\n",
    "           SELECT * FROM teste.ecd_ml_empresas_resumo \n",
    "           WHERE qualidade_classificacao = 'EXCELENTE'\n",
    "           ORDER BY taxa_classificacao DESC\n",
    "           \n",
    "           # Distribui√ß√£o de classes\n",
    "           SELECT \n",
    "               classificacao_nivel_1_desc,\n",
    "               SUM(quantidade_contas) as total\n",
    "           FROM teste.ecd_ml_distribuicao_classes\n",
    "           GROUP BY classificacao_nivel_1_desc\n",
    "           \n",
    "           # Empresas com equa√ß√£o inv√°lida\n",
    "           SELECT * FROM teste.ecd_ml_validacao_equacao\n",
    "           WHERE NOT equacao_valida\n",
    "           ORDER BY diferenca DESC\n",
    "        \"\"\")\n",
    "        \n",
    "        return tabelas_criadas\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUN√á√ÉO AUXILIAR: ESTAT√çSTICAS DAS TABELAS\n",
    "# ============================================================================\n",
    "\n",
    "def mostrar_estatisticas_tabelas(spark):\n",
    "    \"\"\"\n",
    "    Mostra estat√≠sticas das tabelas criadas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä ESTAT√çSTICAS DAS TABELAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    tabelas = [\n",
    "        'ecd_ml_contas_classificadas',\n",
    "        'ecd_ml_empresas_resumo',\n",
    "        'ecd_ml_validacao_equacao',\n",
    "        'ecd_ml_distribuicao_classes',\n",
    "        'ecd_ml_contas_nao_classificadas'\n",
    "    ]\n",
    "    \n",
    "    for tabela in tabelas:\n",
    "        nome_completo = f\"{SCHEMA_DESTINO}.{tabela}\"\n",
    "        try:\n",
    "            df = spark.table(nome_completo)\n",
    "            total = df.count()\n",
    "            colunas = len(df.columns)\n",
    "            \n",
    "            print(f\"\\nüìã {tabela}\")\n",
    "            print(f\"   Registros: {total:,}\")\n",
    "            print(f\"   Colunas: {colunas}\")\n",
    "            print(f\"   Parti√ß√µes: {df.rdd.getNumPartitions()}\")\n",
    "            \n",
    "            # Mostrar schema resumido\n",
    "            print(f\"   Schema: {', '.join(df.columns[:10])}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  {tabela}: {str(e)}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXECU√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\"\"\n",
    "    ================================================================================\n",
    "    SCRIPT DE SALVAMENTO - RESULTADOS CLASSIFICA√á√ÉO ECD\n",
    "    ================================================================================\n",
    "    \n",
    "    Para executar:\n",
    "    \n",
    "    1. Ap√≥s executar o pipeline:\n",
    "       >>> exec(open('/mnt/user-data/outputs/salvar_resultados_hive.py').read())\n",
    "       >>> tabelas = salvar_todos_resultados(spark)\n",
    "    \n",
    "    2. Ver estat√≠sticas:\n",
    "       >>> mostrar_estatisticas_tabelas(spark)\n",
    "    \n",
    "    3. Consultar tabelas no Streamlit:\n",
    "       >>> df = spark.table('teste.ecd_ml_empresas_resumo')\n",
    "       >>> df.show()\n",
    "    \n",
    "    ================================================================================\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d61657-c9fd-42fe-8a15-b6d4dfcc5f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üíæ SALVAMENTO DE RESULTADOS EM TABELAS HIVE\n",
      "================================================================================\n",
      "Schema: teste\n",
      "Prefixo: ecd_ml_*\n",
      "Data: 2025-11-13 19:38:12\n",
      "================================================================================\n",
      "\n",
      "üì• Carregando resultados do pipeline...\n",
      "   Path: SAT_BIG_DATA/data-pipeline/batch/poc/tsevero/final\n",
      "‚úÖ Carregado: 99,773,786 registros\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA 1: ecd_ml_contas_classificadas\n",
      "================================================================================\n",
      "\n",
      "üóëÔ∏è  Removendo tabela antiga (se existir)...\n",
      "üìù Criando tabela teste.ecd_ml_contas_classificadas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela criada com sucesso!\n",
      "   Total de registros: 99,773,786\n",
      "   Classificadas: 45,804,684 (45.9%)\n",
      "\n",
      "üìã Sample dos dados:\n",
      "+------+------------------+------------------+----------------------------+----------------------+-----------------+-----------------+----------+---------------+---------------+---------+------------------+----------+---------+-----------------+--------------+------------------------+--------------+-------------------+--------------------+-----------------------+---------------+-----------------+--------------------------+--------------+\n",
      "|id_ecd|ano_mes_referencia|codigo_conta      |nome_conta                  |codigo_conta_sintetica|natureza_contabil|nivel_hierarquico|tipo_conta|primeiro_digito|prefixo_2_chars|tem_ponto|comprimento_codigo|qtd_pontos|tem_letra|padrao_estrutural|classe_nivel_1|classe_nivel_1_descricao|classe_nivel_2|classificacao_final|metodo_classificacao|confianca_classificacao|faixa_confianca|flag_classificada|data_processamento        |ano_referencia|\n",
      "+------+------------------+------------------+----------------------------+----------------------+-----------------+-----------------+----------+---------------+---------------+---------+------------------+----------+---------+-----------------+--------------+------------------------+--------------+-------------------+--------------------+-----------------------+---------------+-----------------+--------------------------+--------------+\n",
      "|102500|202201            |DRE10             |Outras Despesas Operacionais|DRE0                  |D                |4                |A         |               |DR             |0        |5                 |0         |1        |PREFIXO_DRE      |NULL          |NULL                    |NULL          |NULL               |NULL                |0.0                    |BAIXA          |0                |2025-11-13 19:38:13.364519|2022          |\n",
      "|102537|202201            |BAL1.2.1.1-1023   |VALORES EXIGIVEIS           |BAL1.2.1-1015         |C                |3                |A         |               |BA             |1        |15                |3         |1        |OUTRO            |NULL          |NULL                    |NULL          |NULL               |NULL                |0.0                    |BAIXA          |0                |2025-11-13 19:38:13.364519|2022          |\n",
      "|102537|202201            |BAL1.2.1.1.03-1074|OUTROS EMPRESTIMOS          |BAL1.2.1.1-1023       |C                |4                |A         |               |BA             |1        |18                |4         |1        |OUTRO            |NULL          |NULL                    |NULL          |NULL               |NULL                |0.0                    |BAIXA          |0                |2025-11-13 19:38:13.364519|2022          |\n",
      "|102544|202201            |BP 1162           |MUTUOS PARTES RELACIONADAS  |BP 116                |C                |4                |A         |               |BP             |0        |7                 |0         |1        |PREFIXO_BP       |NULL          |NULL                    |NULL          |NULL               |NULL                |0.0                    |BAIXA          |0                |2025-11-13 19:38:13.364519|2022          |\n",
      "|102544|202201            |DRE3              |RECEITA OPERACIONAL LIQUIDA |DRE5                  |C                |5                |A         |               |DR             |0        |4                 |0         |1        |PREFIXO_DRE      |NULL          |NULL                    |NULL          |NULL               |NULL                |0.0                    |BAIXA          |0                |2025-11-13 19:38:13.364519|2022          |\n",
      "+------+------------------+------------------+----------------------------+----------------------+-----------------+-----------------+----------+---------------+---------------+---------+------------------+----------+---------+-----------------+--------------+------------------------+--------------+-------------------+--------------------+-----------------------+---------------+-----------------+--------------------------+--------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA 2: ecd_ml_empresas_resumo\n",
      "================================================================================\n",
      "\n",
      "üóëÔ∏è  Removendo tabela antiga (se existir)...\n",
      "üìù Criando tabela teste.ecd_ml_empresas_resumo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela criada com sucesso!\n",
      "   Total de empresas: 384,515\n",
      "   Taxa m√©dia de classifica√ß√£o: 50.3%\n",
      "\n",
      "üìä Distribui√ß√£o de qualidade:\n",
      "+-----------------------+--------+----------+\n",
      "|qualidade_classificacao|empresas|taxa_media|\n",
      "+-----------------------+--------+----------+\n",
      "|EXCELENTE              |28800   |99.42     |\n",
      "|OTIMA                  |9627    |92.32     |\n",
      "|BOA                    |31127   |84.41     |\n",
      "|REGULAR                |56836   |74.43     |\n",
      "|RUIM                   |258125  |33.83     |\n",
      "+-----------------------+--------+----------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA 3: ecd_ml_validacao_equacao\n",
      "================================================================================\n",
      "\n",
      "üóëÔ∏è  Removendo tabela antiga (se existir)...\n",
      "üìù Criando tabela teste.ecd_ml_validacao_equacao...\n",
      "‚úÖ Tabela criada com sucesso!\n",
      "   Total de empresas: 379,007\n",
      "   Equa√ß√£o v√°lida: 82,821 (21.9%)\n",
      "\n",
      "üìä Distribui√ß√£o por gravidade (inv√°lidas):\n",
      "+---------+--------+---------------+----------------+\n",
      "|gravidade|empresas|diferenca_media|percentual_medio|\n",
      "+---------+--------+---------------+----------------+\n",
      "|CRITICA  |276895  |417974695.40   |2972.37         |\n",
      "|ALTA     |14828   |4563.60        |422.38          |\n",
      "|MEDIA    |4463    |505.93         |111.91          |\n",
      "+---------+--------+---------------+----------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA 4: ecd_ml_distribuicao_classes\n",
      "================================================================================\n",
      "\n",
      "üóëÔ∏è  Removendo tabela antiga (se existir)...\n",
      "üìù Criando tabela teste.ecd_ml_distribuicao_classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela criada com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total de registros: 1,206,598\n",
      "\n",
      "üìä Top 10 combina√ß√µes mais frequentes:\n",
      "+--------------------------+---------------------+------------+---------+\n",
      "|classificacao_nivel_1_desc|classificacao_nivel_2|total_contas|confianca|\n",
      "+--------------------------+---------------------+------------+---------+\n",
      "|ATIVO                     |1.0                  |21809053    |0.734    |\n",
      "|PASSIVO                   |2.0                  |13108673    |0.786    |\n",
      "|RESULTADO                 |3.0                  |7054066     |0.548    |\n",
      "|ATIVO                     |1.01                 |1520498     |0.797    |\n",
      "|PASSIVO                   |2.01                 |876119      |0.797    |\n",
      "|ATIVO                     |1.02                 |548446      |0.796    |\n",
      "|ATIVO                     |1.02.01              |348150      |0.75     |\n",
      "|PASSIVO                   |2.02                 |235869      |0.798    |\n",
      "|PASSIVO                   |2.03                 |163777      |0.779    |\n",
      "|ATIVO                     |1.02.03              |36318       |0.75     |\n",
      "+--------------------------+---------------------+------------+---------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA 5: ecd_ml_contas_nao_classificadas\n",
      "================================================================================\n",
      "\n",
      "üóëÔ∏è  Removendo tabela antiga (se existir)...\n",
      "üìù Criando tabela teste.ecd_ml_contas_nao_classificadas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela criada com sucesso!\n",
      "   Total de contas n√£o classificadas: 53,969,102\n",
      "\n",
      "üìä Distribui√ß√£o por tipo de problema:\n",
      "+----------------------+------------+--------------+\n",
      "|tipo_problema         |total_contas|total_empresas|\n",
      "+----------------------+------------+--------------+\n",
      "|CODIGO_COM_LETRA      |33908461    |689231        |\n",
      "|CODIGO_NAO_PADRONIZADO|20058616    |1516472       |\n",
      "|OUTRO                 |2025        |166           |\n",
      "+----------------------+------------+--------------+\n",
      "\n",
      "\n",
      "üìä Top 10 padr√µes n√£o classificados:\n",
      "+---------------+-----------------+-----------+--------+\n",
      "|primeiro_digito|padrao_estrutural|cd_natureza|total   |\n",
      "+---------------+-----------------+-----------+--------+\n",
      "|               |PREFIXO_BP       |D          |15319668|\n",
      "|               |PREFIXO_BP       |C          |7775744 |\n",
      "|               |PREFIXO_DRE      |D          |4758185 |\n",
      "|4              |SOMENTE_NUMEROS  |D          |2230445 |\n",
      "|               |OUTRO            |C          |2211743 |\n",
      "|5              |SOMENTE_NUMEROS  |D          |2199987 |\n",
      "|               |OUTRO            |D          |1994981 |\n",
      "|               |PREFIXO_DRE      |C          |1850165 |\n",
      "|5              |SOMENTE_NUMEROS  |C          |1676763 |\n",
      "|6              |SOMENTE_NUMEROS  |D          |1430718 |\n",
      "+---------------+-----------------+-----------+--------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SALVAMENTO CONCLU√çDO COM SUCESSO!\n",
      "================================================================================\n",
      "Tempo total: 0:01:32.663334\n",
      "\n",
      "üìä TABELAS CRIADAS (5):\n",
      "   1. teste.ecd_ml_contas_classificadas\n",
      "   2. teste.ecd_ml_empresas_resumo\n",
      "   3. teste.ecd_ml_validacao_equacao\n",
      "   4. teste.ecd_ml_distribuicao_classes\n",
      "   5. teste.ecd_ml_contas_nao_classificadas\n",
      "\n",
      "================================================================================\n",
      "üéØ PR√ìXIMOS PASSOS:\n",
      "================================================================================\n",
      "\n",
      "        1. Remover LIMITE_REGISTROS para processar popula√ß√£o completa:\n",
      "           PipelineConfig.LIMITE_REGISTROS = None\n",
      "        \n",
      "        2. Executar pipeline completo (945M registros, 73.335 empresas)\n",
      "        \n",
      "        3. Visualizar no Streamlit usando as tabelas:\n",
      "           - teste.ecd_ml_contas_classificadas\n",
      "           - teste.ecd_ml_empresas_resumo\n",
      "           - teste.ecd_ml_validacao_equacao\n",
      "           - teste.ecd_ml_distribuicao_classes\n",
      "           - teste.ecd_ml_contas_nao_classificadas\n",
      "        \n",
      "        4. Queries √∫teis para Streamlit:\n",
      "        \n",
      "           # Empresas com melhor classifica√ß√£o\n",
      "           SELECT * FROM teste.ecd_ml_empresas_resumo \n",
      "           WHERE qualidade_classificacao = 'EXCELENTE'\n",
      "           ORDER BY taxa_classificacao DESC\n",
      "           \n",
      "           # Distribui√ß√£o de classes\n",
      "           SELECT \n",
      "               classificacao_nivel_1_desc,\n",
      "               SUM(quantidade_contas) as total\n",
      "           FROM teste.ecd_ml_distribuicao_classes\n",
      "           GROUP BY classificacao_nivel_1_desc\n",
      "           \n",
      "           # Empresas com equa√ß√£o inv√°lida\n",
      "           SELECT * FROM teste.ecd_ml_validacao_equacao\n",
      "           WHERE NOT equacao_valida\n",
      "           ORDER BY diferenca DESC\n",
      "        \n",
      "\n",
      "================================================================================\n",
      "üìä ESTAT√çSTICAS DAS TABELAS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã ecd_ml_contas_classificadas\n",
      "   Registros: 99,773,786\n",
      "   Colunas: 25\n",
      "   Parti√ß√µes: 36\n",
      "   Schema: id_ecd, ano_mes_referencia, codigo_conta, nome_conta, codigo_conta_sintetica, natureza_contabil, nivel_hierarquico, tipo_conta, primeiro_digito, prefixo_2_chars...\n",
      "\n",
      "üìã ecd_ml_empresas_resumo\n",
      "   Registros: 384,515\n",
      "   Colunas: 30\n",
      "   Parti√ß√µes: 25\n",
      "   Schema: id_ecd, dt_referencia, total_contas, contas_distintas, contas_classificadas, contas_nao_classificadas, total_ativo, total_passivo, total_resultado, class_estrutural...\n",
      "\n",
      "üìã ecd_ml_validacao_equacao\n",
      "   Registros: 379,007\n",
      "   Colunas: 13\n",
      "   Parti√ß√µes: 25\n",
      "   Schema: id_ecd, dt_referencia, total_ativo, total_passivo, total_pl, passivo_pl_calculado, diferenca, percentual_diferenca, equacao_valida, status_equacao...\n",
      "\n",
      "üìã ecd_ml_distribuicao_classes\n",
      "   Registros: 1,206,598\n",
      "   Colunas: 10\n",
      "   Parti√ß√µes: 28\n",
      "   Schema: id_ecd, dt_referencia, classificacao_nivel_2, quantidade_contas, confianca_media, qtd_padroes, qtd_digitos, data_processamento, ano_referencia, classificacao_nivel_1_desc...\n",
      "\n",
      "üìã ecd_ml_contas_nao_classificadas\n",
      "   Registros: 4,467\n",
      "   Colunas: 13\n",
      "   Parti√ß√µes: 12\n",
      "   Schema: dt_referencia, primeiro_digito, padrao_estrutural, cd_natureza, tem_ponto, tem_letra, quantidade, empresas_afetadas, comprimento_medio, pontos_medio...\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------+--------------+\n",
      "|id_ecd|dt_referencia|total_contas|contas_distintas|contas_classificadas|contas_nao_classificadas|total_ativo|total_passivo|total_resultado|class_estrutural|class_dicionario|confianca_media|confianca_minima|confianca_maxima|confianca_alta|confianca_boa|confianca_moderada|confianca_baixa|qtd_padroes_distintos|qtd_digitos_distintos|nivel_minimo|nivel_maximo|nivel_medio|taxa_classificacao|taxa_ativo|taxa_passivo|taxa_resultado|qualidade_classificacao|  data_processamento|ano_referencia|\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------+--------------+\n",
      "|156397|       202201|         116|             116|                   7|                     109|          7|            0|              0|               0|               7|         0.0453|             0.0|            0.75|             0|            0|                 7|            109|                    2|                    1|           1|           6|       4.59|              6.03|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|168294|       202201|         418|             418|                   2|                     416|          1|            1|              0|               0|               2|         0.0036|             0.0|            0.75|             0|            0|                 2|            416|                    2|                    1|           1|           6|       4.88|              0.48|      50.0|        50.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|278441|       202201|        1113|            1113|                  36|                    1077|         36|            0|              0|               0|              36|         0.0243|             0.0|            0.75|             0|            0|                36|           1077|                    2|                    1|           1|           6|       4.99|              3.23|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|160014|       202201|         174|             174|                   4|                     170|          4|            0|              0|               0|               4|         0.0172|             0.0|            0.75|             0|            0|                 4|            170|                    2|                    1|           1|           6|       4.72|               2.3|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|287392|       202201|         109|             109|                  57|                      52|         24|           23|             10|              57|               0|         0.3083|             0.0|             0.8|             0|           42|                 0|             67|                    3|                    3|           1|           5|        3.5|             52.29|     42.11|       40.35|         17.54|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|307830|       202201|        1400|            1400|                 390|                    1010|         47|           27|            316|             389|               1|         0.2228|             0.0|             0.8|             0|          389|                 1|           1010|                    2|                    6|           1|          13|        6.9|             27.86|     12.05|        6.92|         81.03|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|310295|       202210|       26937|           26937|                  18|                   26919|         17|            1|              0|               0|              18|         5.0E-4|             0.0|            0.75|             0|            0|                18|          26919|                    2|                    1|           1|           6|        5.0|              0.07|     94.44|        5.56|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|435272|       202201|         247|             247|                  81|                     166|         70|           11|              0|              67|              14|         0.2595|             0.0|             0.8|             0|           67|                14|            166|                    2|                    8|           1|           9|       6.17|             32.79|     86.42|       13.58|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|473992|       202201|          61|              61|                   0|                      61|          0|            0|              0|               0|               0|            0.0|             0.0|             0.0|             0|            0|                 0|             61|                    2|                    1|           1|           6|       4.21|               0.0|      NULL|        NULL|          NULL|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|384866|       202201|        2722|            2722|                  24|                    2698|         22|            2|              0|               0|              24|         0.0066|             0.0|            0.75|             0|            0|                24|           2698|                    2|                    1|           1|           6|        5.0|              0.88|     91.67|        8.33|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|192986|       202201|         281|             281|                   1|                     280|          1|            0|              0|               0|               1|         0.0027|             0.0|            0.75|             0|            0|                 1|            280|                    2|                    1|           1|           6|       4.84|              0.36|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|194645|       202201|         312|             312|                   4|                     308|          3|            0|              1|               0|               4|         0.0096|             0.0|            0.75|             0|            0|                 4|            308|                    2|                    1|           1|           6|        4.8|              1.28|      75.0|         0.0|          25.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|483253|       202201|         131|             131|                   2|                     129|          0|            2|              0|               0|               2|         0.0115|             0.0|            0.75|             0|            0|                 2|            129|                    2|                    1|           1|           6|       4.57|              1.53|       0.0|       100.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|200833|       202201|         482|             482|                  12|                     470|         12|            0|              0|               0|              12|         0.0187|             0.0|            0.75|             0|            0|                12|            470|                    2|                    1|           1|          10|        5.4|              2.49|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|212450|       202201|         765|             765|                   6|                     759|          5|            1|              0|               0|               6|         0.0059|             0.0|            0.75|             0|            0|                 6|            759|                    2|                    1|           1|           6|       4.99|              0.78|     83.33|       16.67|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|252189|       202201|          34|              34|                  28|                       6|         14|           12|              2|              28|               0|         0.4941|             0.0|             0.8|             0|           21|                 0|             13|                    3|                    3|           1|           5|       3.06|             82.35|      50.0|       42.86|          7.14|                    BOA|2025-11-13 19:38:...|          2022|\n",
      "|245809|       202201|         109|             109|                  30|                      79|         17|            8|              5|              30|               0|         0.2202|             0.0|             0.8|             0|           30|                 0|             79|                    2|                    7|           1|          13|       5.53|             27.52|     56.67|       26.67|         16.67|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|486436|       202201|          77|              77|                  57|                      20|         29|           22|              6|              57|               0|         0.4364|             0.0|             0.8|             0|           42|                 0|             35|                    3|                    3|           1|           4|       3.38|             74.03|     50.88|        38.6|         10.53|                REGULAR|2025-11-13 19:38:...|          2022|\n",
      "|172286|       202201|        1462|            1462|                   0|                    1462|          0|            0|              0|               0|               0|            0.0|             0.0|             0.0|             0|            0|                 0|           1462|                    2|                    1|           1|          13|       5.06|               0.0|      NULL|        NULL|          NULL|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "|278112|       202201|         387|             387|                   1|                     386|          1|            0|              0|               0|               1|         0.0019|             0.0|            0.75|             0|            0|                 1|            386|                    2|                    1|           1|          12|       5.63|              0.26|     100.0|         0.0|           0.0|                   RUIM|2025-11-13 19:38:...|          2022|\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Salvar em tabelas Hive\n",
    "tabelas = salvar_todos_resultados(spark)\n",
    "\n",
    "# 5. Validar Ver Estatisticas\n",
    "mostrar_estatisticas_tabelas(spark)\n",
    "    \n",
    "# 6 Consultar tabelas no Streamlit:\n",
    "df = spark.table('teste.ecd_ml_empresas_resumo')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a49dd64-906b-4c84-9ca4-0c1d6909b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICA√á√ÉO DE TABELAS - SISTEMA ECD H√çBRIDO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "1. TABELA DE SALDOS: teste.ecd_saldos_contas_v2\n",
      "================================================================================\n",
      "\n",
      "üîÑ Carregando dados do ECD com filtros aplicados...\n",
      "\n",
      "üìÇ Carregando: teste.ecd_saldos_contas_v2\n",
      "================================================================================\n",
      "üîç APLICANDO FILTROS DE QUALIDADE - SALDOS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros antes do filtro: 945,499,468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros depois do filtro: 929,622,972\n",
      "üóëÔ∏è  Registros removidos (zeros/nulos): 15,876,496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Taxa de reten√ß√£o: 98.32%\n",
      "\n",
      "üìã Filtrando contas inv√°lidas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros antes: 929,622,972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros depois: 929,622,745\n",
      "üóëÔ∏è  Registros removidos (inv√°lidos): 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóëÔ∏è  Duplicatas removidas: 770,088,431\n",
      "\n",
      "================================================================================\n",
      "üìä RESUMO DO FILTRO:\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originais: 945,499,468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros filtrados: 159,534,314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros removidos: 785,965,154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de reten√ß√£o: 16.87%\n",
      "================================================================================\n",
      "\n",
      "üìÇ Carregando: teste.ecd_empresas_cadastro\n",
      "üìä Empresas carregadas: 349,301\n",
      "\n",
      "üìÇ Carregando: teste.ecd_ml_empresas_resumo\n",
      "üìä Registros ML carregados: 384,515\n",
      "\n",
      "‚úÖ Todos os dados carregados e filtrados com sucesso!\n",
      "\n",
      "‚úÖ Tabela encontrada!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total de registros: 159,534,314\n",
      "\n",
      "üìã Schema da tabela:\n",
      "root\n",
      " |-- id_ecd: long (nullable = true)\n",
      " |-- cnpj: string (nullable = true)\n",
      " |-- ano_referencia: integer (nullable = true)\n",
      " |-- data_inicio_periodo: timestamp (nullable = true)\n",
      " |-- data_fim_periodo: timestamp (nullable = true)\n",
      " |-- cd_conta: string (nullable = true)\n",
      " |-- cd_centro_custos: string (nullable = true)\n",
      " |-- cd_conta_referencial: string (nullable = true)\n",
      " |-- nm_conta: string (nullable = true)\n",
      " |-- tipo_conta: string (nullable = true)\n",
      " |-- nivel_conta: short (nullable = true)\n",
      " |-- descricao_grupo_balanco: string (nullable = true)\n",
      " |-- grupo_balanco: string (nullable = true)\n",
      " |-- saldo_inicial_abs: double (nullable = true)\n",
      " |-- indicador_saldo_inicial: string (nullable = true)\n",
      " |-- saldo_inicial_contabil: double (nullable = true)\n",
      " |-- valor_debito_periodo: double (nullable = true)\n",
      " |-- valor_credito_periodo: double (nullable = true)\n",
      " |-- movimentacao_liquida: double (nullable = true)\n",
      " |-- saldo_final_abs: double (nullable = true)\n",
      " |-- indicador_saldo_final: string (nullable = true)\n",
      " |-- saldo_final_contabil: double (nullable = true)\n",
      "\n",
      "\n",
      "üîç Primeiros 3 registros:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------+-------------------+-------------------+----------------+----------------+--------------------+---------------+----------+-----------+-----------------------+------------------+-----------------+-----------------------+----------------------+--------------------+---------------------+--------------------+---------------+---------------------+--------------------+\n",
      "|id_ecd|cnpj          |ano_referencia|data_inicio_periodo|data_fim_periodo   |cd_conta        |cd_centro_custos|cd_conta_referencial|nm_conta       |tipo_conta|nivel_conta|descricao_grupo_balanco|grupo_balanco     |saldo_inicial_abs|indicador_saldo_inicial|saldo_inicial_contabil|valor_debito_periodo|valor_credito_periodo|movimentacao_liquida|saldo_final_abs|indicador_saldo_final|saldo_final_contabil|\n",
      "+------+--------------+--------------+-------------------+-------------------+----------------+----------------+--------------------+---------------+----------+-----------+-----------------------+------------------+-----------------+-----------------------+----------------------+--------------------+---------------------+--------------------+---------------+---------------------+--------------------+\n",
      "|12    |95764056000129|2021          |2021-07-01 00:00:00|2021-07-31 00:00:00|318             |NULL            |NULL                |CONTA ANAL√çTICA|A         |5          |NULL                   |NULL              |205.4            |D                      |-205.4                |0.0                 |0.0                  |0.0                 |205.4          |D                    |-205.4              |\n",
      "|18    |03208166000196|2021          |2021-10-01 00:00:00|2021-10-31 00:00:00|11270315        |NULL            |1.01.02.04.18       |CONTA ANAL√çTICA|A         |5          |NULL                   |Ativo Circulante  |22307.07         |D                      |-22307.07             |0.0                 |0.0                  |0.0                 |22307.07       |D                    |-22307.07           |\n",
      "|29    |13824680000100|2021          |2021-09-01 00:00:00|2021-09-30 00:00:00|2.1.01.20.416480|NULL            |2.01.01.03.01       |CONTA ANAL√çTICA|A         |5          |NULL                   |Passivo Circulante|0.0              |C                      |0.0                   |0.0                 |62.5                 |-62.5               |62.5           |C                    |62.5                |\n",
      "+------+--------------+--------------+-------------------+-------------------+----------------+----------------+--------------------+---------------+----------+-----------+-----------------------+------------------+-----------------+-----------------------+----------------------+--------------------+---------------------+--------------------+---------------+---------------------+--------------------+\n",
      "\n",
      "\n",
      "‚úÖ Campos essenciais:\n",
      "  ‚úÖ id_ecd\n",
      "  ‚ùå dt_referencia\n",
      "  ‚ùå saldo (ou vl_saldo)\n",
      "  ‚ùå classificacao_nivel_1\n",
      "  ‚ùå classificacao_nivel_2\n",
      "  ‚ùå classificacao_nivel_3\n",
      "\n",
      "================================================================================\n",
      "2. TABELA DE EMPRESAS: teste.ecd_empresas_cadastro\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Tabela encontrada!\n",
      "üìä Total de empresas: 349,301\n",
      "\n",
      "üìã Schema da tabela:\n",
      "root\n",
      " |-- id_ecd: long (nullable = true)\n",
      " |-- cnpj: string (nullable = true)\n",
      " |-- nm_razao_social: string (nullable = true)\n",
      " |-- nm_fantasia: string (nullable = true)\n",
      " |-- cd_uf: string (nullable = true)\n",
      " |-- nu_ie: string (nullable = true)\n",
      " |-- cd_municipio: integer (nullable = true)\n",
      " |-- inscricao_municipal: string (nullable = true)\n",
      " |-- cd_cnae: string (nullable = true)\n",
      " |-- de_cnae: string (nullable = true)\n",
      " |-- cnae_secao: string (nullable = true)\n",
      " |-- cnae_secao_descricao: string (nullable = true)\n",
      " |-- cnae_divisao: string (nullable = true)\n",
      " |-- cnae_divisao_descricao: string (nullable = true)\n",
      " |-- cnae_grupo: string (nullable = true)\n",
      " |-- cnae_grupo_descricao: string (nullable = true)\n",
      " |-- cnae_classe: string (nullable = true)\n",
      " |-- cnae_classe_descricao: string (nullable = true)\n",
      " |-- qtd_cnaes_secundarios: short (nullable = true)\n",
      " |-- sit_cadastral_sefaz: short (nullable = true)\n",
      " |-- nm_sit_cadastral_sefaz: string (nullable = true)\n",
      " |-- dt_constituicao_sefaz: timestamp (nullable = true)\n",
      " |-- natureza_juridica_sefaz: short (nullable = true)\n",
      " |-- nm_natureza_juridica_sefaz: string (nullable = true)\n",
      " |-- cd_tipo_contribuinte: short (nullable = true)\n",
      " |-- nm_tipo_contribuinte: string (nullable = true)\n",
      " |-- cd_reg_apuracao: byte (nullable = true)\n",
      " |-- nm_reg_apuracao: string (nullable = true)\n",
      " |-- sn_simples_nacional_rfb: byte (nullable = true)\n",
      " |-- situacao_especial_ecd: byte (nullable = true)\n",
      " |-- situacao_inicio_periodo_ecd: byte (nullable = true)\n",
      " |-- empresa_grande_porte: string (nullable = true)\n",
      " |-- tipo_ecd: string (nullable = true)\n",
      " |-- data_inicio_periodo: timestamp (nullable = true)\n",
      " |-- data_fim_periodo: timestamp (nullable = true)\n",
      " |-- ano_referencia: integer (nullable = true)\n",
      " |-- periodo_referencia_aaaamm: long (nullable = true)\n",
      " |-- ano_criacao_ecd: short (nullable = true)\n",
      " |-- mes_criacao_ecd: byte (nullable = true)\n",
      " |-- qtd_ecds_entregues: long (nullable = true)\n",
      " |-- ultima_ecd_ano: integer (nullable = true)\n",
      "\n",
      "\n",
      "üîç Primeiros 3 registros:\n",
      "+------+--------------+-------------------+-------------------+-----+------------+------------+-------------------+-------+-------+----------+--------------------+------------+----------------------+----------+--------------------+-----------+---------------------+---------------------+-------------------+----------------------+---------------------+-----------------------+--------------------------+--------------------+--------------------+---------------+---------------+-----------------------+---------------------+---------------------------+--------------------+--------+-------------------+-------------------+--------------+-------------------------+---------------+---------------+------------------+--------------+\n",
      "|id_ecd|cnpj          |nm_razao_social    |nm_fantasia        |cd_uf|nu_ie       |cd_municipio|inscricao_municipal|cd_cnae|de_cnae|cnae_secao|cnae_secao_descricao|cnae_divisao|cnae_divisao_descricao|cnae_grupo|cnae_grupo_descricao|cnae_classe|cnae_classe_descricao|qtd_cnaes_secundarios|sit_cadastral_sefaz|nm_sit_cadastral_sefaz|dt_constituicao_sefaz|natureza_juridica_sefaz|nm_natureza_juridica_sefaz|cd_tipo_contribuinte|nm_tipo_contribuinte|cd_reg_apuracao|nm_reg_apuracao|sn_simples_nacional_rfb|situacao_especial_ecd|situacao_inicio_periodo_ecd|empresa_grande_porte|tipo_ecd|data_inicio_periodo|data_fim_periodo   |ano_referencia|periodo_referencia_aaaamm|ano_criacao_ecd|mes_criacao_ecd|qtd_ecds_entregues|ultima_ecd_ano|\n",
      "+------+--------------+-------------------+-------------------+-----+------------+------------+-------------------+-------+-------+----------+--------------------+------------+----------------------+----------+--------------------+-----------+---------------------+---------------------+-------------------+----------------------+---------------------+-----------------------+--------------------------+--------------------+--------------------+---------------+---------------+-----------------------+---------------------+---------------------------+--------------------+--------+-------------------+-------------------+--------------+-------------------------+---------------+---------------+------------------+--------------+\n",
      "|296386|00009491000131|TELLAIO TEXTIL LTDA|TELLAIO TEXTIL LTDA|SP   |165324089118|3501608     |51360              |NULL   |NULL   |NULL      |NULL                |NULL        |NULL                  |NULL      |NULL                |NULL       |NULL                 |NULL                 |NULL               |NULL                  |NULL                 |NULL                   |NULL                      |NULL                |NULL                |NULL           |NULL           |NULL                   |NULL                 |0                          |N√£o                 |Outros  |2020-12-31 21:00:00|2021-12-30 21:00:00|202101        |202101                   |2024           |10             |6                 |202301        |\n",
      "|342423|00009491000131|TELLAIO TEXTIL LTDA|TELLAIO TEXTIL LTDA|SP   |165324089118|3501608     |51360              |NULL   |NULL   |NULL      |NULL                |NULL        |NULL                  |NULL      |NULL                |NULL       |NULL                 |NULL                 |NULL               |NULL                  |NULL                 |NULL                   |NULL                      |NULL                |NULL                |NULL           |NULL           |NULL                   |NULL                 |0                          |N√£o                 |Outros  |2022-12-31 21:00:00|2023-12-30 21:00:00|202301        |202301                   |2024           |10             |6                 |202301        |\n",
      "|308024|00009491000131|TELLAIO TEXTIL LTDA|TELLAIO TEXTIL LTDA|SP   |165324089118|3501608     |51360              |NULL   |NULL   |NULL      |NULL                |NULL        |NULL                  |NULL      |NULL                |NULL       |NULL                 |NULL                 |NULL               |NULL                  |NULL                 |NULL                   |NULL                      |NULL                |NULL                |NULL           |NULL           |NULL                   |NULL                 |0                          |N√£o                 |Outros  |2018-12-31 20:00:00|2019-12-30 21:00:00|0             |201812                   |2024           |10             |6                 |202301        |\n",
      "+------+--------------+-------------------+-------------------+-----+------------+------------+-------------------+-------+-------+----------+--------------------+------------+----------------------+----------+--------------------+-----------+---------------------+---------------------+-------------------+----------------------+---------------------+-----------------------+--------------------------+--------------------+--------------------+---------------+---------------+-----------------------+---------------------+---------------------------+--------------------+--------+-------------------+-------------------+--------------+-------------------------+---------------+---------------+------------------+--------------+\n",
      "\n",
      "\n",
      "‚úÖ Campos essenciais:\n",
      "  ‚úÖ id_ecd\n",
      "  ‚ùå porte_empresa (ou classificacao_porte)\n",
      "  ‚ùå setor_atividade (ou cnae)\n",
      "\n",
      "================================================================================\n",
      "3. TABELAS ML DISPON√çVEIS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ teste.ecd_ml_contas_classificadas\n",
      "   üìä Registros: 99,773,786\n",
      "   üìã Colunas: id_ecd, ano_mes_referencia, codigo_conta, nome_conta, codigo_conta_sintetica, natureza_contabil, nivel_hierarquico, tipo_conta, primeiro_digito, prefixo_2_chars\n",
      "\n",
      "‚úÖ teste.ecd_ml_contas_nao_classificadas\n",
      "   üìä Registros: 4,467\n",
      "   üìã Colunas: dt_referencia, primeiro_digito, padrao_estrutural, cd_natureza, tem_ponto, tem_letra, quantidade, empresas_afetadas, comprimento_medio, pontos_medio\n",
      "\n",
      "‚úÖ teste.ecd_ml_distribuicao_classes\n",
      "   üìä Registros: 1,206,598\n",
      "   üìã Colunas: id_ecd, dt_referencia, classificacao_nivel_2, quantidade_contas, confianca_media, qtd_padroes, qtd_digitos, data_processamento, ano_referencia, classificacao_nivel_1_desc\n",
      "\n",
      "‚úÖ teste.ecd_ml_empresas_resumo\n",
      "   üìä Registros: 384,515\n",
      "   üìã Colunas: id_ecd, dt_referencia, total_contas, contas_distintas, contas_classificadas, contas_nao_classificadas, total_ativo, total_passivo, total_resultado, class_estrutural\n",
      "\n",
      "‚úÖ teste.ecd_ml_validacao_equacao\n",
      "   üìä Registros: 379,007\n",
      "   üìã Colunas: id_ecd, dt_referencia, total_ativo, total_passivo, total_pl, passivo_pl_calculado, diferenca, percentual_diferenca, equacao_valida, status_equacao\n",
      "\n",
      "================================================================================\n",
      "4. AN√ÅLISE DETALHADA: teste.ecd_ml_empresas_resumo\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Esta √© a tabela ideal para df_ml_features!\n",
      "\n",
      "üìã Schema completo:\n",
      "root\n",
      " |-- id_ecd: long (nullable = true)\n",
      " |-- dt_referencia: integer (nullable = true)\n",
      " |-- total_contas: long (nullable = true)\n",
      " |-- contas_distintas: long (nullable = true)\n",
      " |-- contas_classificadas: long (nullable = true)\n",
      " |-- contas_nao_classificadas: long (nullable = true)\n",
      " |-- total_ativo: long (nullable = true)\n",
      " |-- total_passivo: long (nullable = true)\n",
      " |-- total_resultado: long (nullable = true)\n",
      " |-- class_estrutural: long (nullable = true)\n",
      " |-- class_dicionario: long (nullable = true)\n",
      " |-- confianca_media: double (nullable = true)\n",
      " |-- confianca_minima: double (nullable = true)\n",
      " |-- confianca_maxima: double (nullable = true)\n",
      " |-- confianca_alta: long (nullable = true)\n",
      " |-- confianca_boa: long (nullable = true)\n",
      " |-- confianca_moderada: long (nullable = true)\n",
      " |-- confianca_baixa: long (nullable = true)\n",
      " |-- qtd_padroes_distintos: long (nullable = true)\n",
      " |-- qtd_digitos_distintos: long (nullable = true)\n",
      " |-- nivel_minimo: long (nullable = true)\n",
      " |-- nivel_maximo: long (nullable = true)\n",
      " |-- nivel_medio: double (nullable = true)\n",
      " |-- taxa_classificacao: double (nullable = true)\n",
      " |-- taxa_ativo: double (nullable = true)\n",
      " |-- taxa_passivo: double (nullable = true)\n",
      " |-- taxa_resultado: double (nullable = true)\n",
      " |-- qualidade_classificacao: string (nullable = true)\n",
      " |-- data_processamento: timestamp (nullable = true)\n",
      " |-- ano_referencia: integer (nullable = true)\n",
      "\n",
      "\n",
      "üîç Primeiros 3 registros:\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------------+--------------+\n",
      "|id_ecd|dt_referencia|total_contas|contas_distintas|contas_classificadas|contas_nao_classificadas|total_ativo|total_passivo|total_resultado|class_estrutural|class_dicionario|confianca_media|confianca_minima|confianca_maxima|confianca_alta|confianca_boa|confianca_moderada|confianca_baixa|qtd_padroes_distintos|qtd_digitos_distintos|nivel_minimo|nivel_maximo|nivel_medio|taxa_classificacao|taxa_ativo|taxa_passivo|taxa_resultado|qualidade_classificacao|data_processamento        |ano_referencia|\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------------+--------------+\n",
      "|156397|202201       |116         |116             |7                   |109                     |7          |0            |0              |0               |7               |0.0453         |0.0             |0.75            |0             |0            |7                 |109            |2                    |1                    |1           |6           |4.59       |6.03              |100.0     |0.0         |0.0           |RUIM                   |2025-11-13 19:38:39.773708|2022          |\n",
      "|168294|202201       |418         |418             |2                   |416                     |1          |1            |0              |0               |2               |0.0036         |0.0             |0.75            |0             |0            |2                 |416            |2                    |1                    |1           |6           |4.88       |0.48              |50.0      |50.0        |0.0           |RUIM                   |2025-11-13 19:38:39.773708|2022          |\n",
      "|278441|202201       |1113        |1113            |36                  |1077                    |36         |0            |0              |0               |36              |0.0243         |0.0             |0.75            |0             |0            |36                |1077           |2                    |1                    |1           |6           |4.99       |3.23              |100.0     |0.0         |0.0           |RUIM                   |2025-11-13 19:38:39.773708|2022          |\n",
      "+------+-------------+------------+----------------+--------------------+------------------------+-----------+-------------+---------------+----------------+----------------+---------------+----------------+----------------+--------------+-------------+------------------+---------------+---------------------+---------------------+------------+------------+-----------+------------------+----------+------------+--------------+-----------------------+--------------------------+--------------+\n",
      "\n",
      "\n",
      "‚úÖ Campo 'confianca_media' encontrado - PERFEITO!\n",
      "\n",
      "üìä Estat√≠sticas de confian√ßa_media:\n",
      "+-------+-------------------+\n",
      "|summary|    confianca_media|\n",
      "+-------+-------------------+\n",
      "|  count|             384515|\n",
      "|   mean|0.37300458109567003|\n",
      "| stddev|0.25688007604371216|\n",
      "|    min|                0.0|\n",
      "|    max|                0.8|\n",
      "+-------+-------------------+\n",
      "\n",
      "\n",
      "üí° RECOMENDA√á√ÉO:\n",
      "   Use: df_ml_features = spark.table('teste.ecd_ml_empresas_resumo')\n",
      "\n",
      "================================================================================\n",
      "5. C√ìDIGO FINAL RECOMENDADO\n",
      "================================================================================\n",
      "\n",
      "# ============================================================================\n",
      "# CARREGAR DADOS\n",
      "# ============================================================================\n",
      "df_saldos = spark.table('teste.ecd_saldos_contas_v2')\n",
      "df_empresas = spark.table('teste.ecd_empresas_cadastro')\n",
      "df_ml_features = spark.table('teste.ecd_ml_empresas_resumo')\n",
      "\n",
      "# Se necess√°rio ajustar nomes de campos:\n",
      "df_empresas = df_empresas.select(\n",
      "    'id_ecd',\n",
      "    col('classificacao_porte').alias('porte_empresa'),  # AJUSTAR SE NECESS√ÅRIO\n",
      "    col('cnae_principal').alias('setor_atividade')      # AJUSTAR SE NECESS√ÅRIO\n",
      ")\n",
      "\n",
      "# ============================================================================\n",
      "# EXECUTAR AN√ÅLISE H√çBRIDA\n",
      "# ============================================================================\n",
      "df_hibrido, df_indices_padrao = criar_classificacao_hibrida(\n",
      "    df_saldos,\n",
      "    df_empresas,\n",
      "    df_ml_features\n",
      ")\n",
      "\n",
      "# ============================================================================\n",
      "# SALVAR RESULTADOS\n",
      "# ============================================================================\n",
      "resultados = salvar_analise_indices_padrao(spark, df_hibrido, df_indices_padrao)\n",
      "\n",
      "print(\"‚úÖ An√°lise h√≠brida conclu√≠da com sucesso!\")\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VERIFICA√á√ÉO CONCLU√çDA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT DE VERIFICA√á√ÉO - IDENTIFICAR TABELAS CORRETAS\n",
    "=====================================================\n",
    "\n",
    "Execute este script no seu notebook para identificar as tabelas corretas\n",
    "e verificar se os campos necess√°rios existem.\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICA√á√ÉO DE TABELAS - SISTEMA ECD H√çBRIDO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. VERIFICAR TABELA DE SALDOS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. TABELA DE SALDOS: teste.ecd_saldos_contas_v2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    df_saldos, df_empresas, df_ml = carregar_dados_ecd_filtrados()\n",
    "    \n",
    "    print(\"\\n‚úÖ Tabela encontrada!\")\n",
    "    print(f\"üìä Total de registros: {df_saldos.count():,}\")\n",
    "    \n",
    "    print(\"\\nüìã Schema da tabela:\")\n",
    "    df_saldos.printSchema()\n",
    "    \n",
    "    print(\"\\nüîç Primeiros 3 registros:\")\n",
    "    df_saldos.limit(3).show(truncate=False)\n",
    "    \n",
    "    # Verificar campos essenciais\n",
    "    colunas = df_saldos.columns\n",
    "    campos_essenciais = {\n",
    "        'id_ecd': 'id_ecd' in colunas,\n",
    "        'dt_referencia': 'dt_referencia' in colunas,\n",
    "        'saldo (ou vl_saldo)': 'saldo' in colunas or 'vl_saldo' in colunas,\n",
    "        'classificacao_nivel_1': 'classificacao_nivel_1' in colunas,\n",
    "        'classificacao_nivel_2': 'classificacao_nivel_2' in colunas,\n",
    "        'classificacao_nivel_3': 'classificacao_nivel_3' in colunas,\n",
    "    }\n",
    "    \n",
    "    print(\"\\n‚úÖ Campos essenciais:\")\n",
    "    for campo, existe in campos_essenciais.items():\n",
    "        status = \"‚úÖ\" if existe else \"‚ùå\"\n",
    "        print(f\"  {status} {campo}\")\n",
    "    \n",
    "    # Determinar nome correto do campo saldo\n",
    "    campo_saldo = 'saldo' if 'saldo' in colunas else 'vl_saldo' if 'vl_saldo' in colunas else None\n",
    "    if campo_saldo:\n",
    "        print(f\"\\nüí° Use o campo: '{campo_saldo}' para os saldos\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO: {e}\")\n",
    "    print(\"Verifique se a tabela existe e est√° acess√≠vel\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. VERIFICAR TABELA DE EMPRESAS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. TABELA DE EMPRESAS: teste.ecd_empresas_cadastro\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    df_empresas = spark.table('teste.ecd_empresas_cadastro')\n",
    "    \n",
    "    print(\"\\n‚úÖ Tabela encontrada!\")\n",
    "    print(f\"üìä Total de empresas: {df_empresas.count():,}\")\n",
    "    \n",
    "    print(\"\\nüìã Schema da tabela:\")\n",
    "    df_empresas.printSchema()\n",
    "    \n",
    "    print(\"\\nüîç Primeiros 3 registros:\")\n",
    "    df_empresas.limit(3).show(truncate=False)\n",
    "    \n",
    "    # Verificar campos essenciais\n",
    "    colunas = df_empresas.columns\n",
    "    campos_essenciais = {\n",
    "        'id_ecd': 'id_ecd' in colunas,\n",
    "        'porte_empresa (ou classificacao_porte)': 'porte_empresa' in colunas or 'classificacao_porte' in colunas,\n",
    "        'setor_atividade (ou cnae)': any(x in colunas for x in ['setor_atividade', 'cnae_principal', 'cnae'])\n",
    "    }\n",
    "    \n",
    "    print(\"\\n‚úÖ Campos essenciais:\")\n",
    "    for campo, existe in campos_essenciais.items():\n",
    "        status = \"‚úÖ\" if existe else \"‚ùå\"\n",
    "        print(f\"  {status} {campo}\")\n",
    "    \n",
    "    # Determinar nomes corretos dos campos\n",
    "    if 'porte_empresa' in colunas:\n",
    "        print(f\"\\nüí° Use o campo: 'porte_empresa'\")\n",
    "    elif 'classificacao_porte' in colunas:\n",
    "        print(f\"\\nüí° Use o campo: 'classificacao_porte' (renomear para 'porte_empresa')\")\n",
    "    \n",
    "    if 'setor_atividade' in colunas:\n",
    "        print(f\"üí° Use o campo: 'setor_atividade'\")\n",
    "    elif 'cnae_principal' in colunas:\n",
    "        print(f\"üí° Use o campo: 'cnae_principal' (renomear para 'setor_atividade')\")\n",
    "    elif 'cnae' in colunas:\n",
    "        print(f\"üí° Use o campo: 'cnae' (renomear para 'setor_atividade')\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO: {e}\")\n",
    "    print(\"Verifique se a tabela existe e est√° acess√≠vel\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. VERIFICAR TABELAS ML DISPON√çVEIS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. TABELAS ML DISPON√çVEIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tabelas_ml = [\n",
    "    'teste.ecd_ml_contas_classificadas',\n",
    "    'teste.ecd_ml_contas_nao_classificadas',\n",
    "    'teste.ecd_ml_distribuicao_classes',\n",
    "    'teste.ecd_ml_empresas_resumo',\n",
    "    'teste.ecd_ml_validacao_equacao'\n",
    "]\n",
    "\n",
    "tabelas_encontradas = []\n",
    "\n",
    "for tabela in tabelas_ml:\n",
    "    try:\n",
    "        df_temp = spark.table(tabela)\n",
    "        count = df_temp.count()\n",
    "        tabelas_encontradas.append(tabela)\n",
    "        print(f\"\\n‚úÖ {tabela}\")\n",
    "        print(f\"   üìä Registros: {count:,}\")\n",
    "        print(f\"   üìã Colunas: {', '.join(df_temp.columns[:10])}\")  # Primeiras 10 colunas\n",
    "    except:\n",
    "        print(f\"\\n‚ùå {tabela} - N√ÉO ENCONTRADA\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. ANALISAR TABELA ML RESUMO (PRINCIPAL CANDIDATA)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. AN√ÅLISE DETALHADA: teste.ecd_ml_empresas_resumo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'teste.ecd_ml_empresas_resumo' in tabelas_encontradas:\n",
    "    try:\n",
    "        df_ml_resumo = spark.table('teste.ecd_ml_empresas_resumo')\n",
    "        \n",
    "        print(\"\\n‚úÖ Esta √© a tabela ideal para df_ml_features!\")\n",
    "        \n",
    "        print(\"\\nüìã Schema completo:\")\n",
    "        df_ml_resumo.printSchema()\n",
    "        \n",
    "        print(\"\\nüîç Primeiros 3 registros:\")\n",
    "        df_ml_resumo.limit(3).show(truncate=False)\n",
    "        \n",
    "        # Verificar campo de confian√ßa\n",
    "        colunas = df_ml_resumo.columns\n",
    "        if 'confianca_media' in colunas:\n",
    "            print(\"\\n‚úÖ Campo 'confianca_media' encontrado - PERFEITO!\")\n",
    "            \n",
    "            # Estat√≠sticas de confian√ßa\n",
    "            stats = df_ml_resumo.select('confianca_media').describe()\n",
    "            print(\"\\nüìä Estat√≠sticas de confian√ßa_media:\")\n",
    "            stats.show()\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Campo 'confianca_media' N√ÉO encontrado\")\n",
    "            print(\"Campos dispon√≠veis que podem servir:\")\n",
    "            for col in colunas:\n",
    "                if 'confianca' in col.lower() or 'score' in col.lower() or 'media' in col.lower():\n",
    "                    print(f\"  - {col}\")\n",
    "        \n",
    "        print(\"\\nüí° RECOMENDA√á√ÉO:\")\n",
    "        print(\"   Use: df_ml_features = spark.table('teste.ecd_ml_empresas_resumo')\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERRO ao analisar: {e}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Tabela teste.ecd_ml_empresas_resumo N√ÉO encontrada\")\n",
    "    print(\"\\nüí° SOLU√á√ÉO ALTERNATIVA:\")\n",
    "    print(\"   Criar resumo a partir de teste.ecd_ml_contas_classificadas:\")\n",
    "    print(\"\"\"\n",
    "    df_ml_features = spark.table('teste.ecd_ml_contas_classificadas') \\\\\n",
    "        .groupBy('id_ecd', 'dt_referencia').agg(\n",
    "            avg('confianca').alias('confianca_media'),\n",
    "            count('*').alias('total_contas')\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. C√ìDIGO FINAL RECOMENDADO\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. C√ìDIGO FINAL RECOMENDADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"‚úÖ An√°lise h√≠brida conclu√≠da com sucesso!\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICA√á√ÉO CONCLU√çDA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3343f49-dfbd-4dfd-a01c-f6b0387b9882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Carregando dados do ECD com filtros aplicados...\n",
      "\n",
      "üìÇ Carregando: teste.ecd_saldos_contas_v2\n",
      "================================================================================\n",
      "üîç APLICANDO FILTROS DE QUALIDADE - SALDOS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros antes do filtro: 945,499,468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros depois do filtro: 929,622,972\n",
      "üóëÔ∏è  Registros removidos (zeros/nulos): 15,876,496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Taxa de reten√ß√£o: 98.32%\n",
      "\n",
      "üìã Filtrando contas inv√°lidas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros antes: 929,622,972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Registros depois: 929,622,745\n",
      "üóëÔ∏è  Registros removidos (inv√°lidos): 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóëÔ∏è  Duplicatas removidas: 770,088,431\n",
      "\n",
      "================================================================================\n",
      "üìä RESUMO DO FILTRO:\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originais: 945,499,468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros filtrados: 159,534,314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros removidos: 785,965,154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de reten√ß√£o: 16.87%\n",
      "================================================================================\n",
      "\n",
      "üìÇ Carregando: teste.ecd_empresas_cadastro\n",
      "üìä Empresas carregadas: 349,301\n",
      "\n",
      "üìÇ Carregando: teste.ecd_ml_empresas_resumo\n",
      "üìä Registros ML carregados: 384,515\n",
      "\n",
      "‚úÖ Todos os dados carregados e filtrados com sucesso!\n",
      "üìä Dados carregados:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Saldos: 159,534,314 registros\n",
      "   - Empresas: 349,301 registros\n",
      "   - ML Features: 384,515 registros\n",
      "üìä Calculando indicadores econ√¥mico-financeiros...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indicadores calculados para 1,330,164 registros\n",
      "‚úÖ Indicadores calculados\n",
      "root\n",
      " |-- id_ecd: long (nullable = true)\n",
      " |-- dt_referencia: integer (nullable = true)\n",
      " |-- ativo_circulante: double (nullable = true)\n",
      " |-- realizavel_longo_prazo: double (nullable = true)\n",
      " |-- ativo_permanente: double (nullable = true)\n",
      " |-- ativo_total: double (nullable = true)\n",
      " |-- passivo_circulante: double (nullable = true)\n",
      " |-- exigivel_longo_prazo: double (nullable = true)\n",
      " |-- patrimonio_liquido: double (nullable = true)\n",
      " |-- receita_bruta: double (nullable = true)\n",
      " |-- deducoes_receita: double (nullable = true)\n",
      " |-- receita_liquida: double (nullable = true)\n",
      " |-- lucro_liquido: double (nullable = true)\n",
      " |-- custo_mercadorias: double (nullable = true)\n",
      " |-- exigivel_total: double (nullable = true)\n",
      " |-- recursos_nao_correntes: double (nullable = true)\n",
      " |-- liquidez_corrente: double (nullable = true)\n",
      " |-- liquidez_geral: double (nullable = true)\n",
      " |-- endividamento: double (nullable = true)\n",
      " |-- participacao_capital_proprio: double (nullable = true)\n",
      " |-- giro_ativo: double (nullable = true)\n",
      " |-- margem_liquida: double (nullable = true)\n",
      " |-- retorno_ativo: double (nullable = true)\n",
      " |-- retorno_pl: double (nullable = true)\n",
      " |-- imobilizacao_pl: double (nullable = true)\n",
      " |-- imobilizacao_recursos_nc: double (nullable = true)\n",
      " |-- porte_empresa: string (nullable = true)\n",
      " |-- setor_atividade: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------------+-------------+--------------------+\n",
      "|id_ecd|dt_referencia|   liquidez_corrente|retorno_ativo|       endividamento|\n",
      "+------+-------------+--------------------+-------------+--------------------+\n",
      "|   365|       201904| -2.0162044655601656|         -0.0|-0.44547103498174356|\n",
      "|   864|       201902|                NULL|         NULL|                NULL|\n",
      "|  1065|       202102|-0.05207248988175878|         -0.0| -15.996477749900556|\n",
      "|  1418|       201902|                 0.0|         NULL|                NULL|\n",
      "|  1654|       202108| -1.6465311026170035|         -0.0| -0.6073374492656688|\n",
      "|  1804|       201910|  -2.937873271457931|         -0.0|-0.49428429905085863|\n",
      "|  2453|       201906|                NULL|         NULL|                NULL|\n",
      "|  2493|       202003|                NULL|         NULL|                NULL|\n",
      "|  2523|       202103|                NULL|         NULL|                NULL|\n",
      "|  2600|       202106|  -0.505851975771876|         -0.0|-0.11855770933824981|\n",
      "+------+-------------+--------------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "üìà Calculando √≠ndices-padr√£o setoriais (decis)...\n",
      "  Calculando decis para: liquidez_corrente\n",
      "  Calculando decis para: liquidez_geral\n",
      "  Calculando decis para: endividamento\n",
      "  Calculando decis para: participacao_capital_proprio\n",
      "  Calculando decis para: giro_ativo\n",
      "  Calculando decis para: margem_liquida\n",
      "  Calculando decis para: retorno_ativo\n",
      "  Calculando decis para: retorno_pl\n",
      "  Calculando decis para: imobilizacao_pl\n",
      "  Calculando decis para: imobilizacao_recursos_nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ √çndices-padr√£o calculados: 20 registros\n",
      "‚úÖ √çndices-padr√£o calculados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "| setor_atividade|porte_empresa|n_empresas|               media|       desvio_padrao|           indicador|             decil_1|             decil_2|             decil_3|             decil_4|             mediana|             decil_6|             decil_7|             decil_8|            decil_9|\n",
      "+----------------+-------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|N√ÉO CLASSIFICADO|       GRANDE|        17| -0.7561818247180921| 0.13174101313307462|   liquidez_corrente| -0.8550429138709037| -0.7574407075649694| -0.7376396175576889| -0.7264340162047573| -0.7172813658702608| -0.7074127084703948| -0.7003708912799547| -0.6871555884234778|-0.6835309992413854|\n",
      "|N√ÉO CLASSIFICADO|PEQUENA/M√âDIA|         7|  -0.767277343808014| 0.02109324053972953|   liquidez_corrente|  -0.795944732884132| -0.7807776426572168| -0.7761953128142803| -0.7761953128142803| -0.7752858281586482| -0.7557349366774031| -0.7557349366774031|  -0.754859175613793|-0.7321437778506249|\n",
      "|N√ÉO CLASSIFICADO|       GRANDE|        17| -1.2797843825327635| 0.02854217896681233|      liquidez_geral| -1.3112613004064169| -1.3086294664877314| -1.3042934158646742|  -1.283179992182434| -1.2758357656279973| -1.2694000389838658| -1.2681732190868784| -1.2666382778938738|-1.2525052912656052|\n",
      "|N√ÉO CLASSIFICADO|PEQUENA/M√âDIA|         7| -1.3140224830757379|0.017919350988726417|      liquidez_geral| -1.3308696208332649| -1.3308124505705339| -1.3269359262304627| -1.3269359262304627| -1.3236447892121188| -1.2992739071896047| -1.2992739071896047| -1.2969185336496227|-1.2897021538445588|\n",
      "|N√ÉO CLASSIFICADO|       GRANDE|        17| -0.7817562571080505|0.017858250336211808|       endividamento|  -0.798399820722147| -0.7894913784405511| -0.7885358127338699| -0.7877737271857059| -0.7837999427048319| -0.7793138967972829| -0.7666986491203404| -0.7641582477001144|-0.7626245048870554|\n",
      "|N√ÉO CLASSIFICADO|PEQUENA/M√âDIA|         7| -0.7611438001500822|0.010421510430097059|       endividamento| -0.7753728231119361| -0.7710584543702439| -0.7696606500495733| -0.7696606500495733| -0.7554896964428318| -0.7536158907391886| -0.7536158907391886| -0.7514206825847536|-0.7513884037520485|\n",
      "|N√ÉO CLASSIFICADO|       GRANDE|        17| 0.24847878458191197|0.034309403192116436|participacao_capi...| 0.20904871681579285| 0.22124182574054366| 0.22507499299997435| 0.23023870077808692| 0.23817767127800685|  0.2717904723709504| 0.27248801646601883|  0.2865483880390179| 0.2901110744177544|\n",
      "|N√ÉO CLASSIFICADO|PEQUENA/M√âDIA|         7| 0.28128225033393706|0.006220425872998606|participacao_capi...| 0.27318488196012275|  0.2769169012057744|  0.2774693532550069|  0.2774693532550069| 0.28221165519120184|  0.2822431264889007|  0.2822431264889007|  0.2847503789450701|0.29219945529148295|\n",
      "|N√ÉO CLASSIFICADO|       GRANDE|        17|0.014273461452607794|0.007766632859701355|          giro_ativo|0.004265820719680448|0.006998710607937538|0.010367928980245437|0.012733299728357897|0.014119334001848085| 0.01732410545507057|0.017642016196494997|0.021211154648175818|0.02595510326850958|\n",
      "|N√ÉO CLASSIFICADO|PEQUENA/M√âDIA|         7|  0.0163847713634125| 0.00876126394038614|          giro_ativo|0.002411705252718...|0.007618943835829079|0.013490394096901719|0.013490394096901719|0.019536187559750784|0.023106184202610715|0.023106184202610715|0.023636435257628617|0.02489354933844795|\n",
      "+----------------+-------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "‚öñÔ∏è Calculando Fator de Insolv√™ncia de Kanitz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fator Kanitz calculado: 1,330,162 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|situacao_kanitz|  count|\n",
      "+---------------+-------+\n",
      "|     INSOLVENTE|1285231|\n",
      "|       PENUMBRA|  28904|\n",
      "|       SOLVENTE|  16024|\n",
      "+---------------+-------+\n",
      "\n",
      "‚úÖ Fator Kanitz calculado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|situacao_kanitz|  count|\n",
      "+---------------+-------+\n",
      "|       SOLVENTE|  16020|\n",
      "|       PENUMBRA|  28905|\n",
      "|     INSOLVENTE|1285229|\n",
      "+---------------+-------+\n",
      "\n",
      "\n",
      "üîÑ Criando classifica√ß√£o h√≠brida...\n",
      "üéØ Classificando empresas por √≠ndices-padr√£o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Empresas classificadas: 1,330,153 registros\n",
      "‚úÖ JOIN realizado sem duplicatas: 46 colunas\n",
      "‚úÖ Classifica√ß√£o h√≠brida completa!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------+-------+\n",
      "|classificacao_hibrida|nivel_risco|  count|\n",
      "+---------------------+-----------+-------+\n",
      "|              CR√çTICO|    CR√çTICO|1319356|\n",
      "|                 RUIM|       ALTO|   6818|\n",
      "|              CR√çTICO|       ALTO|   3539|\n",
      "|              REGULAR|      M√âDIO|    335|\n",
      "|                 RUIM|      M√âDIO|    112|\n",
      "+---------------------+-----------+-------+\n",
      "\n",
      "\n",
      "üíæ Salvando tabelas...\n",
      "  ‚úÖ DataFrame final: 57 colunas\n",
      "  Salvando: teste.ecd_indicadores_hibrido\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Salvando: teste.ecd_indices_padrao_setoriais\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Salvando: teste.ecd_empresas_classificacao_resumo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Salvando: teste.ecd_evolucao_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Salvando: teste.ecd_empresas_criticas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Todas as tabelas salvas com sucesso!\n",
      "\n",
      "üìã Tabelas criadas:\n",
      "  1. teste.ecd_indicadores_hibrido\n",
      "  2. teste.ecd_indices_padrao_setoriais\n",
      "  3. teste.ecd_empresas_classificacao_resumo\n",
      "  4. teste.ecd_evolucao_scores\n",
      "  5. teste.ecd_empresas_criticas\n",
      "\n",
      "üìä ESTAT√çSTICAS FINAIS:\n",
      "\n",
      "Empresas Cr√≠ticas: 1,329,709\n",
      "\n",
      "Top 10 Melhores:\n",
      "+------+-------------+---------------------+-----------+\n",
      "|id_ecd|score_hibrido|classificacao_hibrida|nivel_risco|\n",
      "+------+-------------+---------------------+-----------+\n",
      "| 68888|         67.0|              REGULAR|      M√âDIO|\n",
      "|259576|         67.0|              REGULAR|      M√âDIO|\n",
      "|259888|         67.0|              REGULAR|      M√âDIO|\n",
      "| 45940|         67.0|              REGULAR|      M√âDIO|\n",
      "|478648|         67.0|              REGULAR|      M√âDIO|\n",
      "|277486|         67.0|              REGULAR|      M√âDIO|\n",
      "|429942|         67.0|              REGULAR|      M√âDIO|\n",
      "|  4586|         67.0|              REGULAR|      M√âDIO|\n",
      "|426493|         67.0|              REGULAR|      M√âDIO|\n",
      "|323065|         67.0|              REGULAR|      M√âDIO|\n",
      "+------+-------------+---------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "‚úÖ AN√ÅLISE H√çBRIDA CONCLU√çDA!\n",
      "\n",
      "üìä ESTAT√çSTICAS FINAIS:\n",
      "\n",
      "Distribui√ß√£o de Classifica√ß√£o:\n",
      "+---------------------+-----------+------+\n",
      "|classificacao_hibrida|nivel_risco| count|\n",
      "+---------------------+-----------+------+\n",
      "|              CR√çTICO|    CR√çTICO|206389|\n",
      "|                 RUIM|       ALTO|  1678|\n",
      "|              CR√çTICO|       ALTO|   672|\n",
      "|              REGULAR|      M√âDIO|    62|\n",
      "|                 RUIM|      M√âDIO|    16|\n",
      "+---------------------+-----------+------+\n",
      "\n",
      "\n",
      "Empresas Cr√≠ticas:\n",
      "Total: 1,329,709\n",
      "\n",
      "Top 10 Melhores Empresas:\n",
      "+------+----------------------------------------------------------+-------------+---------------------+-----------+\n",
      "|id_ecd|setor_atividade                                           |score_hibrido|classificacao_hibrida|nivel_risco|\n",
      "+------+----------------------------------------------------------+-------------+---------------------+-----------+\n",
      "|68888 |N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|426493|IND√öSTRIAS DE TRANSFORMA√á√ÉO                               |67.0         |REGULAR              |M√âDIO      |\n",
      "|429942|N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|4586  |N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|277486|N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|323065|COM√âRCIO; REPARA√á√ÉO DE VE√çCULOS AUTOMOTORES E MOTOCICLETAS|67.0         |REGULAR              |M√âDIO      |\n",
      "|281150|CONSTRU√á√ÉO                                                |67.0         |REGULAR              |M√âDIO      |\n",
      "|59910 |N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|259888|N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "|279815|N√ÉO CLASSIFICADO                                          |67.0         |REGULAR              |M√âDIO      |\n",
      "+------+----------------------------------------------------------+-------------+---------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "‚úÖ AN√ÅLISE H√çBRIDA CONCLU√çDA COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "C√ìDIGO CORRIGIDO - SISTEMA ECD H√çBRIDO\n",
    "Adaptado para a estrutura real das tabelas\n",
    "\n",
    "MAPEAMENTO DE CAMPOS:\n",
    "- dt_referencia ‚Üí N√ÉO EXISTE, usar: ano_referencia + criar per√≠odo\n",
    "- saldo ‚Üí N√ÉO EXISTE, usar: saldo_final_contabil\n",
    "- classificacao_nivel_X ‚Üí N√ÉO EXISTEM, derivar de: grupo_balanco ou cd_conta_referencial\n",
    "- cd_conta_plano_contas_ref ‚Üí cd_conta_referencial\n",
    "- porte_empresa ‚Üí empresa_grande_porte\n",
    "- setor_atividade ‚Üí cnae_secao_descricao\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# ==============================================================================\n",
    "# FUN√á√ÉO 1: CALCULAR INDICADORES ECON√îMICO-FINANCEIROS (CORRIGIDA)\n",
    "# ==============================================================================\n",
    "\n",
    "def calcular_indicadores_economico_financeiros(df_saldos, df_empresas):\n",
    "    \"\"\"\n",
    "    Calcula 10 indicadores econ√¥mico-financeiros\n",
    "    VERS√ÉO CORRIGIDA para campos reais da tabela\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä Calculando indicadores econ√¥mico-financeiros...\")\n",
    "    \n",
    "    # Preparar dados: adicionar dt_referencia e classifica√ß√µes\n",
    "    df_prep = df_saldos \\\n",
    "        .withColumn('dt_referencia', \n",
    "                   concat(col('ano_referencia'), \n",
    "                          lpad(month(col('data_fim_periodo')), 2, '0')).cast('int')) \\\n",
    "        .withColumn('saldo', col('saldo_final_contabil')) \\\n",
    "        .withColumn('cd_conta_plano_contas_ref', col('cd_conta_referencial'))\n",
    "    \n",
    "    # Derivar classifica√ß√µes a partir do grupo_balanco e cd_conta_referencial\n",
    "    df_prep = df_prep \\\n",
    "        .withColumn('classificacao_nivel_1',\n",
    "                   when(col('grupo_balanco').rlike('^Ativo'), '1')\n",
    "                   .when(col('grupo_balanco').rlike('^Passivo'), '2')\n",
    "                   .when(col('cd_conta_referencial').rlike('^3\\\\.'), '3')\n",
    "                   .otherwise(substring(col('cd_conta_referencial'), 1, 1))) \\\n",
    "        .withColumn('classificacao_nivel_2',\n",
    "                   when(col('grupo_balanco') == 'Ativo Circulante', '1.01')\n",
    "                   .when(col('grupo_balanco').rlike('Ativo.*Longo'), '1.02')\n",
    "                   .when(col('grupo_balanco').rlike('Ativo.*Permanente|Imobilizado|Intang'), '1.03')\n",
    "                   .when(col('grupo_balanco') == 'Passivo Circulante', '2.01')\n",
    "                   .when(col('grupo_balanco').rlike('Passivo.*Longo'), '2.02')\n",
    "                   .when(col('grupo_balanco').rlike('Patrim|PL'), '2.03')\n",
    "                   .otherwise(substring(col('cd_conta_referencial'), 1, 4)))\n",
    "    \n",
    "    # Agregar saldos por empresa e per√≠odo\n",
    "    df_componentes = df_prep.groupBy('id_ecd', 'dt_referencia').agg(\n",
    "        # ATIVO\n",
    "        sum(when(col('classificacao_nivel_2') == '1.01', col('saldo')).otherwise(0)).alias('ativo_circulante'),\n",
    "        sum(when(col('classificacao_nivel_2') == '1.02', col('saldo')).otherwise(0)).alias('realizavel_longo_prazo'),\n",
    "        sum(when(col('classificacao_nivel_2') == '1.03', col('saldo')).otherwise(0)).alias('ativo_permanente'),\n",
    "        sum(when(col('classificacao_nivel_1') == '1', col('saldo')).otherwise(0)).alias('ativo_total'),\n",
    "        \n",
    "        # PASSIVO\n",
    "        sum(when(col('classificacao_nivel_2') == '2.01', col('saldo')).otherwise(0)).alias('passivo_circulante'),\n",
    "        sum(when(col('classificacao_nivel_2') == '2.02', col('saldo')).otherwise(0)).alias('exigivel_longo_prazo'),\n",
    "        sum(when(col('classificacao_nivel_2') == '2.03', col('saldo')).otherwise(0)).alias('patrimonio_liquido'),\n",
    "        \n",
    "        # DRE - Usar cd_conta_referencial para identificar\n",
    "        sum(when(col('cd_conta_referencial').rlike('^3\\\\.01'), col('saldo')).otherwise(0)).alias('receita_bruta'),\n",
    "        sum(when(col('cd_conta_referencial').rlike('^3\\\\.02'), col('saldo')).otherwise(0)).alias('deducoes_receita'),\n",
    "        sum(when(col('cd_conta_referencial').rlike('^3\\\\.03'), col('saldo')).otherwise(0)).alias('receita_liquida'),\n",
    "        sum(when(col('cd_conta_referencial').rlike('^3\\\\.09'), col('saldo')).otherwise(0)).alias('lucro_liquido'),\n",
    "        sum(when(col('cd_conta_referencial').rlike('^3\\\\.04'), col('saldo')).otherwise(0)).alias('custo_mercadorias')\n",
    "    )\n",
    "    \n",
    "    # Calcular √≠ndices\n",
    "    df_indicadores = df_componentes \\\n",
    "        .withColumn('exigivel_total', col('passivo_circulante') + col('exigivel_longo_prazo')) \\\n",
    "        .withColumn('recursos_nao_correntes', col('patrimonio_liquido') + col('exigivel_longo_prazo')) \\\n",
    "        \\\n",
    "        .withColumn('liquidez_corrente', \n",
    "                   when(col('passivo_circulante') != 0, \n",
    "                        col('ativo_circulante') / col('passivo_circulante')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('liquidez_geral',\n",
    "                   when(col('exigivel_total') != 0,\n",
    "                        (col('ativo_circulante') + col('realizavel_longo_prazo')) / col('exigivel_total')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('endividamento',\n",
    "                   when(col('ativo_total') != 0,\n",
    "                        col('exigivel_total') / col('ativo_total')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('participacao_capital_proprio',\n",
    "                   when(col('exigivel_total') != 0,\n",
    "                        col('patrimonio_liquido') / col('exigivel_total')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('giro_ativo',\n",
    "                   when(col('ativo_total') != 0,\n",
    "                        col('receita_liquida') / col('ativo_total')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('margem_liquida',\n",
    "                   when(col('receita_liquida') != 0,\n",
    "                        col('lucro_liquido') / col('receita_liquida')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('retorno_ativo',\n",
    "                   when(col('ativo_total') != 0,\n",
    "                        col('lucro_liquido') / col('ativo_total')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('retorno_pl',\n",
    "                   when(col('patrimonio_liquido') != 0,\n",
    "                        col('lucro_liquido') / col('patrimonio_liquido')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('imobilizacao_pl',\n",
    "                   when(col('patrimonio_liquido') != 0,\n",
    "                        col('ativo_permanente') / col('patrimonio_liquido')).otherwise(None)) \\\n",
    "        \\\n",
    "        .withColumn('imobilizacao_recursos_nc',\n",
    "                   when(col('recursos_nao_correntes') != 0,\n",
    "                        col('ativo_permanente') / col('recursos_nao_correntes')).otherwise(None))\n",
    "    \n",
    "    # Preparar tabela de empresas com campos corretos\n",
    "    df_empresas_prep = df_empresas \\\n",
    "        .select(\n",
    "            'id_ecd',\n",
    "            when(col('empresa_grande_porte') == 'Sim', lit('GRANDE'))\n",
    "                .otherwise(lit('PEQUENA/M√âDIA')).alias('porte_empresa'),\n",
    "            coalesce(col('cnae_secao_descricao'), lit('N√ÉO CLASSIFICADO')).alias('setor_atividade')\n",
    "        ) \\\n",
    "        .dropDuplicates(['id_ecd'])\n",
    "    \n",
    "    # Join com informa√ß√µes de empresa\n",
    "    df_indicadores = df_indicadores.join(\n",
    "        df_empresas_prep,\n",
    "        on='id_ecd',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Indicadores calculados para {df_indicadores.count():,} registros\")\n",
    "    \n",
    "    return df_indicadores\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C√âLULA 2: C√ÅLCULO DE √çNDICES-PADR√ÉO (DECIS)\n",
    "# ==============================================================================\n",
    "\n",
    "def calcular_indices_padrao_setoriais(df_indicadores):\n",
    "    \"\"\"\n",
    "    Calcula √≠ndices-padr√£o (decis) por setor e porte\n",
    "    Metodologia Matarazzo (1998)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìà Calculando √≠ndices-padr√£o setoriais (decis)...\")\n",
    "    \n",
    "    # Lista de indicadores para calcular decis\n",
    "    indicadores = [\n",
    "        'liquidez_corrente', 'liquidez_geral', 'endividamento',\n",
    "        'participacao_capital_proprio', 'giro_ativo', 'margem_liquida',\n",
    "        'retorno_ativo', 'retorno_pl', 'imobilizacao_pl', 'imobilizacao_recursos_nc'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar apenas registros v√°lidos (sem nulos)\n",
    "    df_validos = df_indicadores.filter(\n",
    "        ' AND '.join([f'{ind} IS NOT NULL' for ind in indicadores])\n",
    "    )\n",
    "    \n",
    "    # Calcular decis por setor e porte usando percentile_approx\n",
    "    decis_list = []\n",
    "    \n",
    "    for indicador in indicadores:\n",
    "        print(f\"  Calculando decis para: {indicador}\")\n",
    "        \n",
    "        df_decis = df_validos.groupBy('setor_atividade', 'porte_empresa').agg(\n",
    "            expr(f\"percentile_approx({indicador}, array(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9))\").alias('decis'),\n",
    "            count('*').alias('n_empresas'),\n",
    "            mean(indicador).alias('media'),\n",
    "            stddev(indicador).alias('desvio_padrao')\n",
    "        ).withColumn('indicador', lit(indicador))\n",
    "        \n",
    "        # Expandir array de decis em colunas\n",
    "        df_decis = df_decis \\\n",
    "            .withColumn('decil_1', col('decis')[0]) \\\n",
    "            .withColumn('decil_2', col('decis')[1]) \\\n",
    "            .withColumn('decil_3', col('decis')[2]) \\\n",
    "            .withColumn('decil_4', col('decis')[3]) \\\n",
    "            .withColumn('mediana', col('decis')[4]) \\\n",
    "            .withColumn('decil_6', col('decis')[5]) \\\n",
    "            .withColumn('decil_7', col('decis')[6]) \\\n",
    "            .withColumn('decil_8', col('decis')[7]) \\\n",
    "            .withColumn('decil_9', col('decis')[8]) \\\n",
    "            .drop('decis')\n",
    "        \n",
    "        decis_list.append(df_decis)\n",
    "    \n",
    "    # Consolidar todos os decis\n",
    "    df_indices_padrao = decis_list[0]\n",
    "    for df in decis_list[1:]:\n",
    "        df_indices_padrao = df_indices_padrao.union(df)\n",
    "    \n",
    "    print(f\"‚úÖ √çndices-padr√£o calculados: {df_indices_padrao.count():,} registros\")\n",
    "    \n",
    "    return df_indices_padrao\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C√âLULA 3: CLASSIFICA√á√ÉO POR √çNDICES-PADR√ÉO\n",
    "# ==============================================================================\n",
    "\n",
    "def classificar_por_indices_padrao(df_indicadores, df_indices_padrao):\n",
    "    \"\"\"\n",
    "    Classifica empresas usando escala qualitativa de Matarazzo:\n",
    "    P√âSSIMO, DEFICIENTE, FRACO, RAZO√ÅVEL, SATISFAT√ìRIO, BOM, √ìTIMO\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ Classificando empresas por √≠ndices-padr√£o...\")\n",
    "    \n",
    "    # Fun√ß√£o para determinar conceito baseado em decis\n",
    "    def classificar_decil(valor, decis, quanto_maior_melhor=True):\n",
    "        \"\"\"\n",
    "        Quanto maior melhor: liquidez, rentabilidade\n",
    "        Quanto menor melhor: endividamento, imobiliza√ß√£o\n",
    "        \"\"\"\n",
    "        if quanto_maior_melhor:\n",
    "            return when(valor >= decis['decil_9'], lit('√ìTIMO')) \\\n",
    "                .when(valor >= decis['decil_8'], lit('BOM')) \\\n",
    "                .when(valor >= decis['decil_6'], lit('SATISFAT√ìRIO')) \\\n",
    "                .when(valor >= decis['mediana'], lit('RAZO√ÅVEL')) \\\n",
    "                .when(valor >= decis['decil_3'], lit('FRACO')) \\\n",
    "                .when(valor >= decis['decil_1'], lit('DEFICIENTE')) \\\n",
    "                .otherwise(lit('P√âSSIMO'))\n",
    "        else:\n",
    "            return when(valor <= decis['decil_1'], lit('√ìTIMO')) \\\n",
    "                .when(valor <= decis['decil_2'], lit('BOM')) \\\n",
    "                .when(valor <= decis['decil_4'], lit('SATISFAT√ìRIO')) \\\n",
    "                .when(valor <= decis['mediana'], lit('RAZO√ÅVEL')) \\\n",
    "                .when(valor <= decis['decil_7'], lit('FRACO')) \\\n",
    "                .when(valor <= decis['decil_9'], lit('DEFICIENTE')) \\\n",
    "                .otherwise(lit('P√âSSIMO'))\n",
    "    \n",
    "    # Mapear dire√ß√£o de cada indicador\n",
    "    direcao_indicadores = {\n",
    "        # Quanto maior, melhor\n",
    "        'liquidez_corrente': True,\n",
    "        'liquidez_geral': True,\n",
    "        'participacao_capital_proprio': True,\n",
    "        'giro_ativo': True,\n",
    "        'margem_liquida': True,\n",
    "        'retorno_ativo': True,\n",
    "        'retorno_pl': True,\n",
    "        # Quanto menor, melhor\n",
    "        'endividamento': False,\n",
    "        'imobilizacao_pl': False,\n",
    "        'imobilizacao_recursos_nc': False\n",
    "    }\n",
    "    \n",
    "    # Join com √≠ndices-padr√£o e classificar\n",
    "    df_classificado = df_indicadores\n",
    "    \n",
    "    for indicador, maior_melhor in direcao_indicadores.items():\n",
    "        # Join com tabela de decis\n",
    "        df_decis_ind = df_indices_padrao.filter(col('indicador') == indicador) \\\n",
    "            .select('setor_atividade', 'porte_empresa', 'mediana', \n",
    "                   'decil_1', 'decil_2', 'decil_3', 'decil_4', \n",
    "                   'decil_6', 'decil_7', 'decil_8', 'decil_9')\n",
    "        \n",
    "        df_classificado = df_classificado.join(\n",
    "            df_decis_ind,\n",
    "            on=['setor_atividade', 'porte_empresa'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Aplicar classifica√ß√£o\n",
    "        df_classificado = df_classificado.withColumn(\n",
    "            f'conceito_{indicador}',\n",
    "            classificar_decil(col(indicador), {\n",
    "                'mediana': 'mediana',\n",
    "                'decil_1': 'decil_1', 'decil_2': 'decil_2', 'decil_3': 'decil_3',\n",
    "                'decil_4': 'decil_4', 'decil_6': 'decil_6', 'decil_7': 'decil_7',\n",
    "                'decil_8': 'decil_8', 'decil_9': 'decil_9'\n",
    "            }, maior_melhor)\n",
    "        )\n",
    "        \n",
    "        # Limpar colunas tempor√°rias\n",
    "        df_classificado = df_classificado.drop('mediana', 'decil_1', 'decil_2', 'decil_3',\n",
    "                                               'decil_4', 'decil_6', 'decil_7', 'decil_8', 'decil_9')\n",
    "    \n",
    "    print(f\"‚úÖ Empresas classificadas: {df_classificado.count():,} registros\")\n",
    "    \n",
    "    return df_classificado\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C√âLULA 4: FATOR DE INSOLV√äNCIA DE KANITZ\n",
    "# ==============================================================================\n",
    "\n",
    "def calcular_fator_kanitz(df_indicadores):\n",
    "    \"\"\"\n",
    "    Calcula o Fator de Insolv√™ncia de Kanitz\n",
    "    FI = 0.05*X1 + 1.65*X2 + 3.55*X3 - 1.06*X4 - 0.33*X5\n",
    "    \n",
    "    Interpreta√ß√£o:\n",
    "    - FI > 0: Solvente (baixo risco)\n",
    "    - -3 < FI <= 0: Penumbra (risco moderado)\n",
    "    - FI <= -3: Insolvente (alto risco)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"‚öñÔ∏è Calculando Fator de Insolv√™ncia de Kanitz...\")\n",
    "    \n",
    "    df_kanitz = df_indicadores \\\n",
    "        .withColumn('x1_roa', col('retorno_ativo')) \\\n",
    "        .withColumn('x2_liquidez_ajustada', \n",
    "                   when((col('passivo_circulante') + col('exigivel_longo_prazo')) != 0,\n",
    "                        (col('ativo_circulante') + col('realizavel_longo_prazo')) / \n",
    "                        (col('passivo_circulante') + col('exigivel_longo_prazo'))).otherwise(None)) \\\n",
    "        .withColumn('x3_liquidez_seca',\n",
    "                   when(col('passivo_circulante') != 0,\n",
    "                        (col('ativo_circulante') - col('custo_mercadorias')) / col('passivo_circulante')).otherwise(None)) \\\n",
    "        .withColumn('x4_liquidez_corrente', col('liquidez_corrente')) \\\n",
    "        .withColumn('x5_endividamento_pl',\n",
    "                   when(col('patrimonio_liquido') != 0,\n",
    "                        (col('passivo_circulante') + col('exigivel_longo_prazo')) / col('patrimonio_liquido')).otherwise(None))\n",
    "    \n",
    "    # Calcular Fator de Kanitz\n",
    "    df_kanitz = df_kanitz.withColumn(\n",
    "        'fator_kanitz',\n",
    "        (0.05 * col('x1_roa')) +\n",
    "        (1.65 * col('x2_liquidez_ajustada')) +\n",
    "        (3.55 * col('x3_liquidez_seca')) -\n",
    "        (1.06 * col('x4_liquidez_corrente')) -\n",
    "        (0.33 * col('x5_endividamento_pl'))\n",
    "    )\n",
    "    \n",
    "    # Classificar situa√ß√£o financeira\n",
    "    df_kanitz = df_kanitz.withColumn(\n",
    "        'situacao_kanitz',\n",
    "        when(col('fator_kanitz') > 0, lit('SOLVENTE'))\n",
    "        .when(col('fator_kanitz') > -3, lit('PENUMBRA'))\n",
    "        .otherwise(lit('INSOLVENTE'))\n",
    "    )\n",
    "    \n",
    "    # Adicionar score normalizado (0-100)\n",
    "    df_kanitz = df_kanitz.withColumn(\n",
    "        'score_kanitz',\n",
    "        when(col('fator_kanitz') >= 0, \n",
    "             least(lit(100), 50 + (col('fator_kanitz') * 10)))\n",
    "        .when(col('fator_kanitz') >= -3,\n",
    "             least(lit(50), greatest(lit(25), 50 + (col('fator_kanitz') * 8.33))))\n",
    "        .otherwise(\n",
    "             greatest(lit(0), 25 + ((col('fator_kanitz') + 3) * 8.33)))\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Fator Kanitz calculado: {df_kanitz.count():,} registros\")\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    df_kanitz.groupBy('situacao_kanitz').count().orderBy(desc('count')).show()\n",
    "    \n",
    "    return df_kanitz\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C√âLULA 5: CLASSIFICA√á√ÉO H√çBRIDA (COMBINANDO 3 METODOLOGIAS)\n",
    "# ==============================================================================\n",
    "\n",
    "def criar_classificacao_hibrida(df_saldos, df_empresas, df_ml_features):\n",
    "    \"\"\"\n",
    "    Combina 3 metodologias de classifica√ß√£o:\n",
    "    1. Estrutural (SQL/Regras) - 30%\n",
    "    2. √çndices-Padr√£o (Matarazzo) - 40%\n",
    "    3. Features ML (Dicion√°rios Tem√°ticos) - 30%\n",
    "    \n",
    "    Retorna score ponderado e classifica√ß√£o final\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÑ Criando classifica√ß√£o h√≠brida...\")\n",
    "    \n",
    "    # 1. Calcular indicadores financeiros\n",
    "    df_indicadores = calcular_indicadores_economico_financeiros(df_saldos, df_empresas)\n",
    "    \n",
    "    # 2. Calcular √≠ndices-padr√£o setoriais\n",
    "    df_indices_padrao = calcular_indices_padrao_setoriais(df_indicadores)\n",
    "    \n",
    "    # 3. Classificar por √≠ndices-padr√£o\n",
    "    df_class_padrao = classificar_por_indices_padrao(df_indicadores, df_indices_padrao)\n",
    "    \n",
    "    # 4. Calcular Fator Kanitz\n",
    "    df_kanitz = calcular_fator_kanitz(df_class_padrao)\n",
    "    \n",
    "    # 5. Converter conceitos em scores (0-100)\n",
    "    conceito_to_score = {\n",
    "        'P√âSSIMO': 10,\n",
    "        'DEFICIENTE': 25,\n",
    "        'FRACO': 40,\n",
    "        'RAZO√ÅVEL': 55,\n",
    "        'SATISFAT√ìRIO': 70,\n",
    "        'BOM': 85,\n",
    "        '√ìTIMO': 100\n",
    "    }\n",
    "    \n",
    "    # Criar mapping UDF\n",
    "    conceito_mapping = create_map([lit(x) for pair in conceito_to_score.items() for x in pair])\n",
    "    \n",
    "    # Calcular scores de cada metodologia\n",
    "    df_hibrido = df_kanitz\n",
    "    \n",
    "    # ============================================================================\n",
    "    # CALCULAR SCORE H√çBRIDO (VERS√ÉO CORRIGIDA)\n",
    "    # ============================================================================\n",
    "    \n",
    "    # Lista de indicadores\n",
    "    indicadores_conceito = [\n",
    "        'conceito_liquidez_corrente', \n",
    "        'conceito_liquidez_geral',\n",
    "        'conceito_endividamento', \n",
    "        'conceito_retorno_ativo', \n",
    "        'conceito_retorno_pl'\n",
    "    ]\n",
    "    \n",
    "    # Criar scores individuais\n",
    "    for col_conceito in indicadores_conceito:\n",
    "        df_hibrido = df_hibrido.withColumn(\n",
    "            f'score_{col_conceito}',\n",
    "            conceito_mapping[col(col_conceito)]\n",
    "        )\n",
    "    \n",
    "    # Score Estrutural (m√©dia) ‚úÖ LINHA CORRIGIDA\n",
    "    df_hibrido = df_hibrido.withColumn(\n",
    "        'score_estrutural',\n",
    "        (\n",
    "            coalesce(col('score_conceito_liquidez_corrente'), lit(0)) +\n",
    "            coalesce(col('score_conceito_liquidez_geral'), lit(0)) +\n",
    "            coalesce(col('score_conceito_endividamento'), lit(0)) +\n",
    "            coalesce(col('score_conceito_retorno_ativo'), lit(0)) +\n",
    "            coalesce(col('score_conceito_retorno_pl'), lit(0))\n",
    "        ) / 5.0\n",
    "    )\n",
    "    \n",
    "    # Score √çndices-Padr√£o\n",
    "    df_hibrido = df_hibrido.withColumn('score_indices_padrao', col('score_kanitz'))\n",
    "    \n",
    "    # Score ML\n",
    "    df_hibrido = df_hibrido.join(\n",
    "        df_ml_features.select('id_ecd', 'dt_referencia', \n",
    "                             (col('confianca_media') * 100).alias('score_ml')),\n",
    "        on=['id_ecd', 'dt_referencia'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Score Final H√≠brido\n",
    "    df_hibrido = df_hibrido.withColumn(\n",
    "        'score_hibrido',\n",
    "        (coalesce(col('score_estrutural'), lit(0)) * 0.30) +\n",
    "        (coalesce(col('score_indices_padrao'), lit(0)) * 0.40) +\n",
    "        (coalesce(col('score_ml'), lit(0)) * 0.30)\n",
    "    )\n",
    "    \n",
    "    # Classifica√ß√£o Final\n",
    "    df_hibrido = df_hibrido.withColumn(\n",
    "        'classificacao_hibrida',\n",
    "        when(col('score_hibrido') >= 85, lit('EXCELENTE'))\n",
    "        .when(col('score_hibrido') >= 70, lit('BOM'))\n",
    "        .when(col('score_hibrido') >= 55, lit('REGULAR'))\n",
    "        .when(col('score_hibrido') >= 40, lit('RUIM'))\n",
    "        .otherwise(lit('CR√çTICO'))\n",
    "    )\n",
    "    \n",
    "    df_hibrido = df_hibrido.withColumn(\n",
    "        'nivel_risco',\n",
    "        when(col('score_hibrido') >= 70, lit('BAIXO'))\n",
    "        .when(col('score_hibrido') >= 50, lit('M√âDIO'))\n",
    "        .when(col('score_hibrido') >= 30, lit('ALTO'))\n",
    "        .otherwise(lit('CR√çTICO'))\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Classifica√ß√£o h√≠brida completa!\")\n",
    "    \n",
    "    # Estat√≠sticas finais\n",
    "    print(\"\\nüìä Distribui√ß√£o da Classifica√ß√£o H√≠brida:\")\n",
    "    df_hibrido.groupBy('classificacao_hibrida', 'nivel_risco').count().orderBy(desc('count')).show()\n",
    "    \n",
    "    return df_hibrido, df_indices_padrao\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C√âLULA 6: SALVAR RESULTADOS EM TABELAS HIVE\n",
    "# ==============================================================================\n",
    "\n",
    "def salvar_analise_indices_padrao(spark, df_hibrido, df_indices_padrao):\n",
    "    \"\"\"\n",
    "    Salva todos os resultados em tabelas Hive\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üíæ Salvando resultados em tabelas Hive...\")\n",
    "    \n",
    "    # 1. Tabela de indicadores e classifica√ß√£o h√≠brida\n",
    "    print(\"  Salvando: teste.ecd_indicadores_hibrido\")\n",
    "    df_hibrido.write.mode('overwrite').saveAsTable('teste.ecd_indicadores_hibrido')\n",
    "    \n",
    "    # 2. Tabela de √≠ndices-padr√£o setoriais (decis)\n",
    "    print(\"  Salvando: teste.ecd_indices_padrao_setoriais\")\n",
    "    df_indices_padrao.write.mode('overwrite').saveAsTable('teste.ecd_indices_padrao_setoriais')\n",
    "    \n",
    "    # 3. Tabela resumo por empresa (√∫ltima classifica√ß√£o)\n",
    "    print(\"  Salvando: teste.ecd_empresas_classificacao_resumo\")\n",
    "    window_ultima = Window.partitionBy('id_ecd').orderBy(desc('dt_referencia'))\n",
    "    \n",
    "    df_resumo = df_hibrido \\\n",
    "        .withColumn('rn', row_number().over(window_ultima)) \\\n",
    "        .filter(col('rn') == 1) \\\n",
    "        .select(\n",
    "            'id_ecd', 'dt_referencia', 'setor_atividade', 'porte_empresa',\n",
    "            'score_estrutural', 'score_indices_padrao', 'score_ml', 'score_hibrido',\n",
    "            'classificacao_hibrida', 'nivel_risco', 'situacao_kanitz', 'fator_kanitz',\n",
    "            'liquidez_corrente', 'liquidez_geral', 'endividamento',\n",
    "            'retorno_ativo', 'retorno_pl', 'margem_liquida'\n",
    "        ) \\\n",
    "        .drop('rn')\n",
    "    \n",
    "    df_resumo.write.mode('overwrite').saveAsTable('teste.ecd_empresas_classificacao_resumo')\n",
    "    \n",
    "    # 4. Tabela de evolu√ß√£o temporal\n",
    "    print(\"  Salvando: teste.ecd_evolucao_scores\")\n",
    "    df_evolucao = df_hibrido.select(\n",
    "        'id_ecd', 'dt_referencia', \n",
    "        'score_estrutural', 'score_indices_padrao', 'score_ml', 'score_hibrido',\n",
    "        'classificacao_hibrida', 'nivel_risco'\n",
    "    )\n",
    "    \n",
    "    df_evolucao.write.mode('overwrite').saveAsTable('teste.ecd_evolucao_scores')\n",
    "    \n",
    "    # 5. Tabela de empresas em situa√ß√£o cr√≠tica\n",
    "    print(\"  Salvando: teste.ecd_empresas_criticas\")\n",
    "    df_criticas = df_hibrido.filter(\n",
    "        (col('nivel_risco').isin(['ALTO', 'CR√çTICO'])) |\n",
    "        (col('situacao_kanitz') == 'INSOLVENTE') |\n",
    "        (col('score_hibrido') < 40)\n",
    "    ).select(\n",
    "        'id_ecd', 'dt_referencia', 'setor_atividade', 'porte_empresa',\n",
    "        'score_hibrido', 'nivel_risco', 'situacao_kanitz', 'fator_kanitz',\n",
    "        'classificacao_hibrida'\n",
    "    )\n",
    "    \n",
    "    df_criticas.write.mode('overwrite').saveAsTable('teste.ecd_empresas_criticas')\n",
    "    \n",
    "    print(\"\\n‚úÖ Todas as tabelas salvas com sucesso!\")\n",
    "    print(\"\\nTabelas dispon√≠veis:\")\n",
    "    print(\"  1. teste.ecd_indicadores_hibrido - An√°lise completa\")\n",
    "    print(\"  2. teste.ecd_indices_padrao_setoriais - Decis setoriais\")\n",
    "    print(\"  3. teste.ecd_empresas_classificacao_resumo - Resumo por empresa\")\n",
    "    print(\"  4. teste.ecd_evolucao_scores - Evolu√ß√£o temporal\")\n",
    "    print(\"  5. teste.ecd_empresas_criticas - Empresas em risco\")\n",
    "    \n",
    "    return {\n",
    "        'indicadores_hibrido': df_hibrido,\n",
    "        'indices_padrao': df_indices_padrao,\n",
    "        'resumo': df_resumo,\n",
    "        'evolucao': df_evolucao,\n",
    "        'criticas': df_criticas\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXEMPLO DE USO COMPLETO COM CAMPOS CORRETOS\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 1: CARREGAR DADOS COM NOMES CORRETOS\n",
    "# ============================================================================\n",
    "df_saldos, df_empresas, df_ml = carregar_dados_ecd_filtrados()\n",
    "df_empresas = spark.table('teste.ecd_empresas_cadastro')\n",
    "df_ml_features = spark.table('teste.ecd_ml_empresas_resumo')\n",
    "\n",
    "print(f\"üìä Dados carregados:\")\n",
    "print(f\"   - Saldos: {df_saldos.count():,} registros\")\n",
    "print(f\"   - Empresas: {df_empresas.count():,} registros\")\n",
    "print(f\"   - ML Features: {df_ml_features.count():,} registros\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 2: CALCULAR INDICADORES (VERS√ÉO CORRIGIDA)\n",
    "# ============================================================================\n",
    "df_indicadores = calcular_indicadores_economico_financeiros(df_saldos, df_empresas)\n",
    "\n",
    "print(f\"‚úÖ Indicadores calculados\")\n",
    "df_indicadores.printSchema()\n",
    "df_indicadores.select('id_ecd', 'dt_referencia', 'liquidez_corrente', \n",
    "                     'retorno_ativo', 'endividamento').show(10)\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 3: CALCULAR √çNDICES-PADR√ÉO SETORIAIS\n",
    "# ============================================================================\n",
    "df_indices_padrao = calcular_indices_padrao_setoriais(df_indicadores)\n",
    "\n",
    "print(f\"‚úÖ √çndices-padr√£o calculados\")\n",
    "df_indices_padrao.show(10)\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 4: CALCULAR FATOR KANITZ\n",
    "# ============================================================================\n",
    "df_kanitz = calcular_fator_kanitz(df_indicadores)\n",
    "\n",
    "print(f\"‚úÖ Fator Kanitz calculado\")\n",
    "df_kanitz.groupBy('situacao_kanitz').count().show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 5: CRIAR CLASSIFICA√á√ÉO H√çBRIDA (VERS√ÉO CORRIGIDA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÑ Criando classifica√ß√£o h√≠brida...\")\n",
    "\n",
    "# Classificar por √≠ndices-padr√£o\n",
    "df_class_padrao = classificar_por_indices_padrao(df_indicadores, df_indices_padrao)\n",
    "\n",
    "# ‚úÖ CORRE√á√ÉO 1: Remover colunas duplicadas ANTES do JOIN\n",
    "colunas_para_dropar = [\n",
    "    'ativo_circulante', 'realizavel_longo_prazo', 'ativo_permanente', 'ativo_total',\n",
    "    'passivo_circulante', 'exigivel_longo_prazo', 'patrimonio_liquido',\n",
    "    'receita_bruta', 'deducoes_receita', 'receita_liquida', 'lucro_liquido', 'custo_mercadorias',\n",
    "    'exigivel_total', 'recursos_nao_correntes',\n",
    "    'liquidez_corrente', 'liquidez_geral', 'endividamento', 'participacao_capital_proprio',\n",
    "    'giro_ativo', 'margem_liquida', 'retorno_ativo', 'retorno_pl',\n",
    "    'imobilizacao_pl', 'imobilizacao_recursos_nc',\n",
    "    'setor_atividade', 'porte_empresa'\n",
    "]\n",
    "\n",
    "# Dropar colunas do df_class_padrao que j√° existem em df_kanitz\n",
    "df_class_padrao_limpo = df_class_padrao.drop(*[c for c in colunas_para_dropar if c in df_class_padrao.columns])\n",
    "\n",
    "# Juntar com Kanitz (agora sem duplicatas)\n",
    "df_hibrido = df_kanitz.join(\n",
    "    df_class_padrao_limpo,\n",
    "    on=['id_ecd', 'dt_referencia'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ JOIN realizado sem duplicatas: {len(df_hibrido.columns)} colunas\")\n",
    "\n",
    "# Criar scores h√≠bridos\n",
    "conceito_to_score = {\n",
    "    'P√âSSIMO': 10, 'DEFICIENTE': 25, 'FRACO': 40,\n",
    "    'RAZO√ÅVEL': 55, 'SATISFAT√ìRIO': 70, 'BOM': 85, '√ìTIMO': 100\n",
    "}\n",
    "conceito_mapping = create_map([lit(x) for pair in conceito_to_score.items() for x in pair])\n",
    "\n",
    "# Score estrutural (m√©dia dos conceitos)\n",
    "indicadores_conceito = [\n",
    "    'conceito_liquidez_corrente', 'conceito_liquidez_geral',\n",
    "    'conceito_endividamento', 'conceito_retorno_ativo', 'conceito_retorno_pl'\n",
    "]\n",
    "\n",
    "for col_conceito in indicadores_conceito:\n",
    "    df_hibrido = df_hibrido.withColumn(\n",
    "        f'score_{col_conceito}',\n",
    "        conceito_mapping[col(col_conceito)]\n",
    "    )\n",
    "\n",
    "df_hibrido = df_hibrido.withColumn(\n",
    "    'score_estrutural',\n",
    "    (\n",
    "        coalesce(col('score_conceito_liquidez_corrente'), lit(0)) +\n",
    "        coalesce(col('score_conceito_liquidez_geral'), lit(0)) +\n",
    "        coalesce(col('score_conceito_endividamento'), lit(0)) +\n",
    "        coalesce(col('score_conceito_retorno_ativo'), lit(0)) +\n",
    "        coalesce(col('score_conceito_retorno_pl'), lit(0))\n",
    "    ) / 5.0\n",
    ")\n",
    "\n",
    "# Score √≠ndices-padr√£o (Kanitz normalizado)\n",
    "df_hibrido = df_hibrido.withColumn('score_indices_padrao', col('score_kanitz'))\n",
    "\n",
    "# Score ML\n",
    "df_hibrido = df_hibrido.join(\n",
    "    df_ml_features.select('id_ecd', 'dt_referencia', \n",
    "                         (col('confianca_media') * 100).alias('score_ml')),\n",
    "    on=['id_ecd', 'dt_referencia'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Score Final H√≠brido\n",
    "df_hibrido = df_hibrido.withColumn(\n",
    "    'score_hibrido',\n",
    "    (coalesce(col('score_estrutural'), lit(0)) * 0.30) +\n",
    "    (coalesce(col('score_indices_padrao'), lit(0)) * 0.40) +\n",
    "    (coalesce(col('score_ml'), lit(0)) * 0.30)\n",
    ")\n",
    "\n",
    "# Classifica√ß√£o final\n",
    "df_hibrido = df_hibrido.withColumn(\n",
    "    'classificacao_hibrida',\n",
    "    when(col('score_hibrido') >= 85, lit('EXCELENTE'))\n",
    "    .when(col('score_hibrido') >= 70, lit('BOM'))\n",
    "    .when(col('score_hibrido') >= 55, lit('REGULAR'))\n",
    "    .when(col('score_hibrido') >= 40, lit('RUIM'))\n",
    "    .otherwise(lit('CR√çTICO'))\n",
    ")\n",
    "\n",
    "df_hibrido = df_hibrido.withColumn(\n",
    "    'nivel_risco',\n",
    "    when(col('score_hibrido') >= 70, lit('BAIXO'))\n",
    "    .when(col('score_hibrido') >= 50, lit('M√âDIO'))\n",
    "    .when(col('score_hibrido') >= 30, lit('ALTO'))\n",
    "    .otherwise(lit('CR√çTICO'))\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Classifica√ß√£o h√≠brida completa!\")\n",
    "\n",
    "# Estat√≠sticas\n",
    "df_hibrido.groupBy('classificacao_hibrida', 'nivel_risco').count().orderBy(desc('count')).show()\n",
    "\n",
    "# ============================================================================\n",
    "# SALVAR TABELAS (VERS√ÉO FINAL CORRIGIDA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüíæ Salvando tabelas...\")\n",
    "\n",
    "# ‚úÖ CORRE√á√ÉO 2: Verificar se h√° duplicatas\n",
    "colunas_originais = df_hibrido.columns\n",
    "colunas_unicas = list(dict.fromkeys(colunas_originais))  # Remove duplicatas mantendo ordem\n",
    "\n",
    "if len(colunas_originais) != len(colunas_unicas):\n",
    "    print(f\"  ‚ö†Ô∏è Encontradas {len(colunas_originais) - len(colunas_unicas)} colunas duplicadas\")\n",
    "    duplicadas = [c for c in colunas_unicas if colunas_originais.count(c) > 1]\n",
    "    print(f\"  Colunas duplicadas: {duplicadas}\")\n",
    "    \n",
    "    # Reconstruir DataFrame sem duplicatas\n",
    "    df_hibrido = df_hibrido.toDF(*[f\"{c}_{i}\" if colunas_originais[:idx].count(c) > 0 else c \n",
    "                                    for idx, c in enumerate(colunas_originais) \n",
    "                                    for i in [colunas_originais[:idx].count(c)]])\n",
    "    \n",
    "    # Selecionar apenas primeiras ocorr√™ncias\n",
    "    df_hibrido = df_hibrido.select(colunas_unicas)\n",
    "\n",
    "print(f\"  ‚úÖ DataFrame final: {len(df_hibrido.columns)} colunas\")\n",
    "\n",
    "# 1. Indicadores completos\n",
    "print(\"  Salvando: teste.ecd_indicadores_hibrido\")\n",
    "df_hibrido.write.mode('overwrite').saveAsTable('teste.ecd_indicadores_hibrido')\n",
    "\n",
    "# 2. √çndices-padr√£o setoriais\n",
    "print(\"  Salvando: teste.ecd_indices_padrao_setoriais\")\n",
    "df_indices_padrao.write.mode('overwrite').saveAsTable('teste.ecd_indices_padrao_setoriais')\n",
    "\n",
    "# 3. Resumo por empresa (√∫ltima data)\n",
    "print(\"  Salvando: teste.ecd_empresas_classificacao_resumo\")\n",
    "window_ultima = Window.partitionBy('id_ecd').orderBy(desc('dt_referencia'))\n",
    "df_resumo = df_hibrido \\\n",
    "    .withColumn('rn', row_number().over(window_ultima)) \\\n",
    "    .filter(col('rn') == 1) \\\n",
    "    .drop('rn')\n",
    "\n",
    "# Selecionar colunas importantes\n",
    "colunas_resumo = [\n",
    "    'id_ecd', 'dt_referencia', 'setor_atividade', 'porte_empresa',\n",
    "    'score_estrutural', 'score_indices_padrao', 'score_ml', 'score_hibrido',\n",
    "    'classificacao_hibrida', 'nivel_risco', 'situacao_kanitz', 'fator_kanitz',\n",
    "    'liquidez_corrente', 'liquidez_geral', 'endividamento',\n",
    "    'retorno_ativo', 'retorno_pl', 'margem_liquida'\n",
    "]\n",
    "colunas_resumo_existentes = [c for c in colunas_resumo if c in df_hibrido.columns]\n",
    "df_resumo.select(colunas_resumo_existentes).write.mode('overwrite').saveAsTable('teste.ecd_empresas_classificacao_resumo')\n",
    "\n",
    "# 4. Evolu√ß√£o temporal\n",
    "print(\"  Salvando: teste.ecd_evolucao_scores\")\n",
    "colunas_evolucao = [\n",
    "    'id_ecd', 'dt_referencia',\n",
    "    'score_estrutural', 'score_indices_padrao', 'score_ml', 'score_hibrido',\n",
    "    'classificacao_hibrida', 'nivel_risco'\n",
    "]\n",
    "colunas_evolucao_existentes = [c for c in colunas_evolucao if c in df_hibrido.columns]\n",
    "df_hibrido.select(colunas_evolucao_existentes).write.mode('overwrite').saveAsTable('teste.ecd_evolucao_scores')\n",
    "\n",
    "# 5. Empresas cr√≠ticas\n",
    "print(\"  Salvando: teste.ecd_empresas_criticas\")\n",
    "df_criticas = df_hibrido.filter(\n",
    "    (col('nivel_risco').isin(['ALTO', 'CR√çTICO'])) |\n",
    "    (col('situacao_kanitz') == 'INSOLVENTE') |\n",
    "    (col('score_hibrido') < 40)\n",
    ")\n",
    "colunas_criticas = [\n",
    "    'id_ecd', 'dt_referencia', 'setor_atividade', 'porte_empresa',\n",
    "    'score_hibrido', 'nivel_risco', 'situacao_kanitz', 'fator_kanitz',\n",
    "    'classificacao_hibrida'\n",
    "]\n",
    "colunas_criticas_existentes = [c for c in colunas_criticas if c in df_criticas.columns]\n",
    "df_criticas.select(colunas_criticas_existentes).write.mode('overwrite').saveAsTable('teste.ecd_empresas_criticas')\n",
    "\n",
    "print(\"\\n‚úÖ Todas as tabelas salvas com sucesso!\")\n",
    "print(\"\\nüìã Tabelas criadas:\")\n",
    "print(\"  1. teste.ecd_indicadores_hibrido\")\n",
    "print(\"  2. teste.ecd_indices_padrao_setoriais\")\n",
    "print(\"  3. teste.ecd_empresas_classificacao_resumo\")\n",
    "print(\"  4. teste.ecd_evolucao_scores\")\n",
    "print(\"  5. teste.ecd_empresas_criticas\")\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(\"\\nüìä ESTAT√çSTICAS FINAIS:\")\n",
    "print(f\"\\nEmpresas Cr√≠ticas: {spark.table('teste.ecd_empresas_criticas').count():,}\")\n",
    "\n",
    "print(\"\\nTop 10 Melhores:\")\n",
    "spark.table('teste.ecd_empresas_classificacao_resumo') \\\n",
    "    .select('id_ecd', 'score_hibrido', 'classificacao_hibrida', 'nivel_risco') \\\n",
    "    .orderBy(desc('score_hibrido')).show(10)\n",
    "\n",
    "print(\"\\n‚úÖ AN√ÅLISE H√çBRIDA CONCLU√çDA!\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PASSO 7: VALIDA√á√ïES\n",
    "# ============================================================================\n",
    "print(\"\\nüìä ESTAT√çSTICAS FINAIS:\")\n",
    "\n",
    "print(\"\\nDistribui√ß√£o de Classifica√ß√£o:\")\n",
    "spark.table('teste.ecd_empresas_classificacao_resumo') \\\n",
    "    .groupBy('classificacao_hibrida', 'nivel_risco').count() \\\n",
    "    .orderBy(desc('count')).show()\n",
    "\n",
    "print(\"\\nEmpresas Cr√≠ticas:\")\n",
    "print(f\"Total: {spark.table('teste.ecd_empresas_criticas').count():,}\")\n",
    "\n",
    "print(\"\\nTop 10 Melhores Empresas:\")\n",
    "spark.table('teste.ecd_empresas_classificacao_resumo') \\\n",
    "    .select('id_ecd', 'setor_atividade', 'score_hibrido', \n",
    "            'classificacao_hibrida', 'nivel_risco') \\\n",
    "    .orderBy(desc('score_hibrido')) \\\n",
    "    .show(10, truncate=False)\n",
    "\n",
    "print(\"\\n‚úÖ AN√ÅLISE H√çBRIDA CONCLU√çDA COM SUCESSO!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Pipeline)",
   "language": "python",
   "name": "conda_data_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
