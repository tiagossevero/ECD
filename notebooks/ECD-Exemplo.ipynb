{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aea681-2477-45f5-9ffe-1cb8f6cb1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "#Import libs python\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "\n",
    "#Import libs internas\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "from hooks.hdfs.hdfs_helper import HdfsHelper\n",
    "from jobs.job_base_config import BaseETLJobClass\n",
    "\n",
    "import poc_helper\n",
    "poc_helper.load_env(\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf8a1f-48e4-4c57-a162-c839c8e3a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_session(profile: str, dynamic_allocation_enabled: bool = True) -> utils.DBASparkAppSession:\n",
    "    \"\"\"Generates DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"tsevero_ecd\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "session = get_session(profile='efd_t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00777b24-69dc-4a6e-ba6f-4e11cd534937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session.sparkSession.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2b9e6-be5f-4120-99be-8d828e7bbc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 1: CONFIGURA√á√ÉO INICIAL - PROJETO ECD\n",
    "# ============================================================================\n",
    "# Escritura√ß√£o Cont√°bil Digital - An√°lise Completa\n",
    "# Auditor Fiscal da Receita Estadual de SC\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PySpark imports com aliases para evitar conflitos\n",
    "from pyspark.sql.functions import (\n",
    "    col as spark_col, \n",
    "    sum as spark_sum, \n",
    "    avg as spark_avg,\n",
    "    count as spark_count,\n",
    "    when as spark_when,\n",
    "    desc as spark_desc,\n",
    "    asc as spark_asc,\n",
    "    round as spark_round,\n",
    "    coalesce as spark_coalesce,\n",
    "    max as spark_max,\n",
    "    min as spark_min,\n",
    "    stddev as spark_stddev,\n",
    "    lit as spark_lit,\n",
    "    concat as spark_concat,\n",
    "    expr as spark_expr,\n",
    "    abs as spark_abs\n",
    ")\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# Acesso ao SparkSession\n",
    "spark = session.sparkSession\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "# Configura√ß√£o de estilo para gr√°ficos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Verificar se spark existe na sess√£o\n",
    "try:\n",
    "    spark\n",
    "    print(\"‚úÖ Sess√£o Spark j√° ativa!\")\n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è Sess√£o Spark n√£o encontrada. Por favor, inicialize a sess√£o Spark.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ PROJETO ECD - AN√ÅLISE EXPLORAT√ìRIA E MACHINE LEARNING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìÖ Data de execu√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(\"üìä Bibliotecas carregadas com sucesso!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73145a-982a-48d8-86f4-b19cb3e8410a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 2: VIS√ÉO GERAL DOS DADOS ECD (Vers√£o com TQDM e Status)\n",
    "# ============================================================================\n",
    "\n",
    "# --- Importa√ß√µes Necess√°rias ---\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Assumindo que a vari√°vel 'spark' j√° est√° definida no seu ambiente.\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä VIS√ÉO GERAL - TABELAS ECD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONTAGEM DE REGISTROS POR TABELA\n",
    "# ============================================================================\n",
    "\n",
    "tabelas_ecd = [\n",
    "    'teste.ecd_empresas_cadastro',\n",
    "    'teste.ecd_plano_contas',\n",
    "    'teste.ecd_saldos_contas',\n",
    "    'teste.ecd_balanco_patrimonial',\n",
    "    'teste.ecd_dre',\n",
    "    'teste.ecd_indicadores_financeiros',\n",
    "    'teste.ecd_inconsistencias_equacao',\n",
    "    'teste.ecd_benchmark_setorial',  # Esta n√£o tem CNPJ!\n",
    "    'teste.ecd_score_risco_consolidado'\n",
    "]\n",
    "\n",
    "# Tabelas que N√ÉO t√™m coluna CNPJ (s√£o agregadas)\n",
    "tabelas_sem_cnpj = ['teste.ecd_benchmark_setorial']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "print(\"Iniciando varredura das tabelas (isso pode demorar muito)...\")\n",
    "\n",
    "# Envolvemos a lista de tabelas com o tqdm para uma barra de progresso\n",
    "for tabela in tqdm(tabelas_ecd, desc=\"Progresso Geral (Tabelas)\"):\n",
    "    tabela_nome = tabela.split('.')[-1]\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n[Processando] Tabela '{tabela_nome}'...\")\n",
    "        \n",
    "        # --- Consulta 1: COUNT(*) ---\n",
    "        print(f\"  (1/2) Executando COUNT(*)...\")\n",
    "        total = spark.sql(f\"SELECT COUNT(*) as cnt FROM {tabela}\").collect()[0]['cnt']\n",
    "        \n",
    "        # --- Consulta 2: COUNT(DISTINCT) - com tratamento especial ---\n",
    "        if tabela in tabelas_sem_cnpj:\n",
    "            print(f\"  (2/2) Tabela agregada (sem CNPJ) - pulando COUNT(DISTINCT cnpj)...\")\n",
    "            empresas = \"N/A (agregada)\"\n",
    "        else:\n",
    "            print(f\"  (2/2) Executando COUNT(DISTINCT cnpj)... (Esta √© a parte MAIS LENTA)\")\n",
    "            empresas = spark.sql(f\"SELECT COUNT(DISTINCT cnpj) as cnt FROM {tabela}\").collect()[0]['cnt']\n",
    "            empresas = f'{empresas:,}'\n",
    "        \n",
    "        resultados.append({\n",
    "            'Tabela': tabela_nome,\n",
    "            'Total Registros': f'{total:,}',\n",
    "            'Empresas √önicas': empresas\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ [Conclu√≠do] {tabela_nome}: {total:,} registros | {empresas} empresas\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao acessar {tabela}: {str(e)}\")\n",
    "        resultados.append({\n",
    "            'Tabela': tabela_nome,\n",
    "            'Total Registros': 'Erro',\n",
    "            'Empresas √önicas': 'Erro'\n",
    "        })\n",
    "\n",
    "# Criar DataFrame resumo\n",
    "df_resumo = pd.DataFrame(resultados)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà RESUMO DAS TABELAS\")\n",
    "print(\"=\"*80)\n",
    "print(df_resumo.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUI√á√ÉO POR ANO REFER√äNCIA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÖ DISTRIBUI√á√ÉO POR ANO REFER√äNCIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Iniciando consulta de distribui√ß√£o por ano (GROUP BY com COUNT DISTINCT)...\")\n",
    "# Esta consulta tamb√©m √© pesada e mostrar√° a barra [Stage 0:>]\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_anos_ref AS\n",
    "SELECT \n",
    "    CAST(ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    COUNT(DISTINCT cnpj) AS qtd_empresas,\n",
    "    COUNT(DISTINCT id_ecd) AS qtd_ecds\n",
    "FROM teste.ecd_empresas_cadastro\n",
    "WHERE ano_referencia > 0\n",
    "GROUP BY CAST(ano_referencia / 100 AS INT)\n",
    "ORDER BY ano_fiscal DESC\n",
    "\"\"\")\n",
    "print(\"...Consulta de distribui√ß√£o por ano CONCLU√çDA.\")\n",
    "\n",
    "# Esta √© uma consulta leve (na view tempor√°ria)\n",
    "total_anos = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_anos_ref\").collect()[0]['cnt']\n",
    "\n",
    "if total_anos > 0 and total_anos <= 20:\n",
    "    print(\"Buscando dados da view para o gr√°fico (executando .toPandas())...\")\n",
    "    # O .toPandas() √© uma A√á√ÉO e vai disparar o job do Spark\n",
    "    df_anos = spark.sql(\"SELECT * FROM vw_anos_ref\").toPandas()\n",
    "    print(\"...Dados recebidos. Gerando visualiza√ß√£o.\")\n",
    "    \n",
    "    print(\"\\nüìä Anos dispon√≠veis na base:\")\n",
    "    for _, row in df_anos.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['ano_fiscal']}: {row['qtd_empresas']:,} empresas | {row['qtd_ecds']:,} ECDs\")\n",
    "    \n",
    "    # Gr√°fico de evolu√ß√£o\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Empresas por Ano', 'ECDs por Ano'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_anos['ano_fiscal'],\n",
    "            y=df_anos['qtd_empresas'],\n",
    "            name='Empresas',\n",
    "            marker=dict(color='#1f77b4'),\n",
    "            text=df_anos['qtd_empresas'],\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_anos['ano_fiscal'],\n",
    "            y=df_anos['qtd_ecds'],\n",
    "            name='ECDs',\n",
    "            marker=dict(color='#ff7f0e'),\n",
    "            text=df_anos['qtd_ecds'],\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Distribui√ß√£o Temporal - Base ECD</b>',\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Ano Fiscal\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Ano Fiscal\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Quantidade\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Quantidade\", row=1, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Distribui√ß√£o temporal n√£o dispon√≠vel ({total_anos} registros)\")\n",
    "\n",
    "print(\"\\n‚úÖ Vis√£o geral conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888fcf3-5b11-4568-b4ef-554664058463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 3: AN√ÅLISE BALAN√áO PATRIMONIAL E DRE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí∞ AN√ÅLISE FINANCEIRA - BALAN√áO PATRIMONIAL E DRE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR VIEW DE AN√ÅLISE FINANCEIRA\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_analise_financeira AS\n",
    "SELECT \n",
    "    bp.cnpj,\n",
    "    ec.nm_razao_social,\n",
    "    ec.cd_uf,\n",
    "    ec.cnae_secao,\n",
    "    ec.cnae_secao_descricao,\n",
    "    CAST(bp.ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    CAST(COALESCE(bp.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(bp.ativo_circulante, 0) AS DOUBLE) AS ativo_circulante,\n",
    "    CAST(COALESCE(bp.ativo_nao_circulante, 0) AS DOUBLE) AS ativo_nao_circulante,\n",
    "    CAST(COALESCE(bp.passivo_circulante, 0) AS DOUBLE) AS passivo_circulante,\n",
    "    CAST(COALESCE(bp.passivo_nao_circulante, 0) AS DOUBLE) AS passivo_nao_circulante,\n",
    "    CAST(COALESCE(bp.patrimonio_liquido, 0) AS DOUBLE) AS patrimonio_liquido,\n",
    "    CAST(COALESCE(dre.receita_bruta, 0) AS DOUBLE) AS receita_bruta,\n",
    "    CAST(COALESCE(dre.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(dre.custos_totais, 0) AS DOUBLE) AS custos_totais,\n",
    "    CAST(COALESCE(dre.despesas_totais, 0) AS DOUBLE) AS despesas_totais,\n",
    "    CAST(COALESCE(dre.lucro_bruto, 0) AS DOUBLE) AS lucro_bruto,\n",
    "    CAST(COALESCE(dre.resultado_liquido, 0) AS DOUBLE) AS resultado_liquido\n",
    "FROM teste.ecd_balanco_patrimonial bp\n",
    "INNER JOIN teste.ecd_empresas_cadastro ec \n",
    "    ON bp.cnpj = ec.cnpj \n",
    "    AND bp.ano_referencia = ec.ano_referencia\n",
    "LEFT JOIN teste.ecd_dre dre \n",
    "    ON bp.cnpj = dre.cnpj \n",
    "    AND bp.ano_referencia = dre.ano_referencia\n",
    "WHERE bp.ativo_total > 0\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_fin = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_analise_financeira\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros financeiros: {total_fin:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ESTAT√çSTICAS DESCRITIVAS PRINCIPAIS\n",
    "# ============================================================================\n",
    "\n",
    "if total_fin > 0:\n",
    "    # Limitar a 50.000 registros se necess√°rio\n",
    "    if total_fin > 50000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_fin:,}), limitando a 50.000 para an√°lise...\")\n",
    "        df_financeiro = spark.sql(\"SELECT * FROM vw_analise_financeira ORDER BY ativo_total DESC LIMIT 50000\").toPandas()\n",
    "    else:\n",
    "        df_spark = spark.sql(\"SELECT * FROM vw_analise_financeira\")\n",
    "        df_spark.cache()\n",
    "        df_financeiro = df_spark.toPandas()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dados carregados: {len(df_financeiro):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ESTAT√çSTICAS DESCRITIVAS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà ESTAT√çSTICAS DESCRITIVAS - VALORES EM MILH√ïES (R$)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    colunas_valores = [\n",
    "        'ativo_total', 'ativo_circulante', 'ativo_nao_circulante',\n",
    "        'passivo_circulante', 'passivo_nao_circulante', 'patrimonio_liquido',\n",
    "        'receita_bruta', 'receita_liquida', 'lucro_bruto', 'resultado_liquido'\n",
    "    ]\n",
    "    \n",
    "    # Converter para milh√µes\n",
    "    df_stats = df_financeiro[colunas_valores].copy()\n",
    "    df_stats = df_stats / 1_000_000  # Converter para milh√µes\n",
    "    \n",
    "    # Calcular estat√≠sticas\n",
    "    stats = df_stats.describe()\n",
    "    \n",
    "    print(\"\\nüìä Resumo Estat√≠stico (em Milh√µes R$):\")\n",
    "    print(stats.to_string())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: DISTRIBUI√á√ÉO DE ATIVOS (TOP 30 EMPRESAS)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä VISUALIZA√á√ÉO: TOP 30 EMPRESAS POR ATIVO TOTAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_top30 = df_financeiro.nlargest(30, 'ativo_total').copy()\n",
    "    df_top30['ativo_milhoes'] = df_top30['ativo_total'] / 1_000_000\n",
    "    df_top30['razao_curta'] = df_top30['nm_razao_social'].str[:40]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df_top30['razao_curta'],\n",
    "        x=df_top30['ativo_milhoes'],\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=df_top30['ativo_milhoes'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Ativo (Mi R$)\")\n",
    "        ),\n",
    "        text=[f\"R$ {val:,.1f}M\" for val in df_top30['ativo_milhoes']],\n",
    "        textposition='outside',\n",
    "        hovertemplate='<b>%{y}</b><br>Ativo: R$ %{x:,.2f}M<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Top 30 Empresas - Ativo Total</b>',\n",
    "        xaxis_title='Ativo Total (Milh√µes R$)',\n",
    "        yaxis_title='Empresa',\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: COMPOSI√á√ÉO M√âDIA DO BALAN√áO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä COMPOSI√á√ÉO M√âDIA DO BALAN√áO PATRIMONIAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    composicao_ativo = {\n",
    "        'Ativo Circulante': df_financeiro['ativo_circulante'].sum(),\n",
    "        'Ativo N√£o Circulante': df_financeiro['ativo_nao_circulante'].sum()\n",
    "    }\n",
    "    \n",
    "    composicao_passivo = {\n",
    "        'Passivo Circulante': df_financeiro['passivo_circulante'].sum(),\n",
    "        'Passivo N√£o Circulante': df_financeiro['passivo_nao_circulante'].sum(),\n",
    "        'Patrim√¥nio L√≠quido': df_financeiro['patrimonio_liquido'].sum()\n",
    "    }\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Composi√ß√£o do ATIVO', 'Composi√ß√£o do PASSIVO + PL'),\n",
    "        specs=[[{'type': 'pie'}, {'type': 'pie'}]]\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(composicao_ativo.keys()),\n",
    "            values=list(composicao_ativo.values()),\n",
    "            hole=0.4,\n",
    "            marker=dict(colors=['#1f77b4', '#ff7f0e'])\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(composicao_passivo.keys()),\n",
    "            values=list(composicao_passivo.values()),\n",
    "            hole=0.4,\n",
    "            marker=dict(colors=['#2ca02c', '#d62728', '#9467bd'])\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Composi√ß√£o Patrimonial - Base Agregada</b>',\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AN√ÅLISE DRE - RENTABILIDADE\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üíπ AN√ÅLISE DE RENTABILIDADE (DRE)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Filtrar empresas com receita > 0\n",
    "    df_dre = df_financeiro[df_financeiro['receita_liquida'] > 0].copy()\n",
    "    \n",
    "    if len(df_dre) > 0:\n",
    "        # Calcular margens\n",
    "        df_dre['margem_bruta'] = (df_dre['lucro_bruto'] / df_dre['receita_liquida']) * 100\n",
    "        df_dre['margem_liquida'] = (df_dre['resultado_liquido'] / df_dre['receita_liquida']) * 100\n",
    "        \n",
    "        print(f\"\\n‚úÖ {len(df_dre):,} empresas com receita informada\")\n",
    "        print(f\"\\nüìä Margem Bruta M√©dia: {df_dre['margem_bruta'].mean():.2f}%\")\n",
    "        print(f\"üìä Margem L√≠quida M√©dia: {df_dre['margem_liquida'].mean():.2f}%\")\n",
    "        print(f\"üìä Empresas com lucro: {(df_dre['resultado_liquido'] > 0).sum():,} ({(df_dre['resultado_liquido'] > 0).sum() / len(df_dre) * 100:.1f}%)\")\n",
    "        print(f\"üìä Empresas com preju√≠zo: {(df_dre['resultado_liquido'] < 0).sum():,} ({(df_dre['resultado_liquido'] < 0).sum() / len(df_dre) * 100:.1f}%)\")\n",
    "        \n",
    "        # Gr√°fico de distribui√ß√£o de margens\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=('Distribui√ß√£o - Margem Bruta', 'Distribui√ß√£o - Margem L√≠quida')\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=df_dre['margem_bruta'].clip(-100, 100),\n",
    "                nbinsx=50,\n",
    "                name='Margem Bruta',\n",
    "                marker=dict(color='#1f77b4')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=df_dre['margem_liquida'].clip(-100, 100),\n",
    "                nbinsx=50,\n",
    "                name='Margem L√≠quida',\n",
    "                marker=dict(color='#ff7f0e')\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Margem (%)\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Margem (%)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Frequ√™ncia\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Frequ√™ncia\", row=1, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='<b>Distribui√ß√£o de Margens - An√°lise de Rentabilidade</b>',\n",
    "            height=400,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Nenhuma empresa com receita informada para an√°lise DRE\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados financeiros n√£o dispon√≠veis\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise financeira conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba578e-be80-4606-bf3e-671edd79fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 4: AN√ÅLISE DE INDICADORES FINANCEIROS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä AN√ÅLISE DE INDICADORES FINANCEIROS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR VIEW DE INDICADORES\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_indicadores AS\n",
    "SELECT \n",
    "    ind.cnpj,\n",
    "    ec.nm_razao_social,\n",
    "    ec.cd_uf,\n",
    "    ec.cnae_secao,\n",
    "    ec.cnae_secao_descricao,\n",
    "    ec.empresa_grande_porte,\n",
    "    CAST(ind.ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    CAST(COALESCE(ind.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(ind.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(ind.resultado_liquido, 0) AS DOUBLE) AS resultado_liquido,\n",
    "    CAST(COALESCE(ind.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(ind.liquidez_geral, 0) AS DOUBLE) AS liquidez_geral,\n",
    "    CAST(COALESCE(ind.endividamento_geral, 0) AS DOUBLE) AS endividamento_geral,\n",
    "    CAST(COALESCE(ind.composicao_endividamento, 0) AS DOUBLE) AS composicao_endividamento,\n",
    "    CAST(COALESCE(ind.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida_perc,\n",
    "    CAST(COALESCE(ind.margem_bruta_perc, 0) AS DOUBLE) AS margem_bruta_perc,\n",
    "    CAST(COALESCE(ind.roa_retorno_ativo_perc, 0) AS DOUBLE) AS roa_retorno_ativo_perc,\n",
    "    CAST(COALESCE(ind.roe_retorno_patrimonio_perc, 0) AS DOUBLE) AS roe_retorno_patrimonio_perc\n",
    "FROM teste.ecd_indicadores_financeiros ind\n",
    "INNER JOIN teste.ecd_empresas_cadastro ec \n",
    "    ON ind.cnpj = ec.cnpj \n",
    "    AND ind.ano_referencia = ec.ano_referencia\n",
    "WHERE ind.ativo_total > 0\n",
    "    AND ind.liquidez_corrente IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_ind = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_indicadores\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros com indicadores: {total_ind:,}\")\n",
    "\n",
    "if total_ind > 0:\n",
    "    # Limitar a 30.000 registros se necess√°rio\n",
    "    if total_ind > 30000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_ind:,}), limitando a 30.000...\")\n",
    "        df_ind = spark.sql(\"SELECT * FROM vw_indicadores ORDER BY ativo_total DESC LIMIT 30000\").toPandas()\n",
    "    else:\n",
    "        df_spark = spark.sql(\"SELECT * FROM vw_indicadores\")\n",
    "        df_spark.cache()\n",
    "        df_ind = df_spark.toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dados carregados: {len(df_ind):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ESTAT√çSTICAS DOS INDICADORES\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà ESTAT√çSTICAS DOS INDICADORES FINANCEIROS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    indicadores_cols = [\n",
    "        'liquidez_corrente', 'liquidez_geral', 'endividamento_geral',\n",
    "        'margem_liquida_perc', 'margem_bruta_perc', \n",
    "        'roa_retorno_ativo_perc', 'roe_retorno_patrimonio_perc'\n",
    "    ]\n",
    "    \n",
    "    stats_ind = df_ind[indicadores_cols].describe()\n",
    "    print(\"\\n\" + stats_ind.to_string())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CLASSIFICA√á√ÉO DE LIQUIDEZ\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_ind['classe_liquidez'] = pd.cut(\n",
    "        df_ind['liquidez_corrente'],\n",
    "        bins=[0, 0.5, 1.0, 1.5, 2.0, float('inf')],\n",
    "        labels=['Cr√≠tica', 'Baixa', 'Regular', 'Boa', 'Excelente']\n",
    "    )\n",
    "    \n",
    "    df_ind['classe_endividamento'] = pd.cut(\n",
    "        df_ind['endividamento_geral'],\n",
    "        bins=[0, 0.3, 0.5, 0.7, 1.0, float('inf')],\n",
    "        labels=['Baixo', 'Moderado', 'Alto', 'Cr√≠tico', 'Muito Cr√≠tico']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ CLASSIFICA√á√ÉO DE LIQUIDEZ\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    dist_liquidez = df_ind['classe_liquidez'].value_counts().sort_index()\n",
    "    print(\"\\n\" + dist_liquidez.to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è CLASSIFICA√á√ÉO DE ENDIVIDAMENTO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    dist_endiv = df_ind['classe_endividamento'].value_counts().sort_index()\n",
    "    print(\"\\n\" + dist_endiv.to_string())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: MATRIZ DE CORRELA√á√ÉO DE INDICADORES\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä VISUALIZA√á√ÉO: MATRIZ DE CORRELA√á√ÉO DE INDICADORES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Selecionar amostra para visualiza√ß√£o se dataset muito grande\n",
    "    # FIX: Usar min() do Python nativo, n√£o do PySpark\n",
    "    tamanho_amostra = 1000 if len(df_ind) > 1000 else len(df_ind)\n",
    "    df_sample = df_ind.sample(n=tamanho_amostra, random_state=42)\n",
    "    \n",
    "    # Limpar outliers extremos para melhor visualiza√ß√£o\n",
    "    for col in indicadores_cols:\n",
    "        q1 = df_sample[col].quantile(0.05)\n",
    "        q3 = df_sample[col].quantile(0.95)\n",
    "        df_sample.loc[df_sample[col] < q1, col] = q1\n",
    "        df_sample.loc[df_sample[col] > q3, col] = q3\n",
    "    \n",
    "    # Calcular correla√ß√£o\n",
    "    corr_matrix = df_sample[indicadores_cols].corr()\n",
    "    \n",
    "    # Heatmap de correla√ß√£o\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=corr_matrix.values,\n",
    "        x=['Liq.Cor.', 'Liq.Geral', 'Endiv.', 'M.L√≠q.%', 'M.Bruta%', 'ROA%', 'ROE%'],\n",
    "        y=['Liq.Cor.', 'Liq.Geral', 'Endiv.', 'M.L√≠q.%', 'M.Bruta%', 'ROA%', 'ROE%'],\n",
    "        colorscale='RdBu',\n",
    "        zmid=0,\n",
    "        text=corr_matrix.values.round(2),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title=\"Correla√ß√£o\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Matriz de Correla√ß√£o - Indicadores Financeiros</b>',\n",
    "        height=600,\n",
    "        xaxis_title='',\n",
    "        yaxis_title=''\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: DISTRIBUI√á√ÉO DE LIQUIDEZ x ENDIVIDAMENTO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä AN√ÅLISE: LIQUIDEZ vs ENDIVIDAMENTO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar dados para scatter\n",
    "    df_scatter = df_ind[\n",
    "        (df_ind['liquidez_corrente'] > 0) & \n",
    "        (df_ind['liquidez_corrente'] < 10) &\n",
    "        (df_ind['endividamento_geral'] >= 0) &\n",
    "        (df_ind['endividamento_geral'] <= 2)\n",
    "    ].copy()\n",
    "    \n",
    "    df_scatter['tamanho'] = df_scatter['ativo_total'] / 1_000_000  # Em milh√µes\n",
    "    \n",
    "    # FIX: Usar min() do Python\n",
    "    tamanho_scatter = 2000 if len(df_scatter) > 2000 else len(df_scatter)\n",
    "    df_scatter_sample = df_scatter.sample(n=tamanho_scatter, random_state=42)\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_scatter_sample,\n",
    "        x='endividamento_geral',\n",
    "        y='liquidez_corrente',\n",
    "        color='margem_liquida_perc',\n",
    "        size='tamanho',\n",
    "        hover_data=['nm_razao_social', 'cd_uf', 'cnae_secao_descricao'],\n",
    "        color_continuous_scale='RdYlGn',\n",
    "        labels={\n",
    "            'endividamento_geral': 'Endividamento Geral',\n",
    "            'liquidez_corrente': 'Liquidez Corrente',\n",
    "            'margem_liquida_perc': 'Margem L√≠quida (%)'\n",
    "        },\n",
    "        title='<b>Liquidez vs Endividamento (tamanho = Ativo Total)</b>'\n",
    "    )\n",
    "    \n",
    "    # Adicionar linhas de refer√™ncia\n",
    "    fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=\"Liquidez = 1.0\", annotation_position=\"right\")\n",
    "    fig.add_vline(x=0.7, line_dash=\"dash\", line_color=\"orange\",\n",
    "                  annotation_text=\"Endiv. = 0.7\", annotation_position=\"top\")\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: BOX PLOT POR SETOR\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä INDICADORES POR SETOR (TOP 10 SETORES)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Top 10 setores\n",
    "    top_setores = df_ind['cnae_secao_descricao'].value_counts().head(10).index.tolist()\n",
    "    df_setores = df_ind[df_ind['cnae_secao_descricao'].isin(top_setores)].copy()\n",
    "    \n",
    "    # Preparar nomes curtos\n",
    "    df_setores['setor_curto'] = df_setores['cnae_secao_descricao'].str[:40]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Liquidez Corrente por Setor',\n",
    "            'Endividamento por Setor',\n",
    "            'Margem L√≠quida por Setor',\n",
    "            'ROE por Setor'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for setor in df_setores['setor_curto'].unique():\n",
    "        dados_setor = df_setores[df_setores['setor_curto'] == setor]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Box(y=dados_setor['liquidez_corrente'].clip(0, 5), name=setor, showlegend=False),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Box(y=dados_setor['endividamento_geral'].clip(0, 1.5), name=setor, showlegend=False),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Box(y=dados_setor['margem_liquida_perc'].clip(-50, 50), name=setor, showlegend=False),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Box(y=dados_setor['roe_retorno_patrimonio_perc'].clip(-50, 50), name=setor, showlegend=False),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Distribui√ß√£o de Indicadores por Setor</b>',\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AN√ÅLISE POR PORTE DE EMPRESA\n",
    "    # ========================================================================\n",
    "    \n",
    "    if 'empresa_grande_porte' in df_ind.columns:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üè¢ COMPARA√á√ÉO: GRANDE PORTE vs DEMAIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        df_porte = df_ind.groupby('empresa_grande_porte')[indicadores_cols].mean()\n",
    "        print(\"\\nüìä M√©dias por Porte:\")\n",
    "        print(df_porte.round(2).to_string())\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados de indicadores n√£o dispon√≠veis\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de indicadores conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f7123-b80f-4eff-9fbb-85e66f7c8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 5: AN√ÅLISE DE SCORE DE RISCO E NEAF\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ö†Ô∏è AN√ÅLISE DE RISCO E IND√çCIOS NEAF\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR VIEW DE SCORE DE RISCO\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_score_risco AS\n",
    "SELECT \n",
    "    sr.cnpj,\n",
    "    sr.razao_social,\n",
    "    sr.uf,\n",
    "    sr.cd_cnae,\n",
    "    sr.de_cnae,\n",
    "    sr.cnae_secao,\n",
    "    sr.cnae_secao_descricao,\n",
    "    CAST(sr.ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    sr.empresa_grande_porte,\n",
    "    sr.tipo_ecd,\n",
    "    sr.nm_tipo_contribuinte,\n",
    "    sr.classificacao_risco,\n",
    "    CAST(COALESCE(sr.score_risco_total, 0) AS DOUBLE) AS score_risco_total,\n",
    "    CAST(COALESCE(sr.score_equacao_contabil, 0) AS DOUBLE) AS score_equacao,\n",
    "    CAST(COALESCE(sr.score_neaf, 0) AS DOUBLE) AS score_neaf,\n",
    "    CAST(COALESCE(sr.score_risco_financeiro, 0) AS DOUBLE) AS score_financeiro,\n",
    "    CAST(COALESCE(sr.qtd_indicios_neaf, 0) AS DOUBLE) AS qtd_indicios,\n",
    "    CAST(COALESCE(sr.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(sr.endividamento_geral, 0) AS DOUBLE) AS endividamento_geral,\n",
    "    CAST(COALESCE(sr.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida_perc,\n",
    "    sr.posicao_liquidez_setor,\n",
    "    sr.posicao_margem_setor\n",
    "FROM teste.ecd_score_risco_consolidado sr\n",
    "WHERE sr.score_risco_total IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_score = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_score_risco\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros com score: {total_score:,}\")\n",
    "\n",
    "if total_score > 0:\n",
    "    # Limitar a 50.000 registros\n",
    "    if total_score > 50000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_score:,}), limitando a 50.000...\")\n",
    "        df_score = spark.sql(\"SELECT * FROM vw_score_risco ORDER BY score_risco_total DESC LIMIT 50000\").toPandas()\n",
    "    else:\n",
    "        df_spark = spark.sql(\"SELECT * FROM vw_score_risco\")\n",
    "        df_spark.cache()\n",
    "        df_score = df_spark.toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dados carregados: {len(df_score):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DISTRIBUI√á√ÉO DE CLASSIFICA√á√ÉO DE RISCO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ DISTRIBUI√á√ÉO DE CLASSIFICA√á√ÉO DE RISCO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    dist_risco = df_score['classificacao_risco'].value_counts()\n",
    "    print(\"\\n\" + dist_risco.to_string())\n",
    "    \n",
    "    # Percentuais\n",
    "    print(\"\\nüìä Percentuais:\")\n",
    "    for classe, qtd in dist_risco.items():\n",
    "        pct = (qtd / len(df_score)) * 100\n",
    "        print(f\"  ‚Ä¢ {classe}: {pct:.1f}%\")\n",
    "    \n",
    "    # Gr√°fico Pizza\n",
    "    fig = go.Figure(data=[go.Pie(\n",
    "        labels=dist_risco.index,\n",
    "        values=dist_risco.values,\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=['#d62728', '#ff7f0e', '#ffbb33', '#2ca02c']),\n",
    "        textinfo='label+percent',\n",
    "        textfont_size=14\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Distribui√ß√£o de Classifica√ß√£o de Risco</b>',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ESTAT√çSTICAS DOS SCORES\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà ESTAT√çSTICAS DOS SCORES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    scores_cols = ['score_risco_total', 'score_equacao', 'score_neaf', 'score_financeiro']\n",
    "    stats_scores = df_score[scores_cols].describe()\n",
    "    print(\"\\n\" + stats_scores.to_string())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AN√ÅLISE DE IND√çCIOS NEAF\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üö® AN√ÅLISE DE IND√çCIOS NEAF\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    empresas_com_indicios = (df_score['qtd_indicios'] > 0).sum()\n",
    "    pct_indicios = (empresas_com_indicios / len(df_score)) * 100\n",
    "    \n",
    "    print(f\"\\nüìä Empresas com ind√≠cios NEAF: {empresas_com_indicios:,} ({pct_indicios:.1f}%)\")\n",
    "    print(f\"üìä Total de ind√≠cios: {df_score['qtd_indicios'].sum():.0f}\")\n",
    "    print(f\"üìä M√©dia de ind√≠cios (empresas com ind√≠cio): {df_score[df_score['qtd_indicios'] > 0]['qtd_indicios'].mean():.1f}\")\n",
    "    \n",
    "    # Distribui√ß√£o de quantidade de ind√≠cios\n",
    "    if empresas_com_indicios > 0:\n",
    "        df_indicios = df_score[df_score['qtd_indicios'] > 0].copy()\n",
    "        dist_indicios = df_indicios['qtd_indicios'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"\\nüìä Distribui√ß√£o de Quantidade de Ind√≠cios:\")\n",
    "        for qtd, freq in dist_indicios.head(10).items():\n",
    "            print(f\"  ‚Ä¢ {int(qtd)} ind√≠cios: {freq:,} empresas\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: COMPOSI√á√ÉO DO SCORE DE RISCO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä VISUALIZA√á√ÉO: COMPOSI√á√ÉO DO SCORE DE RISCO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # M√©dias por componente\n",
    "    media_scores = {\n",
    "        'Score Equa√ß√£o': df_score['score_equacao'].mean(),\n",
    "        'Score NEAF': df_score['score_neaf'].mean(),\n",
    "        'Score Financeiro': df_score['score_financeiro'].mean()\n",
    "    }\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=list(media_scores.keys()),\n",
    "            y=list(media_scores.values()),\n",
    "            marker=dict(\n",
    "                color=list(media_scores.values()),\n",
    "                colorscale='Reds',\n",
    "                showscale=False\n",
    "            ),\n",
    "            text=[f\"{val:.2f}\" for val in media_scores.values()],\n",
    "            textposition='outside'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Composi√ß√£o M√©dia do Score de Risco</b>',\n",
    "        xaxis_title='Componente',\n",
    "        yaxis_title='Score M√©dio',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: SCORE DE RISCO POR UF (TOP 15)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üó∫Ô∏è SCORE DE RISCO POR UF\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_uf = df_score.groupby('uf').agg({\n",
    "        'score_risco_total': 'mean',\n",
    "        'cnpj': 'count',\n",
    "        'qtd_indicios': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_uf.columns = ['UF', 'Score M√©dio', 'Qtd Empresas', 'Total Ind√≠cios']\n",
    "    df_uf = df_uf.sort_values('Score M√©dio', ascending=False).head(15)\n",
    "    \n",
    "    print(\"\\nüìä Top 15 UF com maior score de risco:\")\n",
    "    print(df_uf.to_string(index=False))\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=df_uf['UF'],\n",
    "            y=df_uf['Score M√©dio'],\n",
    "            marker=dict(\n",
    "                color=df_uf['Score M√©dio'],\n",
    "                colorscale='Reds',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Score\")\n",
    "            ),\n",
    "            text=df_uf['Score M√©dio'].round(2),\n",
    "            textposition='outside',\n",
    "            hovertemplate='<b>%{x}</b><br>Score: %{y:.2f}<br>Empresas: %{customdata[0]:,}<br>Ind√≠cios: %{customdata[1]:,.0f}<extra></extra>',\n",
    "            customdata=df_uf[['Qtd Empresas', 'Total Ind√≠cios']].values\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Score de Risco M√©dio por UF (Top 15)</b>',\n",
    "        xaxis_title='UF',\n",
    "        yaxis_title='Score M√©dio',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: SCORE POR SETOR (TOP 20)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üè≠ SCORE DE RISCO POR SETOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_setor = df_score.groupby('cnae_secao_descricao').agg({\n",
    "        'score_risco_total': 'mean',\n",
    "        'cnpj': 'count',\n",
    "        'qtd_indicios': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_setor.columns = ['Setor', 'Score M√©dio', 'Qtd Empresas', 'Total Ind√≠cios']\n",
    "    df_setor = df_setor.sort_values('Score M√©dio', ascending=False).head(20)\n",
    "    df_setor['Setor Curto'] = df_setor['Setor'].str[:50]\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            y=df_setor['Setor Curto'],\n",
    "            x=df_setor['Score M√©dio'],\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color=df_setor['Score M√©dio'],\n",
    "                colorscale='Reds',\n",
    "                showscale=False\n",
    "            ),\n",
    "            text=df_setor['Score M√©dio'].round(2),\n",
    "            textposition='outside',\n",
    "            hovertemplate='<b>%{y}</b><br>Score: %{x:.2f}<br>Empresas: %{customdata[0]:,}<extra></extra>',\n",
    "            customdata=df_setor[['Qtd Empresas']].values\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Score de Risco M√©dio por Setor (Top 20)</b>',\n",
    "        xaxis_title='Score M√©dio',\n",
    "        yaxis_title='Setor',\n",
    "        height=700,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EMPRESAS DE ALTO RISCO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üö® EMPRESAS DE ALTO RISCO (Top 30)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_alto_risco = df_score[\n",
    "        df_score['classificacao_risco'].isin(['RISCO CR√çTICO', 'RISCO ALTO'])\n",
    "    ].sort_values('score_risco_total', ascending=False).head(30)\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(df_alto_risco)} empresas de alto risco identificadas\")\n",
    "    \n",
    "    if len(df_alto_risco) > 0:\n",
    "        print(\"\\nüìã Resumo das Top 30:\")\n",
    "        print(df_alto_risco[[\n",
    "            'razao_social', 'uf', 'classificacao_risco', \n",
    "            'score_risco_total', 'qtd_indicios'\n",
    "        ]].to_string(index=False))\n",
    "        \n",
    "        # Gr√°fico das top 30\n",
    "        df_alto_risco['razao_curta'] = df_alto_risco['razao_social'].str[:40]\n",
    "        \n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(\n",
    "                y=df_alto_risco['razao_curta'],\n",
    "                x=df_alto_risco['score_risco_total'],\n",
    "                orientation='h',\n",
    "                marker=dict(color='#d62728'),\n",
    "                text=df_alto_risco['score_risco_total'].round(2),\n",
    "                textposition='outside',\n",
    "                hovertemplate='<b>%{y}</b><br>Score: %{x:.2f}<br>Ind√≠cios: %{customdata[0]:.0f}<extra></extra>',\n",
    "                customdata=df_alto_risco[['qtd_indicios']].values\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='<b>Top 30 Empresas - Maior Score de Risco</b>',\n",
    "            xaxis_title='Score de Risco Total',\n",
    "            yaxis_title='Empresa',\n",
    "            height=900,\n",
    "            yaxis=dict(autorange='reversed')\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados de score de risco n√£o dispon√≠veis\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de risco conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbfcae-8d0e-433c-86da-7dc255b881e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 6: MACHINE LEARNING - RANDOM FOREST E XGBOOST\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ü§ñ MACHINE LEARNING - PREDI√á√ÉO DE RISCO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR DADOS PARA ML\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_ml_dataset AS\n",
    "SELECT \n",
    "    sr.cnpj,\n",
    "    sr.classificacao_risco,\n",
    "    CAST(COALESCE(ind.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(ind.ativo_circulante, 0) AS DOUBLE) AS ativo_circulante,\n",
    "    CAST(COALESCE(ind.passivo_circulante, 0) AS DOUBLE) AS passivo_circulante,\n",
    "    CAST(COALESCE(ind.patrimonio_liquido, 0) AS DOUBLE) AS patrimonio_liquido,\n",
    "    CAST(COALESCE(ind.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(ind.resultado_liquido, 0) AS DOUBLE) AS resultado_liquido,\n",
    "    CAST(COALESCE(ind.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(ind.liquidez_geral, 0) AS DOUBLE) AS liquidez_geral,\n",
    "    CAST(COALESCE(ind.endividamento_geral, 0) AS DOUBLE) AS endividamento_geral,\n",
    "    CAST(COALESCE(ind.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida_perc,\n",
    "    CAST(COALESCE(ind.margem_bruta_perc, 0) AS DOUBLE) AS margem_bruta_perc,\n",
    "    CAST(COALESCE(ind.roa_retorno_ativo_perc, 0) AS DOUBLE) AS roa_perc,\n",
    "    CAST(COALESCE(ind.roe_retorno_patrimonio_perc, 0) AS DOUBLE) AS roe_perc,\n",
    "    CAST(COALESCE(sr.score_equacao_contabil, 0) AS DOUBLE) AS score_equacao,\n",
    "    CAST(COALESCE(sr.qtd_indicios_neaf, 0) AS DOUBLE) AS qtd_indicios,\n",
    "    CASE \n",
    "        WHEN sr.empresa_grande_porte = 'Sim' THEN 1 \n",
    "        ELSE 0 \n",
    "    END AS eh_grande_porte\n",
    "FROM teste.ecd_score_risco_consolidado sr\n",
    "INNER JOIN teste.ecd_indicadores_financeiros ind\n",
    "    ON sr.cnpj = ind.cnpj\n",
    "    AND sr.ano_referencia = ind.ano_referencia\n",
    "WHERE sr.classificacao_risco IS NOT NULL\n",
    "    AND ind.ativo_total > 0\n",
    "    AND ind.liquidez_corrente IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_ml = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_ml_dataset\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros para ML: {total_ml:,}\")\n",
    "\n",
    "if total_ml > 0 and total_ml <= 100000:\n",
    "    df_ml = spark.sql(\"SELECT * FROM vw_ml_dataset\").toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dataset ML carregado: {len(df_ml):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PREPARA√á√ÉO DOS DADOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîß PREPARA√á√ÉO DOS DADOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Verificar distribui√ß√£o das classes\n",
    "    print(\"\\nüìä Distribui√ß√£o das classes:\")\n",
    "    print(df_ml['classificacao_risco'].value_counts())\n",
    "    \n",
    "    # Criar vari√°vel target bin√°ria (Alto Risco vs Baixo Risco)\n",
    "    df_ml['target_binario'] = df_ml['classificacao_risco'].apply(\n",
    "        lambda x: 1 if x in ['RISCO CR√çTICO', 'RISCO ALTO'] else 0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Classes balanceadas:\")\n",
    "    print(f\"  ‚Ä¢ Alto Risco: {df_ml['target_binario'].sum():,} ({df_ml['target_binario'].mean()*100:.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Baixo Risco: {(df_ml['target_binario']==0).sum():,} ({(df_ml['target_binario']==0).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Features para o modelo\n",
    "    features = [\n",
    "        'ativo_total', 'ativo_circulante', 'passivo_circulante', 'patrimonio_liquido',\n",
    "        'receita_liquida', 'resultado_liquido', 'liquidez_corrente', 'liquidez_geral',\n",
    "        'endividamento_geral', 'margem_liquida_perc', 'margem_bruta_perc',\n",
    "        'roa_perc', 'roe_perc', 'score_equacao', 'qtd_indicios', 'eh_grande_porte'\n",
    "    ]\n",
    "    \n",
    "    # Remover valores infinitos e NaN\n",
    "    df_ml[features] = df_ml[features].replace([np.inf, -np.inf], np.nan)\n",
    "    df_ml = df_ml.dropna(subset=features + ['target_binario'])\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset limpo: {len(df_ml):,} registros\")\n",
    "    \n",
    "    # Separar features e target\n",
    "    X = df_ml[features]\n",
    "    y = df_ml['target_binario']\n",
    "    \n",
    "    # ========================================================================\n",
    "    # NORMALIZA√á√ÉO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\nüìä Normalizando features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=features, index=X.index)\n",
    "    \n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Train set: {len(X_train):,} | Test set: {len(X_test):,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODELO 1: RANDOM FOREST\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üå≤ RANDOM FOREST CLASSIFIER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n‚è≥ Treinando Random Forest...\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    print(\"\\nüìä RESULTADOS RANDOM FOREST:\")\n",
    "    print(\"\\n\" + classification_report(y_test, y_pred_rf, target_names=['Baixo Risco', 'Alto Risco']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    roc_auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "    print(f\"\\nüéØ ROC AUC Score: {roc_auc_rf:.4f}\")\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance_rf = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä TOP 10 FEATURES MAIS IMPORTANTES (Random Forest):\")\n",
    "    print(feature_importance_rf.head(10).to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico de import√¢ncia\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            y=feature_importance_rf.head(15)['feature'],\n",
    "            x=feature_importance_rf.head(15)['importance'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#2ca02c'),\n",
    "            text=feature_importance_rf.head(15)['importance'].round(3),\n",
    "            textposition='outside'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Feature Importance - Random Forest</b>',\n",
    "        xaxis_title='Import√¢ncia',\n",
    "        yaxis_title='Feature',\n",
    "        height=600,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODELO 2: XGBOOST\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö° XGBOOST CLASSIFIER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n‚è≥ Treinando XGBoost...\")\n",
    "    \n",
    "    # Calcular scale_pos_weight para balancear classes\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    print(\"\\nüìä RESULTADOS XGBOOST:\")\n",
    "    print(\"\\n\" + classification_report(y_test, y_pred_xgb, target_names=['Baixo Risco', 'Alto Risco']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    roc_auc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
    "    print(f\"\\nüéØ ROC AUC Score: {roc_auc_xgb:.4f}\")\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance_xgb = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': xgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä TOP 10 FEATURES MAIS IMPORTANTES (XGBoost):\")\n",
    "    print(feature_importance_xgb.head(10).to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico de import√¢ncia\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            y=feature_importance_xgb.head(15)['feature'],\n",
    "            x=feature_importance_xgb.head(15)['importance'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#ff7f0e'),\n",
    "            text=feature_importance_xgb.head(15)['importance'].round(3),\n",
    "            textposition='outside'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Feature Importance - XGBoost</b>',\n",
    "        xaxis_title='Import√¢ncia',\n",
    "        yaxis_title='Feature',\n",
    "        height=600,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPARA√á√ÉO DOS MODELOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÜ COMPARA√á√ÉO DOS MODELOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    comparacao = pd.DataFrame({\n",
    "        'Modelo': ['Random Forest', 'XGBoost'],\n",
    "        'ROC AUC': [roc_auc_rf, roc_auc_xgb],\n",
    "        'Acur√°cia': [\n",
    "            (y_test == y_pred_rf).mean(),\n",
    "            (y_test == y_pred_xgb).mean()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + comparacao.to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico de compara√ß√£o\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='ROC AUC', x=comparacao['Modelo'], y=comparacao['ROC AUC'], marker=dict(color='#1f77b4')),\n",
    "        go.Bar(name='Acur√°cia', x=comparacao['Modelo'], y=comparacao['Acur√°cia'], marker=dict(color='#ff7f0e'))\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Compara√ß√£o de Performance dos Modelos</b>',\n",
    "        xaxis_title='Modelo',\n",
    "        yaxis_title='Score',\n",
    "        barmode='group',\n",
    "        height=400,\n",
    "        yaxis=dict(range=[0, 1])\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MATRIZ DE CONFUS√ÉO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä MATRIZ DE CONFUS√ÉO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Matriz Random Forest\n",
    "    cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "    cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Random Forest', 'XGBoost'),\n",
    "        specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}]]\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=cm_rf,\n",
    "            x=['Predito: Baixo', 'Predito: Alto'],\n",
    "            y=['Real: Baixo', 'Real: Alto'],\n",
    "            colorscale='Blues',\n",
    "            text=cm_rf,\n",
    "            texttemplate='%{text}',\n",
    "            showscale=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=cm_xgb,\n",
    "            x=['Predito: Baixo', 'Predito: Alto'],\n",
    "            y=['Real: Baixo', 'Real: Alto'],\n",
    "            colorscale='Oranges',\n",
    "            text=cm_xgb,\n",
    "            texttemplate='%{text}',\n",
    "            showscale=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Matriz de Confus√£o - Compara√ß√£o</b>',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "elif total_ml > 100000:\n",
    "    print(f\"\\n‚ö†Ô∏è Dataset muito grande ({total_ml:,} registros). Limitando a 100.000 para ML...\")\n",
    "    df_ml = spark.sql(\"SELECT * FROM vw_ml_dataset LIMIT 100000\").toPandas()\n",
    "    print(\"Execute novamente a c√©lula para treinar os modelos.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados insuficientes para Machine Learning\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de Machine Learning conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eceb6a-5790-41a2-a925-cfa88dcf69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 7: CLUSTERING E APRENDIZADO N√ÉO SUPERVISIONADO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç AN√ÅLISE DE CLUSTERING - APRENDIZADO N√ÉO SUPERVISIONADO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR DADOS PARA CLUSTERING\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_clustering AS\n",
    "SELECT \n",
    "    ind.cnpj,\n",
    "    ec.nm_razao_social,\n",
    "    ec.cd_uf,\n",
    "    ec.cnae_secao_descricao,\n",
    "    CAST(COALESCE(ind.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(ind.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(ind.resultado_liquido, 0) AS DOUBLE) AS resultado_liquido,\n",
    "    CAST(COALESCE(ind.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(ind.liquidez_geral, 0) AS DOUBLE) AS liquidez_geral,\n",
    "    CAST(COALESCE(ind.endividamento_geral, 0) AS DOUBLE) AS endividamento_geral,\n",
    "    CAST(COALESCE(ind.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida_perc,\n",
    "    CAST(COALESCE(ind.roa_retorno_ativo_perc, 0) AS DOUBLE) AS roa_perc,\n",
    "    CAST(COALESCE(ind.roe_retorno_patrimonio_perc, 0) AS DOUBLE) AS roe_perc,\n",
    "    CAST(COALESCE(sr.score_risco_total, 0) AS DOUBLE) AS score_risco\n",
    "FROM teste.ecd_indicadores_financeiros ind\n",
    "INNER JOIN teste.ecd_empresas_cadastro ec\n",
    "    ON ind.cnpj = ec.cnpj\n",
    "    AND ind.ano_referencia = ec.ano_referencia\n",
    "LEFT JOIN teste.ecd_score_risco_consolidado sr\n",
    "    ON ind.cnpj = sr.cnpj\n",
    "    AND ind.ano_referencia = sr.ano_referencia\n",
    "WHERE ind.ativo_total > 0\n",
    "    AND ind.liquidez_corrente IS NOT NULL\n",
    "    AND ind.liquidez_corrente > 0\n",
    "    AND ind.liquidez_corrente < 10\n",
    "    AND ind.endividamento_geral >= 0\n",
    "    AND ind.endividamento_geral <= 2\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_cluster = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_clustering\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros para clustering: {total_cluster:,}\")\n",
    "\n",
    "if total_cluster > 0:\n",
    "    # Limitar a 20.000 registros\n",
    "    if total_cluster > 20000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_cluster:,}), amostrando 20.000...\")\n",
    "        df_cluster_full = spark.sql(\"SELECT * FROM vw_clustering ORDER BY ativo_total DESC LIMIT 20000\").toPandas()\n",
    "    else:\n",
    "        df_cluster_full = spark.sql(\"SELECT * FROM vw_clustering\").toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dataset carregado: {len(df_cluster_full):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PREPARA√á√ÉO DOS DADOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîß PREPARA√á√ÉO PARA CLUSTERING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Features para clustering\n",
    "    features_cluster = [\n",
    "        'ativo_total', 'receita_liquida', 'resultado_liquido',\n",
    "        'liquidez_corrente', 'liquidez_geral', 'endividamento_geral',\n",
    "        'margem_liquida_perc', 'roa_perc', 'roe_perc', 'score_risco'\n",
    "    ]\n",
    "    \n",
    "    # Remover NaN e infinitos\n",
    "    df_cluster = df_cluster_full[['cnpj', 'nm_razao_social', 'cd_uf', 'cnae_secao_descricao'] + features_cluster].copy()\n",
    "    df_cluster[features_cluster] = df_cluster[features_cluster].replace([np.inf, -np.inf], np.nan)\n",
    "    df_cluster = df_cluster.dropna(subset=features_cluster)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset limpo: {len(df_cluster):,} registros\")\n",
    "    \n",
    "    # Separar features\n",
    "    X_cluster = df_cluster[features_cluster]\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    print(\"\\nüìä Normalizando features...\")\n",
    "    scaler_cluster = StandardScaler()\n",
    "    X_scaled_cluster = scaler_cluster.fit_transform(X_cluster)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled_cluster, columns=features_cluster, index=X_cluster.index)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # M√âTODO DO COTOVELO (ELBOW METHOD)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä M√âTODO DO COTOVELO - DETERMINANDO K √ìTIMO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Testar de 2 a 10 clusters\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    K_range = range(2, 11)\n",
    "    \n",
    "    print(\"\\n‚è≥ Testando diferentes valores de K...\")\n",
    "    \n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_scaled_cluster)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X_scaled_cluster, kmeans.labels_))\n",
    "        print(f\"  K={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouette_scores[-1]:.4f}\")\n",
    "    \n",
    "    # Gr√°fico do cotovelo\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('M√©todo do Cotovelo', 'Silhouette Score')\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(K_range),\n",
    "            y=inertias,\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=10, color='#1f77b4'),\n",
    "            line=dict(width=2)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(K_range),\n",
    "            y=silhouette_scores,\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=10, color='#ff7f0e'),\n",
    "            line=dict(width=2)\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"N√∫mero de Clusters (K)\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"N√∫mero de Clusters (K)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Determina√ß√£o do N√∫mero √ìtimo de Clusters</b>',\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Escolher K √≥timo (maior silhouette)\n",
    "    k_otimo = list(K_range)[np.argmax(silhouette_scores)]\n",
    "    silhouette_maximo = silhouette_scores[np.argmax(silhouette_scores)]\n",
    "    print(f\"\\n‚úÖ K √≥timo sugerido: {k_otimo} (Silhouette Score: {silhouette_maximo:.4f})\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # K-MEANS CLUSTERING\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üéØ K-MEANS CLUSTERING (K={k_otimo})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n‚è≥ Aplicando K-Means com {k_otimo} clusters...\")\n",
    "    kmeans_final = KMeans(n_clusters=k_otimo, random_state=42, n_init=20)\n",
    "    df_cluster['cluster_kmeans'] = kmeans_final.fit_predict(X_scaled_cluster)\n",
    "    \n",
    "    # M√©tricas\n",
    "    silhouette_avg = silhouette_score(X_scaled_cluster, df_cluster['cluster_kmeans'])\n",
    "    davies_bouldin = davies_bouldin_score(X_scaled_cluster, df_cluster['cluster_kmeans'])\n",
    "    calinski_harabasz = calinski_harabasz_score(X_scaled_cluster, df_cluster['cluster_kmeans'])\n",
    "    \n",
    "    print(f\"\\nüìä M√âTRICAS DE QUALIDADE:\")\n",
    "    print(f\"  ‚Ä¢ Silhouette Score: {silhouette_avg:.4f} (quanto maior, melhor)\")\n",
    "    print(f\"  ‚Ä¢ Davies-Bouldin Index: {davies_bouldin:.4f} (quanto menor, melhor)\")\n",
    "    print(f\"  ‚Ä¢ Calinski-Harabasz Score: {calinski_harabasz:.2f} (quanto maior, melhor)\")\n",
    "    \n",
    "    # Estat√≠sticas por cluster\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä PERFIL DOS CLUSTERS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for cluster_id in range(k_otimo):\n",
    "        cluster_data = df_cluster[df_cluster['cluster_kmeans'] == cluster_id]\n",
    "        print(f\"\\nüéØ CLUSTER {cluster_id} ({len(cluster_data):,} empresas - {len(cluster_data)/len(df_cluster)*100:.1f}%):\")\n",
    "        \n",
    "        # Caracter√≠sticas m√©dias\n",
    "        print(f\"  ‚Ä¢ Ativo Total M√©dio: R$ {cluster_data['ativo_total'].mean()/1e6:.2f}M\")\n",
    "        print(f\"  ‚Ä¢ Receita L√≠quida M√©dia: R$ {cluster_data['receita_liquida'].mean()/1e6:.2f}M\")\n",
    "        print(f\"  ‚Ä¢ Liquidez Corrente M√©dia: {cluster_data['liquidez_corrente'].mean():.2f}\")\n",
    "        print(f\"  ‚Ä¢ Endividamento M√©dio: {cluster_data['endividamento_geral'].mean():.2%}\")\n",
    "        print(f\"  ‚Ä¢ Margem L√≠quida M√©dia: {cluster_data['margem_liquida_perc'].mean():.2f}%\")\n",
    "        print(f\"  ‚Ä¢ Score de Risco M√©dio: {cluster_data['score_risco'].mean():.2f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # REDU√á√ÉO DE DIMENSIONALIDADE (PCA)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî¨ REDU√á√ÉO DE DIMENSIONALIDADE - PCA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n‚è≥ Aplicando PCA...\")\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled_cluster)\n",
    "    \n",
    "    df_cluster['pca1'] = X_pca[:, 0]\n",
    "    df_cluster['pca2'] = X_pca[:, 1]\n",
    "    \n",
    "    variance_explained = pca.explained_variance_ratio_\n",
    "    print(f\"\\nüìä Vari√¢ncia explicada:\")\n",
    "    print(f\"  ‚Ä¢ PC1: {variance_explained[0]:.2%}\")\n",
    "    print(f\"  ‚Ä¢ PC2: {variance_explained[1]:.2%}\")\n",
    "    # CORRE√á√ÉO: Usar np.sum() em vez de sum() do PySpark\n",
    "    print(f\"  ‚Ä¢ Total: {np.sum(variance_explained):.2%}\")\n",
    "    \n",
    "    # Visualiza√ß√£o dos clusters no espa√ßo PCA\n",
    "    fig = px.scatter(\n",
    "        df_cluster,\n",
    "        x='pca1',\n",
    "        y='pca2',\n",
    "        color='cluster_kmeans',\n",
    "        hover_data=['nm_razao_social', 'cd_uf', 'ativo_total', 'score_risco'],\n",
    "        title='<b>Clusters K-Means - Visualiza√ß√£o PCA</b>',\n",
    "        labels={\n",
    "            'pca1': f'PC1 ({variance_explained[0]:.1%} vari√¢ncia)',\n",
    "            'pca2': f'PC2 ({variance_explained[1]:.1%} vari√¢ncia)',\n",
    "            'cluster_kmeans': 'Cluster'\n",
    "        },\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO: CARACTER√çSTICAS DOS CLUSTERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä VISUALIZA√á√ÉO: CARACTER√çSTICAS POR CLUSTER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar dados agregados\n",
    "    cluster_stats = df_cluster.groupby('cluster_kmeans')[features_cluster].mean()\n",
    "    cluster_stats_normalized = (cluster_stats - cluster_stats.min()) / (cluster_stats.max() - cluster_stats.min())\n",
    "    \n",
    "    # Heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=cluster_stats_normalized.values.T,\n",
    "        x=[f'Cluster {i}' for i in range(k_otimo)],\n",
    "        y=features_cluster,\n",
    "        colorscale='RdYlGn',\n",
    "        text=cluster_stats.values.T.round(2),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title=\"Valor Normalizado\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Perfil dos Clusters - Caracter√≠sticas Normalizadas</b>',\n",
    "        xaxis_title='Cluster',\n",
    "        yaxis_title='Feature',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DISTRIBUI√á√ÉO GEOGR√ÅFICA DOS CLUSTERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üó∫Ô∏è DISTRIBUI√á√ÉO GEOGR√ÅFICA DOS CLUSTERS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cluster_uf = df_cluster.groupby(['cluster_kmeans', 'cd_uf']).size().reset_index(name='count')\n",
    "    \n",
    "    fig = px.bar(\n",
    "        cluster_uf,\n",
    "        x='cd_uf',\n",
    "        y='count',\n",
    "        color='cluster_kmeans',\n",
    "        title='<b>Distribui√ß√£o dos Clusters por UF</b>',\n",
    "        labels={'count': 'Quantidade de Empresas', 'cd_uf': 'UF', 'cluster_kmeans': 'Cluster'},\n",
    "        barmode='group'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=500)\n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DBSCAN (OPCIONAL)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üîç DBSCAN - CLUSTERING BASEADO EM DENSIDADE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Usar amostra menor para DBSCAN se dataset muito grande\n",
    "    if len(df_cluster) > 5000:\n",
    "        print(f\"‚ö†Ô∏è Dataset muito grande, usando amostra de 5.000 registros...\")\n",
    "        sample_indices = np.random.choice(len(df_cluster), 5000, replace=False)\n",
    "        X_dbscan = X_scaled_cluster[sample_indices]\n",
    "        df_dbscan = df_cluster.iloc[sample_indices].copy()\n",
    "    else:\n",
    "        X_dbscan = X_scaled_cluster\n",
    "        df_dbscan = df_cluster.copy()\n",
    "    \n",
    "    print(\"\\n‚è≥ Aplicando DBSCAN...\")\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "    df_dbscan['cluster_dbscan'] = dbscan.fit_predict(X_dbscan)\n",
    "    \n",
    "    n_clusters_dbscan = len(set(df_dbscan['cluster_dbscan'])) - (1 if -1 in df_dbscan['cluster_dbscan'] else 0)\n",
    "    n_noise = list(df_dbscan['cluster_dbscan']).count(-1)\n",
    "    \n",
    "    print(f\"\\nüìä Clusters encontrados: {n_clusters_dbscan}\")\n",
    "    print(f\"üìä Pontos de ru√≠do: {n_noise} ({n_noise/len(df_dbscan)*100:.1f}%)\")\n",
    "    \n",
    "    if n_clusters_dbscan > 0 and n_clusters_dbscan < 20:\n",
    "        # Visualizar DBSCAN\n",
    "        df_dbscan_plot = df_dbscan.copy()\n",
    "        pca_dbscan = PCA(n_components=2, random_state=42)\n",
    "        X_pca_dbscan = pca_dbscan.fit_transform(X_dbscan)\n",
    "        df_dbscan_plot['pca1'] = X_pca_dbscan[:, 0]\n",
    "        df_dbscan_plot['pca2'] = X_pca_dbscan[:, 1]\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            df_dbscan_plot,\n",
    "            x='pca1',\n",
    "            y='pca2',\n",
    "            color='cluster_dbscan',\n",
    "            title='<b>DBSCAN Clusters - Visualiza√ß√£o PCA</b>',\n",
    "            labels={'cluster_dbscan': 'Cluster (-1 = Ru√≠do)'},\n",
    "            color_continuous_scale='Viridis'\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600)\n",
    "        fig.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados insuficientes para clustering\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de clustering conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aecdbf-e045-406b-827a-0d85718a15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 8: AN√ÅLISE SETORIAL E BENCHMARKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üè≠ AN√ÅLISE SETORIAL E BENCHMARKING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR DADOS SETORIAIS\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_analise_setorial AS\n",
    "SELECT \n",
    "    ec.cnae_secao,\n",
    "    ec.cnae_secao_descricao,\n",
    "    ec.cnae_divisao,\n",
    "    ec.cnae_divisao_descricao,\n",
    "    CAST(ind.ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    COUNT(DISTINCT ec.cnpj) AS qtd_empresas,\n",
    "    CAST(COALESCE(AVG(ind.ativo_total), 0) AS DOUBLE) AS media_ativo,\n",
    "    CAST(COALESCE(AVG(ind.receita_liquida), 0) AS DOUBLE) AS media_receita,\n",
    "    CAST(COALESCE(AVG(ind.resultado_liquido), 0) AS DOUBLE) AS media_resultado,\n",
    "    CAST(COALESCE(AVG(ind.liquidez_corrente), 0) AS DOUBLE) AS media_liquidez,\n",
    "    CAST(COALESCE(AVG(ind.endividamento_geral), 0) AS DOUBLE) AS media_endividamento,\n",
    "    CAST(COALESCE(AVG(ind.margem_liquida_perc), 0) AS DOUBLE) AS media_margem_liquida,\n",
    "    CAST(COALESCE(AVG(ind.roe_retorno_patrimonio_perc), 0) AS DOUBLE) AS media_roe,\n",
    "    CAST(COALESCE(AVG(sr.score_risco_total), 0) AS DOUBLE) AS media_score_risco,\n",
    "    COUNT(DISTINCT CASE WHEN ec.empresa_grande_porte = 'Sim' THEN ec.cnpj END) AS qtd_grande_porte,\n",
    "    COUNT(DISTINCT CASE WHEN sr.classificacao_risco IN ('RISCO CR√çTICO', 'RISCO ALTO') THEN ec.cnpj END) AS qtd_alto_risco\n",
    "FROM teste.ecd_empresas_cadastro ec\n",
    "INNER JOIN teste.ecd_indicadores_financeiros ind\n",
    "    ON ec.cnpj = ind.cnpj\n",
    "    AND ec.ano_referencia = ind.ano_referencia\n",
    "LEFT JOIN teste.ecd_score_risco_consolidado sr\n",
    "    ON ec.cnpj = sr.cnpj\n",
    "    AND ec.ano_referencia = sr.ano_referencia\n",
    "WHERE ec.cnae_secao IS NOT NULL\n",
    "    AND ind.ativo_total > 0\n",
    "GROUP BY ec.cnae_secao, ec.cnae_secao_descricao, ec.cnae_divisao, ec.cnae_divisao_descricao,\n",
    "         CAST(ind.ano_referencia / 100 AS INT)\n",
    "HAVING COUNT(DISTINCT ec.cnpj) >= 3\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_setorial = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_analise_setorial\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de setores/per√≠odos: {total_setorial:,}\")\n",
    "\n",
    "if total_setorial > 0:\n",
    "    # Limitar se necess√°rio\n",
    "    if total_setorial > 1000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_setorial:,}), limitando a 1.000...\")\n",
    "        df_setorial = spark.sql(\"SELECT * FROM vw_analise_setorial ORDER BY qtd_empresas DESC LIMIT 1000\").toPandas()\n",
    "    else:\n",
    "        df_spark = spark.sql(\"SELECT * FROM vw_analise_setorial\")\n",
    "        df_spark.cache()\n",
    "        df_setorial = df_spark.toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dados setoriais carregados: {len(df_setorial):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TOP SETORES POR QUANTIDADE DE EMPRESAS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä TOP 20 SETORES - QUANTIDADE DE EMPRESAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Agregar por se√ß√£o (ano mais recente)\n",
    "    ano_mais_recente = df_setorial['ano_fiscal'].max()\n",
    "    df_ano_atual = df_setorial[df_setorial['ano_fiscal'] == ano_mais_recente].copy()\n",
    "    \n",
    "    df_top_setores = df_ano_atual.groupby('cnae_secao_descricao').agg({\n",
    "        'qtd_empresas': 'sum',\n",
    "        'media_ativo': 'mean',\n",
    "        'media_receita': 'mean',\n",
    "        'media_score_risco': 'mean',\n",
    "        'qtd_grande_porte': 'sum',\n",
    "        'qtd_alto_risco': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_top_setores = df_top_setores.sort_values('qtd_empresas', ascending=False).head(20)\n",
    "    df_top_setores['setor_curto'] = df_top_setores['cnae_secao_descricao'].str[:50]\n",
    "    \n",
    "    print(f\"\\nüìÖ Ano de refer√™ncia: {ano_mais_recente}\")\n",
    "    print(\"\\n\" + df_top_setores[['setor_curto', 'qtd_empresas', 'media_ativo', 'media_receita']].to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico Top Setores\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            y=df_top_setores['setor_curto'],\n",
    "            x=df_top_setores['qtd_empresas'],\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color=df_top_setores['qtd_empresas'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Empresas\")\n",
    "            ),\n",
    "            text=df_top_setores['qtd_empresas'],\n",
    "            textposition='outside',\n",
    "            hovertemplate='<b>%{y}</b><br>Empresas: %{x:,}<extra></extra>'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Top 20 Setores por Quantidade de Empresas</b>',\n",
    "        xaxis_title='Quantidade de Empresas',\n",
    "        yaxis_title='Setor',\n",
    "        height=700,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPARA√á√ÉO DE INDICADORES POR SETOR\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä COMPARA√á√ÉO DE INDICADORES - TOP 15 SETORES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_top15 = df_top_setores.head(15).copy()\n",
    "    df_top15['ativo_milhoes'] = df_top15['media_ativo'] / 1_000_000\n",
    "    df_top15['receita_milhoes'] = df_top15['media_receita'] / 1_000_000\n",
    "    \n",
    "    # Gr√°fico de compara√ß√£o m√∫ltipla\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Ativo M√©dio (Milh√µes R$)',\n",
    "            'Receita M√©dia (Milh√µes R$)',\n",
    "            'Score de Risco M√©dio',\n",
    "            'Liquidez Corrente M√©dia'\n",
    "        ),\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.12\n",
    "    )\n",
    "    \n",
    "    # Ativo\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df_top15['setor_curto'],\n",
    "            x=df_top15['ativo_milhoes'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#1f77b4'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Receita\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df_top15['setor_curto'],\n",
    "            x=df_top15['receita_milhoes'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#ff7f0e'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Score de Risco\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df_top15['setor_curto'],\n",
    "            x=df_top15['media_score_risco'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#d62728'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Liquidez\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df_top15['setor_curto'],\n",
    "            x=df_ano_atual.groupby('cnae_secao_descricao')['media_liquidez'].mean().loc[df_top15['cnae_secao_descricao']].values,\n",
    "            orientation='h',\n",
    "            marker=dict(color='#2ca02c'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Atualizar layout\n",
    "    for i in range(1, 3):\n",
    "        for j in range(1, 3):\n",
    "            fig.update_yaxes(autorange='reversed', row=i, col=j)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Compara√ß√£o de Indicadores por Setor</b>',\n",
    "        height=900,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SETORES COM MAIOR RISCO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è SETORES COM MAIOR RISCO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_risco_setor = df_ano_atual.sort_values('media_score_risco', ascending=False).head(15).copy()\n",
    "    df_risco_setor['perc_alto_risco'] = (df_risco_setor['qtd_alto_risco'] / df_risco_setor['qtd_empresas']) * 100\n",
    "    \n",
    "    print(\"\\nüìä Top 15 setores com maior score de risco:\")\n",
    "    print(df_risco_setor[['cnae_secao_descricao', 'qtd_empresas', 'media_score_risco', 'perc_alto_risco']].to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df_risco_setor['cnae_secao_descricao'].str[:40],\n",
    "        x=df_risco_setor['media_score_risco'],\n",
    "        name='Score M√©dio',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#d62728'),\n",
    "        text=df_risco_setor['media_score_risco'].round(2),\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Top 15 Setores - Maior Score de Risco</b>',\n",
    "        xaxis_title='Score de Risco M√©dio',\n",
    "        yaxis_title='Setor',\n",
    "        height=600,\n",
    "        yaxis=dict(autorange='reversed')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AN√ÅLISE DE RENTABILIDADE POR SETOR\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üíπ AN√ÅLISE DE RENTABILIDADE POR SETOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_rentabilidade = df_ano_atual[df_ano_atual['qtd_empresas'] >= 10].sort_values('media_margem_liquida', ascending=False).head(15).copy()\n",
    "    \n",
    "    print(\"\\nüìä Top 15 setores - Maior margem l√≠quida:\")\n",
    "    print(df_rentabilidade[['cnae_secao_descricao', 'qtd_empresas', 'media_margem_liquida', 'media_roe']].to_string(index=False))\n",
    "    \n",
    "    # Scatter: Margem x ROE\n",
    "    fig = px.scatter(\n",
    "        df_ano_atual[df_ano_atual['qtd_empresas'] >= 5],\n",
    "        x='media_margem_liquida',\n",
    "        y='media_roe',\n",
    "        size='qtd_empresas',\n",
    "        color='media_score_risco',\n",
    "        hover_data=['cnae_secao_descricao', 'qtd_empresas'],\n",
    "        labels={\n",
    "            'media_margem_liquida': 'Margem L√≠quida M√©dia (%)',\n",
    "            'media_roe': 'ROE M√©dio (%)',\n",
    "            'qtd_empresas': 'Qtd. Empresas',\n",
    "            'media_score_risco': 'Score de Risco'\n",
    "        },\n",
    "        title='<b>Rentabilidade por Setor: Margem L√≠quida vs ROE</b>',\n",
    "        color_continuous_scale='RdYlGn_r'\n",
    "    )\n",
    "    \n",
    "    # Adicionar linhas de refer√™ncia\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EVOLU√á√ÉO TEMPORAL POR SETOR (TOP 5)\n",
    "    # ========================================================================\n",
    "    \n",
    "    if df_setorial['ano_fiscal'].nunique() > 1:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìà EVOLU√á√ÉO TEMPORAL - TOP 5 SETORES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Identificar top 5 setores\n",
    "        top5_setores = df_ano_atual.nlargest(5, 'qtd_empresas')['cnae_secao_descricao'].tolist()\n",
    "        df_evolucao = df_setorial[df_setorial['cnae_secao_descricao'].isin(top5_setores)].copy()\n",
    "        \n",
    "        # Agregar por ano e setor\n",
    "        df_evolucao_agg = df_evolucao.groupby(['ano_fiscal', 'cnae_secao_descricao']).agg({\n",
    "            'qtd_empresas': 'sum',\n",
    "            'media_receita': 'mean',\n",
    "            'media_score_risco': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Gr√°fico de evolu√ß√£o\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=('Evolu√ß√£o da Quantidade de Empresas', 'Evolu√ß√£o do Score de Risco'),\n",
    "            vertical_spacing=0.15\n",
    "        )\n",
    "        \n",
    "        for setor in top5_setores:\n",
    "            dados_setor = df_evolucao_agg[df_evolucao_agg['cnae_secao_descricao'] == setor]\n",
    "            setor_curto = setor[:30]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=dados_setor['ano_fiscal'],\n",
    "                    y=dados_setor['qtd_empresas'],\n",
    "                    name=setor_curto,\n",
    "                    mode='lines+markers',\n",
    "                    line=dict(width=2),\n",
    "                    marker=dict(size=8)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=dados_setor['ano_fiscal'],\n",
    "                    y=dados_setor['media_score_risco'],\n",
    "                    name=setor_curto,\n",
    "                    mode='lines+markers',\n",
    "                    line=dict(width=2),\n",
    "                    marker=dict(size=8),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Ano Fiscal\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Quantidade de Empresas\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Score de Risco M√©dio\", row=2, col=1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='<b>Evolu√ß√£o Temporal - Top 5 Setores</b>',\n",
    "            height=700,\n",
    "            hovermode='x unified'\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MATRIZ DE COMPARA√á√ÉO SETORIAL\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä MATRIZ DE COMPARA√á√ÉO SETORIAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Selecionar top 10 setores\n",
    "    top10_setores = df_top_setores.head(10)['cnae_secao_descricao'].tolist()\n",
    "    df_matriz = df_ano_atual[df_ano_atual['cnae_secao_descricao'].isin(top10_setores)].copy()\n",
    "    \n",
    "    # Normalizar valores para compara√ß√£o\n",
    "    features_comparacao = ['media_ativo', 'media_receita', 'media_liquidez', 'media_endividamento', \n",
    "                           'media_margem_liquida', 'media_roe', 'media_score_risco']\n",
    "    \n",
    "    df_matriz_norm = df_matriz.set_index('cnae_secao_descricao')[features_comparacao].copy()\n",
    "    df_matriz_norm = (df_matriz_norm - df_matriz_norm.min()) / (df_matriz_norm.max() - df_matriz_norm.min())\n",
    "    \n",
    "    # Preparar labels\n",
    "    labels_curtos = [s[:30] for s in df_matriz_norm.index]\n",
    "    \n",
    "    # Heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=df_matriz_norm.values,\n",
    "        x=['Ativo', 'Receita', 'Liquidez', 'Endiv.', 'Margem', 'ROE', 'Risco'],\n",
    "        y=labels_curtos,\n",
    "        colorscale='RdYlGn',\n",
    "        text=df_matriz_norm.values.round(2),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 9},\n",
    "        colorbar=dict(title=\"Normalizado<br>(0-1)\")\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Matriz de Compara√ß√£o Setorial (Valores Normalizados)</b>',\n",
    "        xaxis_title='Indicador',\n",
    "        yaxis_title='Setor',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados setoriais n√£o dispon√≠veis\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise setorial conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d60a4-881d-4f9b-8d70-c5878df09a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 9: DASHBOARD EXECUTIVO INTERATIVO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä DASHBOARD EXECUTIVO - ECD ONLINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR DADOS CONSOLIDADOS PARA DASHBOARD\n",
    "# ============================================================================\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_dashboard AS\n",
    "SELECT \n",
    "    ec.cnpj,\n",
    "    ec.nm_razao_social,\n",
    "    ec.cd_uf,\n",
    "    ec.cnae_secao,\n",
    "    ec.cnae_secao_descricao,\n",
    "    ec.empresa_grande_porte,\n",
    "    CAST(ind.ano_referencia / 100 AS INT) AS ano_fiscal,\n",
    "    CAST(COALESCE(ind.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(ind.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(ind.resultado_liquido, 0) AS DOUBLE) AS resultado_liquido,\n",
    "    CAST(COALESCE(ind.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(ind.endividamento_geral, 0) AS DOUBLE) AS endividamento_geral,\n",
    "    CAST(COALESCE(ind.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida_perc,\n",
    "    CAST(COALESCE(ind.roe_retorno_patrimonio_perc, 0) AS DOUBLE) AS roe_perc,\n",
    "    sr.classificacao_risco,\n",
    "    CAST(COALESCE(sr.score_risco_total, 0) AS DOUBLE) AS score_risco,\n",
    "    CAST(COALESCE(sr.qtd_indicios_neaf, 0) AS DOUBLE) AS qtd_indicios\n",
    "FROM teste.ecd_indicadores_financeiros ind\n",
    "INNER JOIN teste.ecd_empresas_cadastro ec\n",
    "    ON ind.cnpj = ec.cnpj\n",
    "    AND ind.ano_referencia = ec.ano_referencia\n",
    "LEFT JOIN teste.ecd_score_risco_consolidado sr\n",
    "    ON ind.cnpj = sr.cnpj\n",
    "    AND ind.ano_referencia = sr.ano_referencia\n",
    "WHERE ind.ativo_total > 0\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_dash = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_dashboard\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros para dashboard: {total_dash:,}\")\n",
    "\n",
    "if total_dash > 0:\n",
    "    # Limitar a 30.000 registros\n",
    "    if total_dash > 30000:\n",
    "        print(f\"‚ö†Ô∏è Muitos registros ({total_dash:,}), limitando a 30.000...\")\n",
    "        df_dash = spark.sql(\"SELECT * FROM vw_dashboard ORDER BY ativo_total DESC LIMIT 30000\").toPandas()\n",
    "    else:\n",
    "        df_spark = spark.sql(\"SELECT * FROM vw_dashboard\")\n",
    "        df_spark.cache()\n",
    "        df_dash = df_spark.toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dados do dashboard carregados: {len(df_dash):,} registros\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # M√âTRICAS PRINCIPAIS (KPIs)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä INDICADORES-CHAVE (KPIs)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calcular KPIs\n",
    "    kpis = {\n",
    "        'total_empresas': df_dash['cnpj'].nunique(),\n",
    "        'ativo_total': df_dash['ativo_total'].sum(),\n",
    "        'receita_total': df_dash['receita_liquida'].sum(),\n",
    "        'resultado_total': df_dash['resultado_liquido'].sum(),\n",
    "        'empresas_lucro': (df_dash['resultado_liquido'] > 0).sum(),\n",
    "        'empresas_prejuizo': (df_dash['resultado_liquido'] < 0).sum(),\n",
    "        'empresas_alto_risco': df_dash[df_dash['classificacao_risco'].isin(['RISCO CR√çTICO', 'RISCO ALTO'])]['cnpj'].nunique() if 'classificacao_risco' in df_dash.columns else 0,\n",
    "        'liquidez_media': df_dash['liquidez_corrente'].mean(),\n",
    "        'endividamento_medio': df_dash['endividamento_geral'].mean(),\n",
    "        'margem_media': df_dash['margem_liquida_perc'].mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüè¢ Total de Empresas: {kpis['total_empresas']:,}\")\n",
    "    print(f\"üí∞ Ativo Total: R$ {kpis['ativo_total']/1e9:.2f} bilh√µes\")\n",
    "    print(f\"üíµ Receita Total: R$ {kpis['receita_total']/1e9:.2f} bilh√µes\")\n",
    "    print(f\"üìà Resultado Total: R$ {kpis['resultado_total']/1e9:.2f} bilh√µes\")\n",
    "    print(f\"‚úÖ Empresas com Lucro: {kpis['empresas_lucro']:,} ({kpis['empresas_lucro']/len(df_dash)*100:.1f}%)\")\n",
    "    print(f\"‚ùå Empresas com Preju√≠zo: {kpis['empresas_prejuizo']:,} ({kpis['empresas_prejuizo']/len(df_dash)*100:.1f}%)\")\n",
    "    print(f\"‚ö†Ô∏è Empresas Alto Risco: {kpis['empresas_alto_risco']:,}\")\n",
    "    print(f\"üìä Liquidez Corrente M√©dia: {kpis['liquidez_media']:.2f}\")\n",
    "    print(f\"üìä Endividamento M√©dio: {kpis['endividamento_medio']:.2%}\")\n",
    "    print(f\"üìä Margem L√≠quida M√©dia: {kpis['margem_media']:.2f}%\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DASHBOARD PRINCIPAL - 6 PAIN√âIS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä GERANDO DASHBOARD PRINCIPAL...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Criar subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'üìä Distribui√ß√£o de Risco',\n",
    "            'üí∞ Top 10 Empresas por Ativo',\n",
    "            'üó∫Ô∏è Distribui√ß√£o por UF',\n",
    "            'üè≠ Top 10 Setores',\n",
    "            'üìà Indicadores Financeiros',\n",
    "            '‚ö†Ô∏è Empresas em Risco'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'pie'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'bar'}],\n",
    "            [{'type': 'box'}, {'type': 'scatter'}]\n",
    "        ],\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.10\n",
    "    )\n",
    "    \n",
    "    # 1. DISTRIBUI√á√ÉO DE RISCO (Pie Chart)\n",
    "    if 'classificacao_risco' in df_dash.columns:\n",
    "        dist_risco = df_dash['classificacao_risco'].value_counts()\n",
    "        fig.add_trace(\n",
    "            go.Pie(\n",
    "                labels=dist_risco.index,\n",
    "                values=dist_risco.values,\n",
    "                hole=0.4,\n",
    "                marker=dict(colors=['#d62728', '#ff7f0e', '#ffbb33', '#2ca02c']),\n",
    "                textinfo='label+percent'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. TOP 10 EMPRESAS POR ATIVO\n",
    "    df_top10_ativo = df_dash.nlargest(10, 'ativo_total').copy()\n",
    "    df_top10_ativo['razao_curta'] = df_top10_ativo['nm_razao_social'].str[:25]\n",
    "    df_top10_ativo['ativo_bi'] = df_top10_ativo['ativo_total'] / 1e9\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=df_top10_ativo['razao_curta'],\n",
    "            x=df_top10_ativo['ativo_bi'],\n",
    "            orientation='h',\n",
    "            marker=dict(color='#1f77b4'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. DISTRIBUI√á√ÉO POR UF\n",
    "    dist_uf = df_dash['cd_uf'].value_counts().head(15)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=dist_uf.index,\n",
    "            y=dist_uf.values,\n",
    "            marker=dict(color='#ff7f0e'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. TOP 10 SETORES\n",
    "    if 'cnae_secao_descricao' in df_dash.columns:\n",
    "        dist_setor = df_dash.groupby('cnae_secao_descricao').size().sort_values(ascending=False).head(10)\n",
    "        setores_curtos = [s[:25] for s in dist_setor.index]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                y=setores_curtos,\n",
    "                x=dist_setor.values,\n",
    "                orientation='h',\n",
    "                marker=dict(color='#2ca02c'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # 5. BOX PLOT - INDICADORES FINANCEIROS\n",
    "    indicadores = ['liquidez_corrente', 'endividamento_geral', 'margem_liquida_perc']\n",
    "    cores_box = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    for idx, ind in enumerate(indicadores):\n",
    "        # Limpar outliers extremos para visualiza√ß√£o\n",
    "        dados_clean = df_dash[ind].clip(\n",
    "            df_dash[ind].quantile(0.05),\n",
    "            df_dash[ind].quantile(0.95)\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=dados_clean,\n",
    "                name=ind.replace('_', ' ').title(),\n",
    "                marker=dict(color=cores_box[idx]),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # 6. SCATTER - RISCO vs ATIVO\n",
    "    if 'score_risco' in df_dash.columns:\n",
    "        # Preparar dados para scatter\n",
    "        df_scatter = df_dash[\n",
    "            (df_dash['score_risco'] > 0) &\n",
    "            (df_dash['ativo_total'] > 0)\n",
    "        ].copy()\n",
    "        \n",
    "        # Amostrar se muitos dados - FIX: Usar min() do Python\n",
    "        tamanho_amostra_scatter = 1000 if len(df_scatter) > 1000 else len(df_scatter)\n",
    "        df_scatter = df_scatter.sample(n=tamanho_amostra_scatter, random_state=42)\n",
    "        \n",
    "        df_scatter['ativo_log'] = np.log10(df_scatter['ativo_total'])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_scatter['score_risco'],\n",
    "                y=df_scatter['ativo_log'],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=6,\n",
    "                    color=df_scatter['score_risco'],\n",
    "                    colorscale='Reds',\n",
    "                    showscale=False,\n",
    "                    opacity=0.6\n",
    "                ),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=3, col=2\n",
    "        )\n",
    "    \n",
    "    # Atualizar layouts dos eixos\n",
    "    fig.update_xaxes(title_text=\"Ativo (Bi R$)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"UF\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Qtd. Empresas\", row=2, col=2)\n",
    "    fig.update_xaxes(title_text=\"Score de Risco\", row=3, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Empresa\", row=1, col=2, autorange='reversed')\n",
    "    fig.update_yaxes(title_text=\"Qtd. Empresas\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Setor\", row=2, col=2, autorange='reversed')\n",
    "    fig.update_yaxes(title_text=\"Valor\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Log10(Ativo)\", row=3, col=2)\n",
    "    \n",
    "    # Layout geral\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': '<b>DASHBOARD EXECUTIVO - ECD ONLINE</b><br><sub>Escritura√ß√£o Cont√°bil Digital - An√°lise Consolidada</sub>',\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center'\n",
    "        },\n",
    "        height=1200,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DASHBOARD FINANCEIRO DETALHADO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí∞ DASHBOARD FINANCEIRO DETALHADO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar dados\n",
    "    df_financeiro = df_dash[df_dash['receita_liquida'] > 0].copy()\n",
    "    df_financeiro['lucro_prejuizo'] = df_financeiro['resultado_liquido'].apply(\n",
    "        lambda x: 'Lucro' if x > 0 else 'Preju√≠zo'\n",
    "    )\n",
    "    \n",
    "    # Criar dashboard financeiro\n",
    "    fig_fin = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'üíµ Distribui√ß√£o de Receita L√≠quida',\n",
    "            'üìä Lucro vs Preju√≠zo',\n",
    "            'üìà ROE por Porte de Empresa',\n",
    "            'üí∞ Receita x Resultado'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'histogram'}, {'type': 'bar'}],\n",
    "            [{'type': 'box'}, {'type': 'scatter'}]\n",
    "        ],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.12\n",
    "    )\n",
    "    \n",
    "    # 1. Histograma de Receita\n",
    "    fig_fin.add_trace(\n",
    "        go.Histogram(\n",
    "            x=np.log10(df_financeiro['receita_liquida'].clip(lower=1)),\n",
    "            nbinsx=50,\n",
    "            marker=dict(color='#1f77b4'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Bar - Lucro vs Preju√≠zo\n",
    "    dist_resultado = df_financeiro['lucro_prejuizo'].value_counts()\n",
    "    \n",
    "    fig_fin.add_trace(\n",
    "        go.Bar(\n",
    "            x=dist_resultado.index,\n",
    "            y=dist_resultado.values,\n",
    "            marker=dict(color=['#2ca02c', '#d62728']),\n",
    "            text=dist_resultado.values,\n",
    "            textposition='outside',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Box Plot - ROE por Porte\n",
    "    if 'empresa_grande_porte' in df_financeiro.columns:\n",
    "        for porte in df_financeiro['empresa_grande_porte'].unique():\n",
    "            dados_porte = df_financeiro[df_financeiro['empresa_grande_porte'] == porte]['roe_perc']\n",
    "            dados_porte = dados_porte.clip(-50, 50)\n",
    "            \n",
    "            fig_fin.add_trace(\n",
    "                go.Box(\n",
    "                    y=dados_porte,\n",
    "                    name=f\"Porte: {porte}\",\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    # 4. Scatter - Receita x Resultado - FIX: Usar min() do Python\n",
    "    tamanho_scatter_fin = 1000 if len(df_financeiro) > 1000 else len(df_financeiro)\n",
    "    df_scatter_fin = df_financeiro.sample(n=tamanho_scatter_fin, random_state=42).copy()\n",
    "    df_scatter_fin['receita_mi'] = df_scatter_fin['receita_liquida'] / 1e6\n",
    "    df_scatter_fin['resultado_mi'] = df_scatter_fin['resultado_liquido'] / 1e6\n",
    "    \n",
    "    fig_fin.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_scatter_fin['receita_mi'],\n",
    "            y=df_scatter_fin['resultado_mi'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=df_scatter_fin['margem_liquida_perc'],\n",
    "                colorscale='RdYlGn',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Margem %\", x=1.15),\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Linha de break-even\n",
    "    fig_fin.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, df_scatter_fin['receita_mi'].max()],\n",
    "            y=[0, 0],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', dash='dash'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Atualizar eixos\n",
    "    fig_fin.update_xaxes(title_text=\"Log10(Receita)\", row=1, col=1)\n",
    "    fig_fin.update_xaxes(title_text=\"Situa√ß√£o\", row=1, col=2)\n",
    "    fig_fin.update_xaxes(title_text=\"Receita (Mi R$)\", row=2, col=2)\n",
    "    \n",
    "    fig_fin.update_yaxes(title_text=\"Frequ√™ncia\", row=1, col=1)\n",
    "    fig_fin.update_yaxes(title_text=\"Qtd. Empresas\", row=1, col=2)\n",
    "    fig_fin.update_yaxes(title_text=\"ROE (%)\", row=2, col=1)\n",
    "    fig_fin.update_yaxes(title_text=\"Resultado (Mi R$)\", row=2, col=2)\n",
    "    \n",
    "    fig_fin.update_layout(\n",
    "        title='<b>Dashboard Financeiro - An√°lise de Receitas e Resultados</b>',\n",
    "        height=900,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_fin.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SUNBURST - HIERARQUIA DE DADOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üåû VISUALIZA√á√ÉO HIER√ÅRQUICA (SUNBURST)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preparar dados para sunburst\n",
    "    if 'cnae_secao_descricao' in df_dash.columns and 'classificacao_risco' in df_dash.columns:\n",
    "        # Agregar por setor e risco\n",
    "        df_sunburst = df_dash.groupby(['cnae_secao_descricao', 'classificacao_risco']).agg({\n",
    "            'ativo_total': 'sum',\n",
    "            'cnpj': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        df_sunburst.columns = ['setor', 'risco', 'ativo', 'empresas']\n",
    "        \n",
    "        # Top 10 setores\n",
    "        top_setores = df_dash['cnae_secao_descricao'].value_counts().head(10).index.tolist()\n",
    "        df_sunburst = df_sunburst[df_sunburst['setor'].isin(top_setores)]\n",
    "        \n",
    "        # Criar hierarquia\n",
    "        labels = ['Total']\n",
    "        parents = ['']\n",
    "        values = [df_sunburst['empresas'].sum()]\n",
    "        \n",
    "        for setor in df_sunburst['setor'].unique():\n",
    "            setor_curto = setor[:30]\n",
    "            labels.append(setor_curto)\n",
    "            parents.append('Total')\n",
    "            values.append(df_sunburst[df_sunburst['setor'] == setor]['empresas'].sum())\n",
    "            \n",
    "            for _, row in df_sunburst[df_sunburst['setor'] == setor].iterrows():\n",
    "                labels.append(f\"{setor_curto} - {row['risco']}\")\n",
    "                parents.append(setor_curto)\n",
    "                values.append(row['empresas'])\n",
    "        \n",
    "        fig_sun = go.Figure(go.Sunburst(\n",
    "            labels=labels,\n",
    "            parents=parents,\n",
    "            values=values,\n",
    "            branchvalues=\"total\",\n",
    "            marker=dict(colorscale='RdYlGn_r')\n",
    "        ))\n",
    "        \n",
    "        fig_sun.update_layout(\n",
    "            title='<b>Hierarquia: Setores e Classifica√ß√£o de Risco</b>',\n",
    "            height=700\n",
    "        )\n",
    "        \n",
    "        fig_sun.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Dados insuficientes para dashboard\")\n",
    "\n",
    "print(\"\\n‚úÖ Dashboard executivo conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef037b09-1d9b-4eca-9bc4-73958819e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# C√âLULA 10: RELAT√ìRIO FINAL E RECOMENDA√á√ïES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã RELAT√ìRIO FINAL - PROJETO ECD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMO EXECUTIVO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ RESUMO EXECUTIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Carregar m√©tricas consolidadas\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_resumo_executivo AS\n",
    "SELECT \n",
    "    COUNT(DISTINCT ec.cnpj) AS total_empresas,\n",
    "    COUNT(DISTINCT ec.id_ecd) AS total_ecds,\n",
    "    CAST(MAX(ec.ano_referencia / 100) AS INT) AS ano_mais_recente,\n",
    "    CAST(SUM(COALESCE(ind.ativo_total, 0)) AS DOUBLE) AS ativo_total_consolidado,\n",
    "    CAST(SUM(COALESCE(ind.receita_liquida, 0)) AS DOUBLE) AS receita_total_consolidada,\n",
    "    CAST(SUM(COALESCE(ind.resultado_liquido, 0)) AS DOUBLE) AS resultado_total_consolidado,\n",
    "    CAST(AVG(COALESCE(ind.liquidez_corrente, 0)) AS DOUBLE) AS liquidez_media,\n",
    "    CAST(AVG(COALESCE(ind.endividamento_geral, 0)) AS DOUBLE) AS endividamento_medio,\n",
    "    CAST(AVG(COALESCE(ind.margem_liquida_perc, 0)) AS DOUBLE) AS margem_media,\n",
    "    COUNT(DISTINCT CASE WHEN ec.empresa_grande_porte = 'Sim' THEN ec.cnpj END) AS empresas_grande_porte,\n",
    "    COUNT(DISTINCT CASE WHEN sr.classificacao_risco IN ('RISCO CR√çTICO', 'RISCO ALTO') THEN ec.cnpj END) AS empresas_alto_risco,\n",
    "    COUNT(DISTINCT CASE WHEN ind.resultado_liquido > 0 THEN ec.cnpj END) AS empresas_lucro,\n",
    "    COUNT(DISTINCT CASE WHEN ind.resultado_liquido < 0 THEN ec.cnpj END) AS empresas_prejuizo\n",
    "FROM teste.ecd_empresas_cadastro ec\n",
    "LEFT JOIN teste.ecd_indicadores_financeiros ind\n",
    "    ON ec.cnpj = ind.cnpj\n",
    "    AND ec.ano_referencia = ind.ano_referencia\n",
    "LEFT JOIN teste.ecd_score_risco_consolidado sr\n",
    "    ON ec.cnpj = sr.cnpj\n",
    "    AND ec.ano_referencia = sr.ano_referencia\n",
    "\"\"\")\n",
    "\n",
    "resumo = spark.sql(\"SELECT * FROM vw_resumo_executivo\").toPandas()\n",
    "\n",
    "if len(resumo) > 0:\n",
    "    r = resumo.iloc[0]\n",
    "    \n",
    "    print(f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                       RESUMO EXECUTIVO - ECD ONLINE                         ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üìä BASE DE DADOS                                                          ‚ïë\n",
    "‚ïë     ‚Ä¢ Total de Empresas Analisadas: {r['total_empresas']:>32,}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Total de ECDs Processados: {r['total_ecds']:>35,}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Ano de Refer√™ncia: {r['ano_mais_recente']:>43}  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üí∞ VALORES CONSOLIDADOS                                                   ‚ïë\n",
    "‚ïë     ‚Ä¢ Ativo Total: {f\"R$ {r['ativo_total_consolidado']/1e9:>45,.2f} Bi\"}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Receita L√≠quida Total: {f\"R$ {r['receita_total_consolidada']/1e9:>36,.2f} Bi\"}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Resultado L√≠quido Total: {f\"R$ {r['resultado_total_consolidado']/1e9:>34,.2f} Bi\"}  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üìä INDICADORES M√âDIOS                                                     ‚ïë\n",
    "‚ïë     ‚Ä¢ Liquidez Corrente M√©dia: {r['liquidez_media']:>39,.2f}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Endividamento M√©dio: {r['endividamento_medio']:>43,.2%}  ‚ïë\n",
    "‚ïë     ‚Ä¢ Margem L√≠quida M√©dia: {r['margem_media']:>42,.2f}%  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üè¢ PERFIL DAS EMPRESAS                                                    ‚ïë\n",
    "‚ïë     ‚Ä¢ Grande Porte: {r['empresas_grande_porte']:>50,} ({r['empresas_grande_porte']/r['total_empresas']*100:>4,.1f}%)  ‚ïë\n",
    "‚ïë     ‚Ä¢ Com Lucro: {r['empresas_lucro']:>55,} ({r['empresas_lucro']/r['total_empresas']*100:>4,.1f}%)  ‚ïë\n",
    "‚ïë     ‚Ä¢ Com Preju√≠zo: {r['empresas_prejuizo']:>52,} ({r['empresas_prejuizo']/r['total_empresas']*100:>4,.1f}%)  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  ‚ö†Ô∏è  AN√ÅLISE DE RISCO                                                      ‚ïë\n",
    "‚ïë     ‚Ä¢ Empresas de Alto Risco: {r['empresas_alto_risco']:>42,} ({r['empresas_alto_risco']/r['total_empresas']*100:>4,.1f}%)  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "    \"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# TOP EMPRESAS PARA FISCALIZA√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ TOP 50 EMPRESAS PRIORIT√ÅRIAS PARA FISCALIZA√á√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_prioridades AS\n",
    "SELECT \n",
    "    sr.cnpj,\n",
    "    sr.razao_social,\n",
    "    sr.uf,\n",
    "    sr.de_cnae,\n",
    "    sr.classificacao_risco,\n",
    "    CAST(COALESCE(sr.score_risco_total, 0) AS DOUBLE) AS score_risco,\n",
    "    CAST(COALESCE(sr.qtd_indicios_neaf, 0) AS DOUBLE) AS qtd_indicios,\n",
    "    CAST(COALESCE(ind.ativo_total, 0) AS DOUBLE) AS ativo_total,\n",
    "    CAST(COALESCE(ind.receita_liquida, 0) AS DOUBLE) AS receita_liquida,\n",
    "    CAST(COALESCE(ind.liquidez_corrente, 0) AS DOUBLE) AS liquidez_corrente,\n",
    "    CAST(COALESCE(ind.margem_liquida_perc, 0) AS DOUBLE) AS margem_liquida,\n",
    "    CASE \n",
    "        WHEN sr.score_risco_total >= 7 AND ind.ativo_total >= 100000000 THEN 1\n",
    "        WHEN sr.score_risco_total >= 7 OR ind.ativo_total >= 100000000 THEN 2\n",
    "        WHEN sr.score_risco_total >= 5 THEN 3\n",
    "        WHEN sr.score_risco_total >= 3 THEN 4\n",
    "        ELSE 5\n",
    "    END AS prioridade\n",
    "FROM teste.ecd_score_risco_consolidado sr\n",
    "LEFT JOIN teste.ecd_indicadores_financeiros ind\n",
    "    ON sr.cnpj = ind.cnpj\n",
    "    AND sr.ano_referencia = ind.ano_referencia\n",
    "WHERE sr.score_risco_total >= 3\n",
    "    OR sr.qtd_indicios_neaf >= 2\n",
    "    OR ind.liquidez_corrente < 0.5\n",
    "    OR (ind.resultado_liquido < 0 AND ind.ativo_total > 50000000)\n",
    "ORDER BY prioridade ASC, score_risco DESC, ativo_total DESC\n",
    "LIMIT 50\n",
    "\"\"\")\n",
    "\n",
    "total_prior = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_prioridades\").collect()[0]['cnt']\n",
    "\n",
    "if total_prior > 0:\n",
    "    df_prioridades = spark.sql(\"SELECT * FROM vw_prioridades\").toPandas()\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(df_prioridades)} empresas identificadas como priorit√°rias\")\n",
    "    \n",
    "    # Estat√≠sticas das prioridades\n",
    "    print(\"\\nüìä Distribui√ß√£o por Prioridade:\")\n",
    "    dist_prior = df_prioridades['prioridade'].value_counts().sort_index()\n",
    "    for prior, qtd in dist_prior.items():\n",
    "        print(f\"  ‚Ä¢ Prioridade {prior}: {qtd} empresas\")\n",
    "    \n",
    "    # Criar tabela formatada\n",
    "    df_export = df_prioridades.copy()\n",
    "    df_export['ativo_mi'] = df_export['ativo_total'] / 1_000_000\n",
    "    df_export['receita_mi'] = df_export['receita_liquida'] / 1_000_000\n",
    "    \n",
    "    print(\"\\nüìã TOP 20 EMPRESAS PRIORIT√ÅRIAS:\")\n",
    "    print(df_export.head(20)[[\n",
    "        'cnpj', 'razao_social', 'uf', 'classificacao_risco', \n",
    "        'score_risco', 'qtd_indicios', 'ativo_mi', 'prioridade'\n",
    "    ]].to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico de prioridades\n",
    "    fig = px.scatter(\n",
    "        df_prioridades,\n",
    "        x='score_risco',\n",
    "        y='ativo_total',\n",
    "        color='prioridade',\n",
    "        size='qtd_indicios',\n",
    "        hover_data=['razao_social', 'uf', 'de_cnae'],\n",
    "        title='<b>Mapa de Prioriza√ß√£o de Fiscaliza√ß√£o</b>',\n",
    "        labels={\n",
    "            'score_risco': 'Score de Risco',\n",
    "            'ativo_total': 'Ativo Total',\n",
    "            'prioridade': 'Prioridade',\n",
    "            'qtd_indicios': 'Ind√≠cios NEAF'\n",
    "        },\n",
    "        color_continuous_scale='RdYlGn_r',\n",
    "        log_y=True\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "\n",
    "# ============================================================================\n",
    "# PRINCIPAIS ACHADOS E INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç PRINCIPAIS ACHADOS E INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# An√°lise de setores de risco\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_setores_risco AS\n",
    "SELECT \n",
    "    ec.cnae_secao_descricao,\n",
    "    COUNT(DISTINCT ec.cnpj) AS qtd_empresas,\n",
    "    CAST(AVG(COALESCE(sr.score_risco_total, 0)) AS DOUBLE) AS score_medio,\n",
    "    COUNT(DISTINCT CASE WHEN sr.classificacao_risco IN ('RISCO CR√çTICO', 'RISCO ALTO') THEN ec.cnpj END) AS empresas_alto_risco,\n",
    "    CAST(AVG(COALESCE(ind.margem_liquida_perc, 0)) AS DOUBLE) AS margem_media,\n",
    "    CAST(AVG(COALESCE(ind.liquidez_corrente, 0)) AS DOUBLE) AS liquidez_media\n",
    "FROM teste.ecd_empresas_cadastro ec\n",
    "LEFT JOIN teste.ecd_score_risco_consolidado sr\n",
    "    ON ec.cnpj = sr.cnpj\n",
    "    AND ec.ano_referencia = sr.ano_referencia\n",
    "LEFT JOIN teste.ecd_indicadores_financeiros ind\n",
    "    ON ec.cnpj = ind.cnpj\n",
    "    AND ec.ano_referencia = ind.ano_referencia\n",
    "WHERE ec.cnae_secao_descricao IS NOT NULL\n",
    "GROUP BY ec.cnae_secao_descricao\n",
    "HAVING COUNT(DISTINCT ec.cnpj) >= 10\n",
    "ORDER BY score_medio DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "df_setores_risco = spark.sql(\"SELECT * FROM vw_setores_risco\").toPandas()\n",
    "\n",
    "if len(df_setores_risco) > 0:\n",
    "    print(\"\\nüè≠ TOP 10 SETORES COM MAIOR RISCO M√âDIO:\")\n",
    "    for idx, row in df_setores_risco.iterrows():\n",
    "        perc_risco = (row['empresas_alto_risco'] / row['qtd_empresas']) * 100\n",
    "        print(f\"\\n{idx+1}. {row['cnae_secao_descricao'][:60]}\")\n",
    "        print(f\"   ‚Ä¢ Empresas: {row['qtd_empresas']:.0f}\")\n",
    "        print(f\"   ‚Ä¢ Score M√©dio: {row['score_medio']:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Alto Risco: {row['empresas_alto_risco']:.0f} ({perc_risco:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Margem M√©dia: {row['margem_media']:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Liquidez M√©dia: {row['liquidez_media']:.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RECOMENDA√á√ïES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° RECOMENDA√á√ïES PARA A√á√ÉO FISCAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                            RECOMENDA√á√ïES                                   ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  1Ô∏è‚É£  PRIORIZA√á√ÉO DE FISCALIZA√á√ÉO                                          ‚ïë\n",
    "‚ïë     ‚Üí Focar nas empresas com Prioridade 1 e 2 (score ‚â• 7 ou ativo alto)   ‚ïë\n",
    "‚ïë     ‚Üí Empresas com m√∫ltiplos ind√≠cios NEAF requerem aten√ß√£o especial      ‚ïë\n",
    "‚ïë     ‚Üí Setores de alto risco devem ter fiscaliza√ß√£o preventiva             ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  2Ô∏è‚É£  MONITORAMENTO CONT√çNUO                                               ‚ïë\n",
    "‚ïë     ‚Üí Acompanhar empresas com liquidez < 1.0                              ‚ïë\n",
    "‚ïë     ‚Üí Monitorar empresas com endividamento > 70%                          ‚ïë\n",
    "‚ïë     ‚Üí Alertar sobre empresas em preju√≠zo recorrente                       ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  3Ô∏è‚É£  AN√ÅLISE SETORIAL                                                     ‚ïë\n",
    "‚ïë     ‚Üí Investigar setores com score m√©dio > 5.0                            ‚ïë\n",
    "‚ïë     ‚Üí Comparar empresas com benchmark setorial                            ‚ïë\n",
    "‚ïë     ‚Üí Identificar outliers por setor                                      ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  4Ô∏è‚É£  VALIDA√á√ÉO DE INCONSIST√äNCIAS                                         ‚ïë\n",
    "‚ïë     ‚Üí Priorizar empresas com diferen√ßas na equa√ß√£o cont√°bil               ‚ïë\n",
    "‚ïë     ‚Üí Verificar empresas com varia√ß√µes at√≠picas ano a ano                 ‚ïë\n",
    "‚ïë     ‚Üí Cruzar dados ECD com outras obriga√ß√µes acess√≥rias                   ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  5Ô∏è‚É£  INTELIG√äNCIA FISCAL                                                  ‚ïë\n",
    "‚ïë     ‚Üí Usar modelos de ML para predi√ß√£o de risco cont√≠nua                  ‚ïë\n",
    "‚ïë     ‚Üí Aplicar clustering para identificar padr√µes an√¥malos                ‚ïë\n",
    "‚ïë     ‚Üí Manter base de conhecimento atualizada                              ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONCLUS√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ AN√ÅLISE CONCLU√çDA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                            CONCLUS√ÉO DO PROJETO                            ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üìä An√°lise completa da base ECD realizada com sucesso                     ‚ïë\n",
    "‚ïë  ü§ñ Modelos de Machine Learning treinados e validados                      ‚ïë\n",
    "‚ïë  üîç Clustering identificou grupos distintos de comportamento               ‚ïë\n",
    "‚ïë  üìà Dashboards interativos gerados para an√°lise visual                     ‚ïë\n",
    "‚ïë  üéØ Lista de prioriza√ß√£o para fiscaliza√ß√£o preparada                       ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  ‚ú® PR√ìXIMOS PASSOS:                                                       ‚ïë\n",
    "‚ïë     1. Revisar lista de empresas priorit√°rias                             ‚ïë\n",
    "‚ïë     2. Aplicar crit√©rios adicionais de sele√ß√£o                            ‚ïë\n",
    "‚ïë     3. Iniciar a√ß√µes de fiscaliza√ß√£o direcionada                          ‚ïë\n",
    "‚ïë     4. Monitorar resultados e ajustar modelos                             ‚ïë\n",
    "‚ïë     5. Integrar com outras bases de dados                                 ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïë  üìÖ Data de execu√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S'):>44}  ‚ïë\n",
    "‚ïë                                                                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üéâ PROJETO ECD - AN√ÅLISE EXPLORAT√ìRIA E MACHINE LEARNING\n",
    "   Auditor Fiscal da Receita Estadual de SC\n",
    "   \n",
    "   Desenvolvido com: Python, PySpark, Scikit-learn, XGBoost, Plotly\n",
    "   \n",
    "   Para d√∫vidas ou sugest√µes, consulte a equipe de Data Science.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üôè OBRIGADO POR UTILIZAR ESTE PROJETO!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Pipeline)",
   "language": "python",
   "name": "conda_data_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
