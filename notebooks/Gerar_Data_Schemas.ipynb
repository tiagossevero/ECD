{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gera√ß√£o de Data Schemas - Projeto ECD\n",
    "\n",
    "Este notebook coleta automaticamente os metadados e amostras de dados de todas as tabelas do projeto ECD.\n",
    "\n",
    "## O que ser√° gerado:\n",
    "\n",
    "Para cada tabela:\n",
    "- **DESCRIBE FORMATTED** - Metadados completos (schema, parti√ß√µes, localiza√ß√£o, etc)\n",
    "- **SELECT * FROM ... LIMIT 10** - Amostra de 10 linhas de dados\n",
    "\n",
    "## Totais:\n",
    "- **52 tabelas** (originais + intermedi√°rias)\n",
    "- **104 comandos SQL** (2 por tabela)\n",
    "- **156 arquivos** de sa√≠da (DESCRIBE.txt, SAMPLE.txt, SAMPLE.csv)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Adicionar paths necess√°rios\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports realizados com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar Sess√£o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(profile: str = 'efd_t2', dynamic_allocation_enabled: bool = True):\n",
    "    \"\"\"Gera DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"ecd_data_schema_generator\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "# Inicializar sess√£o\n",
    "print(\"Inicializando sess√£o Spark...\")\n",
    "session = get_session(profile='efd_t2')\n",
    "spark = session.sparkSession\n",
    "print(\"‚úì Sess√£o Spark inicializada com sucesso\")\n",
    "\n",
    "# Testar conex√£o\n",
    "spark.sql(\"SHOW DATABASES\").limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defini√ß√£o das Tabelas\n",
    "\n",
    "Organize as tabelas por categoria para facilitar o processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABELAS = {\n",
    "    \"ORIGINAIS_RI\": [\n",
    "        \"usr_sat_ecd.ecd_ri050_plano_contas\",\n",
    "        \"usr_sat_ecd.ecd_ri051_plano_contas_referencial\",\n",
    "        \"usr_sat_ecd.ecd_ri150_saldos_periodicos_identificacao_periodo\",\n",
    "        \"usr_sat_ecd.ecd_ri155_detalhe_saldos_periodicos\",\n",
    "    ],\n",
    "    \n",
    "    \"ORIGINAIS_RJ\": [\n",
    "        \"usr_sat_ecd.ecd_rj100_balanco_patrimonial\",\n",
    "        \"usr_sat_ecd.ecd_rj150_demonstracao_resultado_exercicio\",\n",
    "    ],\n",
    "    \n",
    "    \"ORIGINAIS_PROCESSADAS\": [\n",
    "        \"teste.ecd_i150\",\n",
    "        \"teste.ecd_i200\",\n",
    "    ],\n",
    "    \n",
    "    \"PRODUCAO\": [\n",
    "        \"teste.ecd_contas_classificadas_producao\",\n",
    "        \"teste.ecd_balanco_patrimonial\",\n",
    "        \"teste.ecd_dre\",\n",
    "        \"teste.ecd_indicadores_financeiros\",\n",
    "    ],\n",
    "    \n",
    "    \"STREAMLIT\": [\n",
    "        \"teste.ecd_empresas_cadastro\",\n",
    "        \"teste.ecd_score_risco_consolidado\",\n",
    "        \"teste.ecd_saldos_contas_v2\",\n",
    "        \"teste.ecd_plano_contas\",\n",
    "    ],\n",
    "    \n",
    "    \"ML_DATASET\": [\n",
    "        \"teste.ecd_ml_dataset\",\n",
    "        \"teste.ecd_ml_train\",\n",
    "        \"teste.ecd_ml_val\",\n",
    "        \"teste.ecd_ml_test\",\n",
    "    ],\n",
    "    \n",
    "    \"ML_PREDICOES\": [\n",
    "        \"teste.ecd_ml_predictions_ALL\",\n",
    "        \"teste.ecd_ml_predictions_rf_val\",\n",
    "        \"teste.ecd_ml_predictions_lr_val\",\n",
    "        \"teste.ecd_ml_predicoes\",\n",
    "    ],\n",
    "    \n",
    "    \"ML_METRICAS\": [\n",
    "        \"teste.ecd_ml_metricas\",\n",
    "        \"teste.ecd_ml_performance_por_classe\",\n",
    "        \"teste.ecd_ml_erros_rf\",\n",
    "        \"teste.ml_label_mapping\",\n",
    "    ],\n",
    "    \n",
    "    \"ML_EMPRESAS\": [\n",
    "        \"teste.ecd_ml_stats_classificacao_empresa\",\n",
    "        \"teste.ecd_ml_valores_balanco_empresa\",\n",
    "        \"teste.ecd_ml_valores_dre_empresa\",\n",
    "        \"teste.ecd_ml_empresas_consolidado\",\n",
    "    ],\n",
    "    \n",
    "    \"ML_ANALISE\": [\n",
    "        \"teste.ecd_ml_empresas_aptas_indicadores\",\n",
    "        \"teste.ecd_ml_empresas_indices_padrao\",\n",
    "        \"teste.ecd_ml_indices_padrao_decis\",\n",
    "        \"teste.ecd_ml_candidatas_ajuste_manual\",\n",
    "        \"teste.ecd_ml_sinteticas_por_heranca\",\n",
    "        \"teste.ecd_ml_fallback_classificacoes\",\n",
    "    ],\n",
    "    \n",
    "    \"INDICADORES\": [\n",
    "        \"teste.ecd_indicadores_hibrido\",\n",
    "        \"teste.ecd_indices_padrao_setoriais\",\n",
    "        \"teste.ecd_empresas_classificacao_resumo\",\n",
    "        \"teste.ecd_evolucao_scores\",\n",
    "        \"teste.ecd_empresas_criticas\",\n",
    "    ],\n",
    "    \n",
    "    \"VALIDACAO\": [\n",
    "        \"teste.pc_referencia_completa\",\n",
    "        \"teste.ecd_contas_classificadas_final\",\n",
    "        \"teste.ecd_resumo_executivo\",\n",
    "        \"teste.ecd_detalhamento_metodo\",\n",
    "        \"teste.ecd_top_classificacoes\",\n",
    "        \"teste.ecd_empresas_equacao_ok\",\n",
    "        \"teste.ecd_amostra_ml\",\n",
    "        \"teste.ecd_contas_nao_classificadas\",\n",
    "        \"teste.ecd_stats_por_empresa\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Estat√≠sticas\n",
    "total_tabelas = sum(len(tabelas) for tabelas in TABELAS.values())\n",
    "print(f\"Total de categorias: {len(TABELAS)}\")\n",
    "print(f\"Total de tabelas: {total_tabelas}\")\n",
    "print(f\"Total de comandos SQL: {total_tabelas * 2}\")\n",
    "print(\"\\nTabelas por categoria:\")\n",
    "for categoria, tabelas in TABELAS.items():\n",
    "    print(f\"  - {categoria}: {len(tabelas)} tabelas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_tabela_existe(tabela_nome):\n",
    "    \"\"\"Verifica se a tabela existe no banco.\"\"\"\n",
    "    try:\n",
    "        spark.sql(f\"DESCRIBE {tabela_nome}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def coletar_describe_formatted(tabela_nome):\n",
    "    \"\"\"Coleta DESCRIBE FORMATTED de uma tabela.\"\"\"\n",
    "    try:\n",
    "        df = spark.sql(f\"DESCRIBE FORMATTED {tabela_nome}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erro ao coletar DESCRIBE FORMATTED: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def coletar_sample_data(tabela_nome):\n",
    "    \"\"\"Coleta amostra de dados (10 linhas) de uma tabela.\"\"\"\n",
    "    try:\n",
    "        df = spark.sql(f\"SELECT * FROM {tabela_nome} LIMIT 10\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erro ao coletar sample: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def salvar_dataframe_como_texto(df, arquivo_path):\n",
    "    \"\"\"Salva DataFrame como arquivo de texto.\"\"\"\n",
    "    try:\n",
    "        pdf = df.toPandas()\n",
    "        with open(arquivo_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(pdf.to_string(index=False))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erro ao salvar arquivo: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def salvar_dataframe_como_csv(df, arquivo_path):\n",
    "    \"\"\"Salva DataFrame como CSV.\"\"\"\n",
    "    try:\n",
    "        pdf = df.toPandas()\n",
    "        pdf.to_csv(arquivo_path, index=False, encoding='utf-8')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erro ao salvar CSV: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "print(\"‚úì Fun√ß√µes auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configurar Diret√≥rio de Sa√≠da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rio de sa√≠da\n",
    "output_dir = Path(\"/home/user/ECD/data-schemas\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Diret√≥rio de sa√≠da: {output_dir}\")\n",
    "print(f\"‚úì Diret√≥rio criado/verificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processar Tabelas\n",
    "\n",
    "### ‚öôÔ∏è Escolha o que processar:\n",
    "\n",
    "**Op√ß√£o 1:** Execute todas as c√©lulas abaixo para processar TODAS as categorias\n",
    "\n",
    "**Op√ß√£o 2:** Execute apenas as c√©lulas das categorias que voc√™ precisa\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. ORIGINAIS_RI (4 tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"ORIGINAIS_RI\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. ORIGINAIS_RJ (2 tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"ORIGINAIS_RJ\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. ORIGINAIS_PROCESSADAS (2 tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"ORIGINAIS_PROCESSADAS\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. PRODUCAO (4 tabelas) ‚≠ê PRIORIT√ÅRIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"PRODUCAO\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. STREAMLIT (4 tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"STREAMLIT\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6. ML_DATASET (4 tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = \"ML_DATASET\"\n",
    "tabelas = TABELAS[categoria]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "categoria_dir = output_dir / categoria\n",
    "categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, tabela in enumerate(tabelas, 1):\n",
    "    print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "    \n",
    "    if not verificar_tabela_existe(tabela):\n",
    "        print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "        continue\n",
    "    \n",
    "    tabela_limpa = tabela.replace('.', '_')\n",
    "    \n",
    "    # DESCRIBE FORMATTED\n",
    "    print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "    df_describe = coletar_describe_formatted(tabela)\n",
    "    if df_describe:\n",
    "        arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "        if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "            print(f\"  ‚úì DESCRIBE salvo\")\n",
    "    \n",
    "    # SELECT SAMPLE\n",
    "    print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "    df_sample = coletar_sample_data(tabela)\n",
    "    if df_sample:\n",
    "        arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "        arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "        \n",
    "        if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "            print(f\"  ‚úì Sample TXT salvo\")\n",
    "        if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "            print(f\"  ‚úì Sample CSV salvo\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7. Processar Categorias Restantes (AUTOMATIZADO)\n",
    "\n",
    "Esta c√©lula processa todas as categorias ML restantes de uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorias restantes para processar\n",
    "categorias_restantes = [\n",
    "    \"ML_PREDICOES\",\n",
    "    \"ML_METRICAS\",\n",
    "    \"ML_EMPRESAS\",\n",
    "    \"ML_ANALISE\",\n",
    "    \"INDICADORES\",\n",
    "    \"VALIDACAO\"\n",
    "]\n",
    "\n",
    "for categoria in categorias_restantes:\n",
    "    tabelas = TABELAS[categoria]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  üìÇ CATEGORIA: {categoria}\")\n",
    "    print(f\"  Total de tabelas: {len(tabelas)}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    categoria_dir = output_dir / categoria\n",
    "    categoria_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i, tabela in enumerate(tabelas, 1):\n",
    "        print(f\"\\n[{i}/{len(tabelas)}] üìä Processando: {tabela}\")\n",
    "        \n",
    "        if not verificar_tabela_existe(tabela):\n",
    "            print(f\"  ‚ö†Ô∏è  Tabela n√£o encontrada\")\n",
    "            continue\n",
    "        \n",
    "        tabela_limpa = tabela.replace('.', '_')\n",
    "        \n",
    "        # DESCRIBE FORMATTED\n",
    "        print(f\"  ‚Üí Coletando DESCRIBE FORMATTED...\")\n",
    "        df_describe = coletar_describe_formatted(tabela)\n",
    "        if df_describe:\n",
    "            arquivo_describe = categoria_dir / f\"{tabela_limpa}_DESCRIBE.txt\"\n",
    "            if salvar_dataframe_como_texto(df_describe, arquivo_describe):\n",
    "                print(f\"  ‚úì DESCRIBE salvo\")\n",
    "        \n",
    "        # SELECT SAMPLE\n",
    "        print(f\"  ‚Üí Coletando sample (10 linhas)...\")\n",
    "        df_sample = coletar_sample_data(tabela)\n",
    "        if df_sample:\n",
    "            arquivo_sample_txt = categoria_dir / f\"{tabela_limpa}_SAMPLE.txt\"\n",
    "            arquivo_sample_csv = categoria_dir / f\"{tabela_limpa}_SAMPLE.csv\"\n",
    "            \n",
    "            if salvar_dataframe_como_texto(df_sample, arquivo_sample_txt):\n",
    "                print(f\"  ‚úì Sample TXT salvo\")\n",
    "            if salvar_dataframe_como_csv(df_sample, arquivo_sample_csv):\n",
    "                print(f\"  ‚úì Sample CSV salvo\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  ‚úÖ Categoria {categoria} conclu√≠da!\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n\\nüéâ TODAS AS CATEGORIAS RESTANTES PROCESSADAS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Criar √çndice de Arquivos Gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_indice = output_dir / \"INDEX.md\"\n",
    "\n",
    "with open(arquivo_indice, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# Data Schemas - Projeto ECD\\n\\n\")\n",
    "    f.write(f\"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "    \n",
    "    for categoria, tabelas in TABELAS.items():\n",
    "        f.write(f\"## {categoria}\\n\\n\")\n",
    "        \n",
    "        for tabela in tabelas:\n",
    "            tabela_limpa = tabela.replace('.', '_')\n",
    "            f.write(f\"### {tabela}\\n\\n\")\n",
    "            f.write(f\"- **DESCRIBE**: `{categoria}/{tabela_limpa}_DESCRIBE.txt`\\n\")\n",
    "            f.write(f\"- **SAMPLE TXT**: `{categoria}/{tabela_limpa}_SAMPLE.txt`\\n\")\n",
    "            f.write(f\"- **SAMPLE CSV**: `{categoria}/{tabela_limpa}_SAMPLE.csv`\\n\\n\")\n",
    "\n",
    "print(f\"‚úì √çndice criado: {arquivo_indice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Relat√≥rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  RELAT√ìRIO FINAL - GERA√á√ÉO DE DATA SCHEMAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Contar arquivos gerados\n",
    "total_arquivos = 0\n",
    "arquivos_por_categoria = {}\n",
    "\n",
    "for categoria in TABELAS.keys():\n",
    "    categoria_dir = output_dir / categoria\n",
    "    if categoria_dir.exists():\n",
    "        arquivos = list(categoria_dir.glob(\"*\"))\n",
    "        arquivos_por_categoria[categoria] = len(arquivos)\n",
    "        total_arquivos += len(arquivos)\n",
    "\n",
    "print(f\"\\nüìä Estat√≠sticas:\")\n",
    "print(f\"  - Total de categorias processadas: {len(arquivos_por_categoria)}\")\n",
    "print(f\"  - Total de arquivos gerados: {total_arquivos}\")\n",
    "print(f\"  - Diret√≥rio de sa√≠da: {output_dir}\")\n",
    "\n",
    "print(f\"\\nüìÅ Arquivos por categoria:\")\n",
    "for categoria, num_arquivos in arquivos_por_categoria.items():\n",
    "    print(f\"  - {categoria}: {num_arquivos} arquivos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  ‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÑ Consulte o √≠ndice completo em: {arquivo_indice}\")\n",
    "print(f\"\\nüí° Pr√≥ximo passo: Revisar os arquivos gerados em {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verificar Exemplos de Sa√≠da (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Visualizar DESCRIBE de uma tabela\n",
    "exemplo_tabela = \"teste.ecd_balanco_patrimonial\"\n",
    "\n",
    "if verificar_tabela_existe(exemplo_tabela):\n",
    "    print(f\"\\nüìã DESCRIBE FORMATTED: {exemplo_tabela}\\n\")\n",
    "    df = spark.sql(f\"DESCRIBE FORMATTED {exemplo_tabela}\")\n",
    "    df.show(50, truncate=False)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Tabela {exemplo_tabela} n√£o encontrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Visualizar SAMPLE de uma tabela\n",
    "exemplo_tabela = \"teste.ecd_balanco_patrimonial\"\n",
    "\n",
    "if verificar_tabela_existe(exemplo_tabela):\n",
    "    print(f\"\\nüìä SAMPLE (10 linhas): {exemplo_tabela}\\n\")\n",
    "    df = spark.sql(f\"SELECT * FROM {exemplo_tabela} LIMIT 10\")\n",
    "    df.show(10, truncate=True)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Tabela {exemplo_tabela} n√£o encontrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notas Importantes\n",
    "\n",
    "### Tabelas Particionadas\n",
    "\n",
    "As seguintes tabelas s√£o particionadas por `ano`:\n",
    "- `teste.ecd_balanco_patrimonial`\n",
    "- `teste.ecd_dre`\n",
    "- `teste.ecd_indicadores_financeiros`\n",
    "\n",
    "O DESCRIBE FORMATTED mostrar√° as informa√ß√µes de particionamento.\n",
    "\n",
    "### Tabelas que Podem N√£o Existir\n",
    "\n",
    "Algumas tabelas podem n√£o existir se os notebooks correspondentes n√£o foram executados:\n",
    "- Tabelas ML (se modelo n√£o foi treinado)\n",
    "- Tabelas de valida√ß√£o (se an√°lise n√£o foi feita)\n",
    "\n",
    "**O notebook pula automaticamente tabelas inexistentes.**\n",
    "\n",
    "### Performance\n",
    "\n",
    "- Tempo estimado: 10-20 minutos para processar todas as 52 tabelas\n",
    "- Cada categoria pode ser executada independentemente\n",
    "- Use LIMIT 10 para garantir performance\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
